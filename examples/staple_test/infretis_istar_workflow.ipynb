{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61d7de0c",
   "metadata": {},
   "source": [
    "# Interface-based State Transition Analysis and Rate calculation (iSTAR) Workflow\n",
    "\n",
    "This notebook implements the iSTAR method for calculating crossing probabilities (Pcross) from transition interface sampling (TIS) simulations using infretis weights. The iSTAR approach builds a Markov state model at the interfaces to efficiently calculate transition probabilities.\n",
    "\n",
    "## Key Features:\n",
    "- **Weight Calculation**: Uses infretis weights for proper statistical weighting of paths\n",
    "- **Transition Matrix Construction**: Builds transition matrices from interface-to-interface transition probabilities  \n",
    "- **Global Pcross Calculation**: Computes the global crossing probability using the iSTAR Markov model\n",
    "- **WHAM Integration**: Incorporates WHAM-based methods for improved statistical accuracy\n",
    "\n",
    "## Workflow Overview:\n",
    "1. Load and process infretis simulation data\n",
    "2. Calculate path weights using infretis methodology\n",
    "3. Compute transition probabilities between interfaces\n",
    "4. Construct the iSTAR transition matrix\n",
    "5. Calculate global crossing probability from the Markov model\n",
    "6. Compare with traditional WHAM methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e8100b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n",
      "Available functions:\n",
      "- get_path_weights: Calculate unbiased weights for paths\n",
      "- run_analysis: WHAM-based crossing probability analysis\n",
      "- read_toml: Read TOML configuration files\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import warnings\n",
    "\n",
    "# Inftools imports\n",
    "import sys\n",
    "sys.path.append('/mnt/0bf0c339-34bb-4500-a5fb-f3c2a863de29/DATA/APPTIS/inftools')\n",
    "\n",
    "from inftools.tistools.path_weights import get_path_weights\n",
    "from inftools.analysis.Wham_Pcross import run_analysis\n",
    "from inftools.misc.tomlreader import infretis_data_reader\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(\"Available functions:\")\n",
    "print(\"- get_path_weights: Calculate unbiased weights for paths\")\n",
    "print(\"- run_analysis: WHAM-based crossing probability analysis\")\n",
    "print(\"- read_toml: Read TOML configuration files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5073e12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function calculate_infretis_weights updated with correct ptype handling from conv_inf_py.py!\n"
     ]
    }
   ],
   "source": [
    "def calculate_infretis_weights(data_file: str, toml_file: str, nskip: int = 0) -> Dict:\n",
    "    \"\"\"\n",
    "    Calculate infretis weights for paths, based on the path_weights.py methodology.\n",
    "    Updated to handle ptype information and derive direction from aXMYb format.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_file : str\n",
    "        Path to infretis_data.txt file\n",
    "    toml_file : str  \n",
    "        Path to infretis.toml configuration file\n",
    "    nskip : int\n",
    "        Number of initial entries to skip\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    Dict containing path data and weights\n",
    "    \"\"\"\n",
    "    import tomli\n",
    "    import re\n",
    "    import random\n",
    "    \n",
    "    def parse_ptype_direction(ptype):\n",
    "        \"\"\"\n",
    "        Parse ptype to extract direction based on interface indices.\n",
    "        Uses the exact logic from conv_inf_py.py\n",
    "        \"\"\"\n",
    "        # Handle simple ptype formats (ensemble 0)\n",
    "        if ptype in ['RMR', 'RML', 'LMR', 'LML']:\n",
    "            return 1\n",
    "        \n",
    "        # Handle complex ptype formats with interface indices\n",
    "        # Pattern to match: digits + letters + digits\n",
    "        match = re.match(r'^(\\d+)([LR]M[LR])(\\d+)$', ptype)\n",
    "        if match:\n",
    "            try:\n",
    "                a = int(match.group(1))  # First interface index\n",
    "                b = int(match.group(3))  # Last interface index\n",
    "                \n",
    "                if a < b:\n",
    "                    return 1\n",
    "                elif a > b:\n",
    "                    return -1\n",
    "                else:  # a == b\n",
    "                    return random.choice([1, -1])\n",
    "            except ValueError:\n",
    "                # If parsing fails, default to 1\n",
    "                return 1\n",
    "        \n",
    "        # Default case\n",
    "        return 1\n",
    "\n",
    "    def extract_ptype_middle(ptype):\n",
    "        \"\"\"\n",
    "        Extract the middle part (XMX) from ptype.\n",
    "        Uses the exact logic from conv_inf_py.py\n",
    "        \"\"\"\n",
    "        # Handle simple ptype formats (ensemble 0)\n",
    "        if ptype in ['RMR', 'RML', 'LMR', 'LML']:\n",
    "            return ptype\n",
    "        \n",
    "        # Handle complex ptype formats with interface indices\n",
    "        match = re.match(r'^(\\d+)([LR]M[LR])(\\d+)$', ptype)\n",
    "        if match:\n",
    "            return match.group(2)  # Return the middle part (XMX)\n",
    "        \n",
    "        # Default case - return as is\n",
    "        return ptype\n",
    "    \n",
    "    # Load configuration\n",
    "    with open(toml_file, \"rb\") as f:\n",
    "        toml_config = tomli.load(f)\n",
    "    interfaces = toml_config[\"simulation\"][\"interfaces\"]\n",
    "    \n",
    "    # Load data\n",
    "    data = np.loadtxt(data_file, dtype=str, usecols=np.arange(16))\n",
    "    data = data[nskip:]  # Skip initial entries\n",
    "    \n",
    "    # Check if we have ptype information (look for correct patterns)\n",
    "    has_ptype = False\n",
    "    ptype_col = None\n",
    "    \n",
    "    # Look for ptype patterns in the data - use correct patterns\n",
    "    for col in range(data.shape[1]):\n",
    "        sample_values = data[:10, col]  # Check first 10 rows\n",
    "        for val in sample_values:\n",
    "            if isinstance(val, str) and (re.match(r'\\d+[LR]M[LR]\\d+', val) or val in ['RMR', 'RML', 'LMR', 'LML']):\n",
    "                has_ptype = True\n",
    "                ptype_col = col\n",
    "                break\n",
    "        if has_ptype:\n",
    "            break\n",
    "    \n",
    "    if has_ptype:\n",
    "        print(f\"Found ptype information in column {ptype_col}\")\n",
    "        # Extract direction information from ptype\n",
    "        directions = []\n",
    "        start_interfaces = []\n",
    "        end_interfaces = []\n",
    "        \n",
    "        for i, row in enumerate(data):\n",
    "            ptype = row[ptype_col]\n",
    "            if isinstance(ptype, str):\n",
    "                # Parse using the correct logic from conv_inf_py.py\n",
    "                direction = parse_ptype_direction(ptype)\n",
    "                directions.append(direction)\n",
    "                \n",
    "                # Extract start and end interface indices\n",
    "                if ptype in ['RMR', 'RML', 'LMR', 'LML']:\n",
    "                    # Simple format - ensemble 0\n",
    "                    start_interfaces.append(0)\n",
    "                    end_interfaces.append(0)\n",
    "                else:\n",
    "                    # Complex format with interface indices\n",
    "                    match = re.match(r'^(\\d+)([LR]M[LR])(\\d+)$', ptype)\n",
    "                    if match:\n",
    "                        a = int(match.group(1))  # start interface index\n",
    "                        b = int(match.group(3))  # end interface index\n",
    "                        start_interfaces.append(a)\n",
    "                        end_interfaces.append(b)\n",
    "                    else:\n",
    "                        start_interfaces.append(0)\n",
    "                        end_interfaces.append(0)\n",
    "            else:\n",
    "                directions.append(0)  # Default for non-ptype entries\n",
    "                start_interfaces.append(0)\n",
    "                end_interfaces.append(0)\n",
    "    else:\n",
    "        print(\"No ptype information found, using standard format\")\n",
    "        directions = None\n",
    "        start_interfaces = None\n",
    "        end_interfaces = None\n",
    "    \n",
    "    # Identify non-zero paths (those with \"----\" in the zero-ensemble column)\n",
    "    # Adjust column index based on whether ptype is present\n",
    "    zero_col = 4 if not has_ptype else 5  # Assumes ptype is typically after maxop\n",
    "    if zero_col < data.shape[1]:\n",
    "        non_zero_paths = data[:, zero_col] == \"----\"\n",
    "    else:\n",
    "        # Fallback: look for \"----\" in any column after maxop\n",
    "        non_zero_paths = data[:, 3] == \"----\"\n",
    "    \n",
    "    # Replace \"----\" with \"0.0\" for numerical processing\n",
    "    data[data == \"----\"] = \"0.0\"\n",
    "    \n",
    "    # Extract path information\n",
    "    D = {}\n",
    "    D[\"pnr\"] = data[non_zero_paths, 0:1].astype(int)  # Path numbers\n",
    "    D[\"len\"] = data[non_zero_paths, 1:2].astype(int)  # Path lengths\n",
    "    D[\"maxop\"] = data[non_zero_paths, 2:3].astype(float)  # Maximum order parameter\n",
    "    \n",
    "    # Add ptype-derived information if available\n",
    "    if has_ptype:\n",
    "        D[\"ptype\"] = data[non_zero_paths, ptype_col]  # Path types\n",
    "        D[\"direction\"] = np.array([directions[i] for i in range(len(directions)) if non_zero_paths[i]])\n",
    "        D[\"start_intf\"] = np.array([start_interfaces[i] for i in range(len(start_interfaces)) if non_zero_paths[i]])\n",
    "        D[\"end_intf\"] = np.array([end_interfaces[i] for i in range(len(end_interfaces)) if non_zero_paths[i]])\n",
    "    \n",
    "    # Determine data columns for path_f and path_w\n",
    "    data_start_col = ptype_col + 1 if has_ptype else 4\n",
    "    D[\"path_f\"] = data[non_zero_paths, data_start_col : data_start_col + len(interfaces)].astype(float)  # Path occurrences\n",
    "    D[\"path_w\"] = data[non_zero_paths, data_start_col + len(interfaces) : data_start_col + 2 * len(interfaces)].astype(float)  # Path weights\n",
    "    \n",
    "    # Calculate weights w = path_f / path_w\n",
    "    w = D[\"path_f\"] / D[\"path_w\"]\n",
    "    w[np.isnan(w)] = 0\n",
    "    \n",
    "    # Normalize weights to match total number of samples\n",
    "    w = w / np.sum(w, axis=0) * np.sum(D[\"path_f\"], axis=0)\n",
    "    w[np.isnan(w)] = 0.0\n",
    "    wsum = np.sum(w, axis=0)\n",
    "    \n",
    "    # # Calculate local crossing probabilities (ploc) using WHAM\n",
    "    # ploc_wham = np.zeros(len(interfaces))\n",
    "    # ploc_wham[0] = 1.0\n",
    "    \n",
    "    # for i, intf_p1 in enumerate(interfaces[1:]):\n",
    "    #     h1 = D[\"maxop\"] >= intf_p1\n",
    "    #     nj = wsum[:i + 1]  # Number of paths crossing lambda_i for each ensemble up to i\n",
    "    #     njl = np.sum(h1 * w[:, : i + 1], axis=0)  # Number of paths crossing lambda_i+1\n",
    "    #     ploc_wham[i + 1] = np.sum(njl) / np.sum(nj / ploc_wham[: i + 1])\n",
    "    \n",
    "    # # Calculate unbiased path weights\n",
    "    # A = np.zeros_like(D[\"maxop\"])\n",
    "    # Q = 1 / np.cumsum(wsum / ploc_wham[:-1])\n",
    "    \n",
    "    # for j, pathnr in enumerate(D[\"pnr\"][:, 0]):\n",
    "    #     # Find the highest interface crossed by this path\n",
    "    #     K = min(\n",
    "    #         np.where(D[\"maxop\"][j] > interfaces)[0][-1] if np.any(D[\"maxop\"][j] > interfaces) else 0, \n",
    "    #         len(interfaces) - 2\n",
    "    #     )\n",
    "    #     A[j] = Q[K] * np.sum(w[j])\n",
    "    \n",
    "    # Store results\n",
    "    results = {\n",
    "        'interfaces': interfaces,\n",
    "        'path_data': D,\n",
    "        'weights_matrix': w,\n",
    "        # 'unbiased_weights': A,\n",
    "        # 'ploc_wham': ploc_wham,\n",
    "        # 'Q_factors': Q,\n",
    "        'has_ptype': has_ptype\n",
    "    }\n",
    "    \n",
    "    print(f\"Processed {len(D['pnr'])} non-zero paths\")\n",
    "    print(f\"Interfaces: {interfaces}\")\n",
    "    # print(f\"Local crossing probabilities (WHAM): {ploc_wham}\")\n",
    "    \n",
    "    if has_ptype:\n",
    "        print(f\"Path type information detected:\")\n",
    "        print(f\"  Forward paths (dir=1): {np.sum(D['direction'] == 1)}\")\n",
    "        print(f\"  Backward paths (dir=-1): {np.sum(D['direction'] == -1)}\")\n",
    "        print(f\"  Other paths (dir=0): {np.sum(D['direction'] == 0)}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"Function calculate_infretis_weights updated with correct ptype handling from conv_inf_py.py!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd10a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function compute_weight_matrices_weights updated with original istar_analysis.py logic!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def compute_weight_matrices_weights(weight_results: Dict, n_int: Optional[int] = None, tr: bool = True) -> Dict:\n",
    "    \"\"\"\n",
    "    Compute 3D weight matrices from path data following original istar_analysis logic.\n",
    "    \n",
    "    This function constructs weight matrices [i,j,k] where:\n",
    "    - i: ensemble index (path ensemble)\n",
    "    - j: starting interface index\n",
    "    - k: ending interface index\n",
    "    \n",
    "    Implements the original istar_analysis.py logic for:\n",
    "    - tr (time reversal): boolean for applying time-reversal symmetry\n",
    "    - Edge case handling for specific interface transitions\n",
    "    - Proper direction mask logic and boundary conditions\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    weight_results : Dict\n",
    "        Results from calculate_infretis_weights function containing:\n",
    "        - path_data (D): Dictionary with path information including path_f and path_w\n",
    "        - interfaces: List of interface positions\n",
    "        - has_ptype: Boolean indicating if ptype information is available\n",
    "    tr : bool, optional\n",
    "        If True, applies time-reversal symmetry by symmetrizing weight matrices.\n",
    "        Default is False.\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    Dict containing:\n",
    "        - weight_matrix_3d: 3D array [i,j,k] with weights for ensemble i, from interface j to k\n",
    "        - count_matrix_3d: 3D array [i,j,k] with path counts for ensemble i, from interface j to k\n",
    "        - weight_matrix_2d: 2D array [j,k] with total weights (summed over ensembles)\n",
    "        - count_matrix_2d: 2D array [j,k] with total count (summed over ensembles)\n",
    "        - ensemble_totals: 1D array with total weights per ensemble\n",
    "        - transition_summary: Dictionary with detailed transition statistics\n",
    "        - tr_applied: Boolean indicating if time-reversal symmetry was applied\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract data from weight_results\n",
    "    D = weight_results['path_data']\n",
    "    if n_int is None:\n",
    "        interfaces = weight_results['interfaces']\n",
    "    else:\n",
    "        interfaces = weight_results['interfaces'][:n_int]\n",
    "    has_ptype = weight_results.get('has_ptype', False)\n",
    "    \n",
    "    n_interfaces = len(interfaces)\n",
    "    n_ensembles = len(interfaces)  # Number of ensembles equals number of interfaces\n",
    "    n_paths = len(D['pnr'])\n",
    "    \n",
    "    print(f\"Computing weight matrices for {n_paths} paths\")\n",
    "    print(f\"Structure: Dictionary of 2D matrices [ensemble_idx][start_interface, end_interface]\")\n",
    "    print(f\"Dimensions: {n_ensembles} ensembles x {n_interfaces} interfaces x {n_interfaces} interfaces\")\n",
    "    print(f\"Following original istar_analysis.py logic with tr={tr}\")\n",
    "    \n",
    "    # Initialize dictionaries of 2D matrices {ensemble_i: [start_interface_j, end_interface_k]}\n",
    "    weight_matrix_3d = {i: np.zeros((n_interfaces, n_interfaces)) for i in range(n_ensembles)}\n",
    "    weight_matrix_3d_norm = {i: np.zeros((n_interfaces, n_interfaces)) for i in range(n_ensembles)}\n",
    "    count_matrix_3d = {i: np.zeros((n_interfaces, n_interfaces)) for i in range(n_ensembles)}\n",
    "    \n",
    "    # Arrays to track totals\n",
    "    ensemble_totals = np.zeros(n_ensembles)\n",
    "    \n",
    "    if has_ptype and 'start_intf' in D and 'end_intf' in D and 'direction' in D:\n",
    "        print(\"Using ptype information with direction for istar_analysis-style computation\")\n",
    "        \n",
    "        # Process each path\n",
    "        for path_idx in range(n_paths):\n",
    "            ptype = D['ptype'][path_idx]\n",
    "            start_intf = int(D['start_intf'][path_idx])\n",
    "            end_intf = int(D['end_intf'][path_idx])\n",
    "            direction = int(D['direction'][path_idx])  # 1 for forward, -1 for backward, 0 for other\n",
    "            \n",
    "            # Validate interface indices\n",
    "            if (((start_intf < 0 or start_intf >= n_interfaces) and\n",
    "                (end_intf < 0 or end_intf >= n_interfaces)) or\n",
    "                (start_intf >= n_interfaces-1 and end_intf >= n_interfaces-1 and n_int is not None)):\n",
    "                continue\n",
    "\n",
    "            start_intf = min(start_intf, n_interfaces - 1)  # Ensure within bounds\n",
    "            end_intf = min(end_intf, n_interfaces - 1)  # Ensure within bounds\n",
    "                \n",
    "            # Process each ensemble for this path (following original istar_analysis logic)\n",
    "            # Calculate weight as path_f / path_w\n",
    "            path_f_k = D['path_f'][path_idx, :]\n",
    "            path_w_k = np.array([min(D['path_w'][path_idx, i], 1.) for i in range(len(D['path_w'][path_idx, :]))])\n",
    "            # weight_k = np.nan_to_num(path_f_k / path_w_k) if np.sum(path_w_k) != 0 else 0\n",
    "            weight_k = path_f_k if np.sum(path_w_k) != 0 else 0\n",
    "            # weight_k = np.nan_to_num(weight_k / np.sum(weight_k) * np.sum(path_f_k)) if (np.sum(path_w_k) != 0 or np.sum(path_f_k) != 0) else 0\n",
    "\n",
    "            for i in range(1,n_ensembles):\n",
    "                if np.sum(path_w_k) != 0 and np.sum(path_f_k) != 0:  # Only process non-zero entries\n",
    "                # if weight_results['weights_matrix'][path_idx, i] != 0:\n",
    "                    # weight = weight_results['weights_matrix'][path_idx, i]\n",
    "                    weight = weight_k[i]\n",
    "                    # assert(weight == weight_results['weights_matrix'][path_idx, i]), f\"Weight mismatch for path {path_idx}, ensemble {i}: {weight} != {weight_results['weights_matrix'][path_idx, i]}\"\n",
    "                    # if not tr and ((i == 2 and \"LML\" in ptype) or (i == len(interfaces) - 1 and \"RMR\" in ptype)):\n",
    "                    #     weight /= 2\n",
    "                    #     if (i == 2 and \"LML\" in ptype):\n",
    "                    #         weight /= 2  # Additional halving for LML in ensemble 2\n",
    "                    # Apply original istar_analysis logic for j→k transitions\n",
    "                    j, k = start_intf, end_intf\n",
    "                    \n",
    "                    # Determine if this path should be counted in ensemble i\n",
    "                    should_count = False\n",
    "                    \n",
    "                    if j == k:\n",
    "                        # Self-transitions: Special case for i==1 (ensemble 1) and j==0\n",
    "                        if j == 0:\n",
    "                            # Original logic: count LMR paths in ensemble 1 for 0→0 transitions\n",
    "                            # if 'LMR' in D['ptype'][path_idx] or ('LML' in D['ptype'][path_idx] and D['maxop'][path_idx] >= interfaces[1]):\n",
    "                            #     k = 1  # Adjust to next interface for ensemble 1\n",
    "                            should_count = True\n",
    "                        elif j == len(interfaces) - 1:\n",
    "                            k = len(interfaces) - 2  # Last interface self-transition\n",
    "                            should_count = True  # Original logic: count RMR paths in last ensemble\n",
    "                        else:\n",
    "                            print(j,k, ptype)\n",
    "                            should_count = False\n",
    "                            \n",
    "                    elif j < k:\n",
    "                        # Forward transitions (j → k where j < k)\n",
    "                        \n",
    "                        # Edge case 1: j==0 and k==1 (first interface to second)\n",
    "                        if j == 0 and k == 1:\n",
    "                            # print(\"shouldnt happen first\")\n",
    "                            if i != 2:\n",
    "                                # Use direction==1 for forward paths\n",
    "                                should_count = (direction == 1)\n",
    "                                assert should_count\n",
    "                            elif i == 2:\n",
    "                                # Special case: ensemble 2 uses different logic\n",
    "                                # In original: dir_mask = masks[i][\"LML\"]\n",
    "                                should_count = True  # Simplified - would need LML mask\n",
    "                                \n",
    "                        # Edge case 2: Last interface transition\n",
    "                        elif j == len(interfaces)-2 and k == len(interfaces)-1:\n",
    "                            # print(\"shouldnt happen last\")\n",
    "                            # Original: dir_mask = masks[i][\"RMR\"]\n",
    "                            should_count = True  # Simplified - would need RMR mask\n",
    "\n",
    "                        elif i-1 in [j, k] and 1 < i < len(interfaces):\n",
    "                            # print(f\"path_w: {D['path_w'][path_idx, i]}, path_f: {D['path_f'][path_idx, i]}, weight: {weight}, j: {j}, k: {k}, i: {i}, ptype: {ptype}\")\n",
    "                            weight *= 2\n",
    "                            should_count = True\n",
    "                        else:\n",
    "                            # Standard forward transitions\n",
    "                            should_count = (direction == 1)\n",
    "                            assert should_count\n",
    "                            \n",
    "                    else:\n",
    "                        # Backward transitions (j → k where j > k)\n",
    "                        \n",
    "                        # Edge case 1: j==1 and k==0 (second interface to first)\n",
    "                        if j == 1 and k == 0:\n",
    "                            # print(\"shouldnt happen first backward\")\n",
    "                            if i != 2:\n",
    "                                # Use direction==-1 for backward paths\n",
    "                                should_count = (direction == -1)\n",
    "                                assert should_count\n",
    "                            elif i == 2:\n",
    "                                # Special case: ensemble 2 uses different logic\n",
    "                                should_count = True  # Simplified - would need LML mask\n",
    "                                \n",
    "                        # Edge case 2: Last interface backward transition\n",
    "                        elif j == len(interfaces)-1 and k == len(interfaces)-2:\n",
    "                            # print(\"shouldnt happen last backward\")\n",
    "                            # Original: dir_mask = masks[i][\"RMR\"]\n",
    "                            should_count = True  # Simplified - would need RMR mask\n",
    "                            \n",
    "                        elif i-1 in [j, k] and 1 < i < len(interfaces):\n",
    "                            # print(f\"path_w: {D['path_w'][path_idx, i]}, path_f: {D['path_f'][path_idx, i]}, weight: {weight}, j: {j}, k: {k}, i: {i}, ptype: {ptype}\")\n",
    "                            weight *= 2\n",
    "                            should_count = True\n",
    "                        else:\n",
    "                            # Standard backward transitions\n",
    "                            should_count = (direction == -1)\n",
    "                            assert should_count\n",
    "                    \n",
    "                    # Count the transition if criteria are met\n",
    "                    if should_count:\n",
    "                        \n",
    "                        weight_matrix_3d[i][j, k] += weight\n",
    "                        count_matrix_3d[i][j, k] += 1\n",
    "                        ensemble_totals[i] += weight\n",
    "    \n",
    "    else:\n",
    "        print(\"No ptype information with direction available\")\n",
    "        raise ValueError(\"Path data must contain 'start_intf', 'end_intf', and 'direction' for istar_analysis-style computation.\")\n",
    "    \n",
    "    # Apply time-reversal symmetry if requested (following original istar_analysis logic)\n",
    "    weight_matrix_3d_notr = {i: weight_matrix_3d[i].copy() for i in range(n_ensembles)}\n",
    "    count_matrix_3d_notr = {i: count_matrix_3d[i].copy() for i in range(n_ensembles)}\n",
    "    weight_matrix_2d_notr = np.zeros((n_interfaces, n_interfaces))\n",
    "    count_matrix_2d_notr = np.zeros((n_interfaces, n_interfaces))\n",
    "    if tr:\n",
    "        print(\"Applying time-reversal symmetry (tr=True)\")\n",
    "        \n",
    "        for i in range(n_ensembles):\n",
    "            # Original edge case logic for time reversal\n",
    "            # if i == 2 and weight_matrix_3d[i][1, 0] == 0:\n",
    "            #     # In [1*] all LML paths are classified as 1 → 0 (for now).\n",
    "            #     # Time reversal needs to be adjusted to compensate for this\n",
    "            #     weight_matrix_3d[i][0, 1] *= 2\n",
    "            #     print(f\"  Applied tr edge case for ensemble 2: doubled weight_matrix_3d[{i}, 0, 1]\")\n",
    "                \n",
    "            # elif i == len(interfaces)-1 and weight_matrix_3d[i][-2, -1] == 0:\n",
    "            #     weight_matrix_3d[i][-1, -2] *= 2\n",
    "            #     print(f\"  Applied tr edge case for last ensemble: doubled weight_matrix_3d[{i}, -1, -2]\")\n",
    "            \n",
    "            # Properly symmetrize the matrix: X[i] = (X[i] + X[i].T) / 2.0\n",
    "            weight_matrix_3d[i] = (weight_matrix_3d[i] + weight_matrix_3d[i].T) / 2.0\n",
    "            count_matrix_3d[i] = (count_matrix_3d[i] + count_matrix_3d[i].T) / 2.0\n",
    "    \n",
    "    # Calculate 2D matrices by summing over ensembles\n",
    "    weight_matrix_2d = np.zeros((n_interfaces, n_interfaces))\n",
    "    count_matrix_2d = np.zeros((n_interfaces, n_interfaces))\n",
    "\n",
    "    for i in range(n_ensembles):\n",
    "        weight_matrix_2d += weight_matrix_3d[i]\n",
    "        count_matrix_2d += count_matrix_3d[i]\n",
    "        weight_matrix_2d_notr += weight_matrix_3d_notr[i]\n",
    "        count_matrix_2d_notr += count_matrix_3d_notr[i]\n",
    "    \n",
    "    # Create transition summary\n",
    "    total_weight = sum(np.sum(weight_matrix_3d[i]) for i in range(n_ensembles))\n",
    "    total_transitions = sum(np.sum(count_matrix_3d[i]) for i in range(n_ensembles))\n",
    "    \n",
    "    # Analyze transition types across all ensembles\n",
    "    forward_transitions = 0\n",
    "    backward_transitions = 0\n",
    "    self_transitions = 0\n",
    "    forward_weight = 0\n",
    "    backward_weight = 0\n",
    "    self_weight = 0 \n",
    "    \n",
    "    for i in range(n_ensembles):\n",
    "        for j in range(n_interfaces):\n",
    "            for k in range(n_interfaces):\n",
    "                weight_ijk = weight_matrix_3d[i][j, k]\n",
    "                count_ijk = count_matrix_3d[i][j, k]\n",
    "                \n",
    "                if count_ijk > 0:\n",
    "                    if j < k:  # Forward transition\n",
    "                        forward_transitions += count_ijk\n",
    "                        forward_weight += weight_ijk\n",
    "                    elif j > k:  # Backward transition\n",
    "                        backward_transitions += count_ijk\n",
    "                        backward_weight += weight_ijk\n",
    "                    else:  # Self transition\n",
    "                        self_transitions += count_ijk\n",
    "                        self_weight += weight_ijk\n",
    "    \n",
    "    transition_summary = {\n",
    "        'total_weight': total_weight,\n",
    "        'total_transitions': total_transitions,\n",
    "        'forward_transitions': forward_transitions,\n",
    "        'backward_transitions': backward_transitions,\n",
    "        'self_transitions': self_transitions,\n",
    "        'forward_weight': forward_weight,\n",
    "        'backward_weight': backward_weight,\n",
    "        'self_weight': self_weight,\n",
    "        'forward_weight_fraction': forward_weight / total_weight if total_weight > 0 else 0,\n",
    "        'backward_weight_fraction': backward_weight / total_weight if total_weight > 0 else 0,\n",
    "        'self_weight_fraction': self_weight / total_weight if total_weight > 0 else 0\n",
    "    }\n",
    "    \n",
    "    # Print detailed results following original istar_analysis style\n",
    "    print(f\"\\n=== 3D WEIGHT MATRICES RESULTS (istar_analysis style) ===\")\n",
    "    print(f\"3D Matrix dimensions: {n_ensembles} x {n_interfaces} x {n_interfaces}\")\n",
    "    print(f\"Total weight processed: {total_weight:.6f}\")\n",
    "    print(f\"Total transitions: {total_transitions}\")\n",
    "    print(f\"Non-zero 3D matrix elements: {sum(np.count_nonzero(weight_matrix_3d[i]) for i in range(n_ensembles))}\")\n",
    "    print(f\"Time-reversal symmetry applied: {tr}\")\n",
    "    \n",
    "    # Print ensemble weights (like original \"Sum weights ensemble i\")\n",
    "    print(f\"\\nEnsemble weight totals:\")\n",
    "    for i in range(n_ensembles):\n",
    "        ensemble_sum = np.sum(weight_matrix_3d[i])\n",
    "        print(f\"  Sum weights ensemble {i}: {ensemble_sum:.4f}\")\n",
    "    \n",
    "    print(f\"\\n2D Weight Matrix [start_interface, end_interface] (summed over ensembles):\")\n",
    "    print(\"Rows = start interface, Columns = end interface\")\n",
    "    for j in range(n_interfaces):\n",
    "        row_str = f\"Interface {j}: \"\n",
    "        for k in range(n_interfaces):\n",
    "            row_str += f\"{weight_matrix_2d[j, k]:8.4f} \"\n",
    "        print(row_str)\n",
    "    \n",
    "    print(f\"\\nTransition Analysis:\")\n",
    "    print(f\"Forward transitions (j<k):  {forward_transitions:4f} paths, {forward_weight:8.4f} weight ({transition_summary['forward_weight_fraction']:.1%})\")\n",
    "    print(f\"Backward transitions (j>k): {backward_transitions:4f} paths, {backward_weight:8.4f} weight ({transition_summary['backward_weight_fraction']:.1%})\")\n",
    "    print(f\"Self transitions (j=k):     {self_transitions:4f} paths, {self_weight:8.4f} weight ({transition_summary['self_weight_fraction']:.1%})\")\n",
    "\n",
    "    # Show some 3D matrix details for non-zero entries\n",
    "    print(f\"\\nNon-zero 3D matrix entries (first 10):\")\n",
    "    count = 0\n",
    "    for i in range(n_ensembles):\n",
    "        for j in range(n_interfaces):\n",
    "            for k in range(n_interfaces):\n",
    "                if weight_matrix_3d[i][j, k] > 0 and count < 10:\n",
    "                    print(f\"  weights[{i},{j},{k}] = {weight_matrix_3d[i][j, k]:.6f} (count: {count_matrix_3d[i][j, k]:.1f})\")\n",
    "                    count += 1\n",
    "                if count >= 10:\n",
    "                    break\n",
    "            if count >= 10:\n",
    "                break\n",
    "        if count >= 10:\n",
    "            break\n",
    "    \n",
    "    # Store and return results\n",
    "    results = {\n",
    "        'weight_matrix_3d': weight_matrix_3d,\n",
    "        'count_matrix_3d': count_matrix_3d,\n",
    "        'weight_matrix_3d_notr': weight_matrix_3d_notr,\n",
    "        'count_matrix_3d_notr': count_matrix_3d_notr,\n",
    "        'weight_matrix_2d': weight_matrix_2d,\n",
    "        'count_matrix_2d': count_matrix_2d,\n",
    "        'weight_matrix_2d_notr': weight_matrix_2d_notr,\n",
    "        'count_matrix_2d_notr': count_matrix_2d_notr,\n",
    "        'ensemble_totals': ensemble_totals,\n",
    "        'transition_summary': transition_summary,\n",
    "        'tr_applied': tr,\n",
    "        'interfaces': interfaces,\n",
    "        'n_interfaces': n_interfaces,\n",
    "        'n_ensembles': n_ensembles,\n",
    "        'total_paths_processed': n_paths\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"Function compute_weight_matrices_weights updated with original istar_analysis.py logic!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b5ae6fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function display_data_infretis successfully defined!\n"
     ]
    }
   ],
   "source": [
    "def display_data_infretis(weight_matrices_result: Dict, threshold_w: float = 0.03, threshold_tr: float = 0.05) -> None:\n",
    "    \"\"\"\n",
    "    Display detailed analysis of infretis weight matrices in a format similar to display_data.\n",
    "    \n",
    "    This function provides comprehensive inspection of transition data from infretis weights,\n",
    "    including raw counts, weighted transitions, and time-reversal statistics. It's adapted\n",
    "    from the original display_data function to work with infretis data structures.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    weight_matrices_result : Dict\n",
    "        Results from compute_weight_matrices_weights function containing:\n",
    "        - weight_matrix_3d: Dictionary of 2D weight matrices {ensemble_i: [j,k]}\n",
    "        - count_matrix_3d: Dictionary of 2D count matrices {ensemble_i: [j,k]}\n",
    "        - weight_matrix_2d: 2D total weight matrix [j,k]\n",
    "        - ensemble_totals: Array of total weights per ensemble\n",
    "        - transition_summary: Dictionary with transition statistics\n",
    "        - interfaces: List of interface positions\n",
    "        - tr_applied: Boolean indicating if time-reversal was applied\n",
    "    threshold_w : float, optional\n",
    "        Threshold for detecting significant differences between weighted and raw data.\n",
    "        Default is 0.03 (3%).\n",
    "    threshold_tr : float, optional\n",
    "        Threshold for detecting time-reversal symmetry violations. Default is 0.05 (5%).\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "        This function only displays information and does not return values.\n",
    "        \n",
    "    Notes:\n",
    "    ------\n",
    "    This function provides similar diagnostics to the original display_data but adapted\n",
    "    for the infretis workflow data structures. It helps identify:\n",
    "    - Statistical anomalies in path weighting\n",
    "    - Time-reversal symmetry violations\n",
    "    - Insufficient sampling at specific interfaces\n",
    "    - Unusual transition patterns\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract data from results\n",
    "    weight_matrix_3d = weight_matrices_result['weight_matrix_3d']\n",
    "    count_matrix_3d = weight_matrices_result['count_matrix_3d']\n",
    "    weight_matrix_2d = weight_matrices_result['weight_matrix_2d']\n",
    "    count_matrix_3d_notr = weight_matrices_result['count_matrix_3d_notr']\n",
    "    weight_matrix_3d_notr = weight_matrices_result['weight_matrix_3d_notr']\n",
    "    ensemble_totals = weight_matrices_result['ensemble_totals']\n",
    "    interfaces = weight_matrices_result['interfaces']\n",
    "    n_interfaces = len(interfaces)\n",
    "    n_ensembles = len(weight_matrix_3d)\n",
    "    tr_applied = weight_matrices_result.get('tr_applied', False)\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"INFRETIS WEIGHT MATRICES ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Structure: {n_ensembles} ensembles × {n_interfaces} interfaces × {n_interfaces} interfaces\")\n",
    "    print(f\"Time-reversal symmetry applied: {tr_applied}\")\n",
    "    print(f\"Warning thresholds: weight differences ≥ {threshold_w:.1%}, TR violations ≥ {threshold_tr:.1%}\")\n",
    "    \n",
    "    # Process each ensemble\n",
    "    for i in range(n_ensembles):\n",
    "        print(f\"\\n{'-'*10}\")\n",
    "        print(f\"ENSEMBLE [{i-1 if i>0 else 0}{'*' if i>0 else '-'}] | ID {i}\")\n",
    "        print(f\"{'-'*10}\")\n",
    "        \n",
    "        # Get matrices for this ensemble\n",
    "        X_i = weight_matrix_3d_notr[i]  # Weighted matrix\n",
    "        C_i = count_matrix_3d_notr[i]   # Count matrix (raw paths)\n",
    "        \n",
    "        # Calculate fractions for anomaly detection\n",
    "        total_X = np.sum(X_i)\n",
    "        total_C = np.sum(C_i)\n",
    "        \n",
    "        if total_X > 0 and total_C > 0:\n",
    "            frac_w = X_i / total_X\n",
    "            frac_c = C_i / total_C\n",
    "            diff_frac = np.abs(frac_w - frac_c)\n",
    "            \n",
    "            # Find significant differences between weighted and raw data\n",
    "            idx_weird_w = np.argwhere(diff_frac >= threshold_w)\n",
    "        else:\n",
    "            idx_weird_w = []\n",
    "            diff_frac = np.zeros_like(X_i)\n",
    "        \n",
    "        # Calculate time-reversal symmetry violations\n",
    "        X_sym = (X_i + X_i.T) / 2.0\n",
    "        tr_diff = np.zeros_like(X_i)\n",
    "        \n",
    "        # Only calculate TR differences for non-zero entries\n",
    "        mask = (X_i + X_i.T) > 0\n",
    "        tr_diff[mask] = np.abs(X_i[mask] - X_i.T[mask]) / X_sym[mask]\n",
    "        \n",
    "        idx_tr = np.argwhere(tr_diff >= threshold_tr)\n",
    "        # Remove duplicates (only keep lower triangle)\n",
    "        idx_tr = [(min(a, b), max(a, b)) for a, b in idx_tr]\n",
    "        idx_tr = list(set(idx_tr))\n",
    "        \n",
    "        # 1. Raw unweighted path counts\n",
    "        print(f\"\\n1a. Raw data: unweighted count matrix C[{i}] (notr)\")\n",
    "        print(np.array2string(C_i, precision=1, suppress_small=True))\n",
    "        \n",
    "        # 2. Weighted data\n",
    "        print(f\"\\n1b. Weighted data: X[{i}] (notr)\")\n",
    "        print(np.array2string(X_i, precision=4, suppress_small=True))\n",
    "        print(f\"Total weight ensemble {i}: {np.sum(X_i):.4f}\")\n",
    "        \n",
    "        # Warnings for significant differences between weighted and raw data\n",
    "        if len(idx_weird_w) > 0:\n",
    "            print(f\"\\n[WARNING] Significant differences between weighted and raw data (≥{threshold_w:.1%}):\")\n",
    "            for idx in idx_weird_w:\n",
    "                j, k = idx[0], idx[1]\n",
    "                print(f\"  Path {j} → {k}: raw count={C_i[j, k]:.1f}, \"\n",
    "                      f\"weighted={X_i[j, k]:.4f}, \"\n",
    "                      f\"fraction diff={diff_frac[j, k]:.4f}\")\n",
    "        \n",
    "        # 3. Time-reversal symmetry analysis (if applied)\n",
    "        if tr_applied:\n",
    "            print(f\"\\n2a. Time-reversal symmetrized count matrix C_tr[{i}]:\")\n",
    "            C_sym = (C_i + C_i.T) / 2.0\n",
    "            print(np.array2string(C_sym, precision=1, suppress_small=True))\n",
    "            \n",
    "            print(f\"\\n2b. Time-reversal symmetrized weight matrix X_tr[{i}]:\")\n",
    "            print(np.array2string(X_sym, precision=4, suppress_small=True))\n",
    "            \n",
    "            # Warnings for time-reversal symmetry violations\n",
    "            if len(idx_tr) > 0:\n",
    "                print(f\"\\n[WARNING] Time-reversal symmetry violations (≥{threshold_tr:.1%}):\")\n",
    "                for idx in idx_tr:\n",
    "                    j, k = idx[0], idx[1]\n",
    "                    print(f\"  Path {j} ↔ {k}: relative diff={tr_diff[j, k]:.4f}, \"\n",
    "                          f\"forward weight={X_i[j, k]:.4f}, \"\n",
    "                          f\"backward weight={X_i[k, j]:.4f}\")\n",
    "        else:\n",
    "            print(f\"\\n2. Time-reversal symmetry not applied for this analysis\")\n",
    "        \n",
    "        # Warning for insufficient sampling at interfaces\n",
    "        total_weight = np.sum(X_i)\n",
    "        if total_weight > 0:\n",
    "            col_sums = np.sum(X_i, axis=0)\n",
    "            row_sums = np.sum(X_i, axis=1)\n",
    "            n_cols = X_i.shape[1]\n",
    "            threshold_sampling = total_weight / (5 * n_cols)  # 20% of average\n",
    "            \n",
    "            low_cols = np.where(col_sums < threshold_sampling)[0]\n",
    "            low_rows = np.where(row_sums < threshold_sampling)[0]\n",
    "            \n",
    "            if len(low_cols) > 0:\n",
    "                print(f\"\\n[WARNING] Interfaces with insufficient sampling (incoming):\")\n",
    "                for col in low_cols:\n",
    "                    print(f\"  Interface {col}: incoming weight={col_sums[col]:.4f}, \"\n",
    "                          f\"only {(col_sums[col]/total_weight)*100:.1f}% of total \"\n",
    "                          f\"(threshold: {threshold_sampling:.4f})\")\n",
    "            \n",
    "            if len(low_rows) > 0:\n",
    "                print(f\"\\n[WARNING] Interfaces with insufficient sampling (outgoing):\")\n",
    "                for row in low_rows:\n",
    "                    print(f\"  Interface {row}: outgoing weight={row_sums[row]:.4f}, \"\n",
    "                          f\"only {(row_sums[row]/total_weight)*100:.1f}% of total \"\n",
    "                          f\"(threshold: {threshold_sampling:.4f})\")\n",
    "    \n",
    "    # Combined statistics across all ensembles\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(\"ALL ENSEMBLES COMBINED\")\n",
    "    print(f\"{'-'*20}\")\n",
    "    \n",
    "    # Combined weight matrix (already calculated)\n",
    "    print(f\"\\n3a. Combined weight matrix (sum over all ensembles, notr):\")\n",
    "    print(\"Rows = start interface, Columns = end interface\")\n",
    "    print(np.array2string(weight_matrix_2d, precision=4, suppress_small=True))\n",
    "    \n",
    "    # Combined count matrix\n",
    "    combined_count_matrix = np.zeros_like(weight_matrix_2d)\n",
    "    for i in range(n_ensembles):\n",
    "        combined_count_matrix += count_matrix_3d[i]\n",
    "    \n",
    "    print(f\"\\n3b. Combined count matrix (sum over all ensembles, notr):\")\n",
    "    print(\"Rows = start interface, Columns = end interface\")\n",
    "    print(np.array2string(combined_count_matrix, precision=1, suppress_small=True))\n",
    "    \n",
    "    # Combined with time-reversal symmetry\n",
    "    if tr_applied:\n",
    "        weight_matrix_2d_tr = (weight_matrix_2d + weight_matrix_2d.T) / 2.0\n",
    "        combined_count_matrix_tr = (combined_count_matrix + combined_count_matrix.T) / 2.0\n",
    "        \n",
    "        print(f\"\\n4a. Combined weight matrix with time-reversal symmetry:\")\n",
    "        print(np.array2string(weight_matrix_2d_tr, precision=4, suppress_small=True))\n",
    "        \n",
    "        print(f\"\\n4b. Combined count matrix with time-reversal symmetry:\")\n",
    "        print(np.array2string(combined_count_matrix_tr, precision=1, suppress_small=True))\n",
    "    \n",
    "    # Overall statistics\n",
    "    transition_summary = weight_matrices_result.get('transition_summary', {})\n",
    "    total_weight = transition_summary.get('total_weight', np.sum(weight_matrix_2d))\n",
    "    \n",
    "    print(f\"\\n=== OVERALL STATISTICS ===\")\n",
    "    print(f\"Total weight across all ensembles: {total_weight:.4f}\")\n",
    "    print(f\"Total transitions: {transition_summary.get('total_transitions', 0)}\")\n",
    "    print(f\"Non-zero matrix elements: {np.count_nonzero(weight_matrix_2d)}/{n_interfaces*n_interfaces}\")\n",
    "    \n",
    "    # Transition type breakdown\n",
    "    if transition_summary:\n",
    "        print(f\"\\nTransition breakdown:\")\n",
    "        print(f\"• Forward (j<k):  {transition_summary.get('forward_weight', 0):.4f} \"\n",
    "              f\"({transition_summary.get('forward_weight_fraction', 0):.1%})\")\n",
    "        print(f\"• Backward (j>k): {transition_summary.get('backward_weight', 0):.4f} \"\n",
    "              f\"({transition_summary.get('backward_weight_fraction', 0):.1%})\")\n",
    "        print(f\"• Self (j=k):     {transition_summary.get('self_weight', 0):.4f} \"\n",
    "              f\"({transition_summary.get('self_weight_fraction', 0):.1%})\")\n",
    "    \n",
    "    # Interface activity analysis\n",
    "    print(f\"\\nInterface activity analysis:\")\n",
    "    interface_activity = np.sum(weight_matrix_2d, axis=0) + np.sum(weight_matrix_2d, axis=1)\n",
    "    for i, activity in enumerate(interface_activity):\n",
    "        print(f\"  Interface {i}: total activity = {activity:.4f} \"\n",
    "              f\"({(activity/np.sum(interface_activity))*100:.1f}% of total)\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Analysis complete. Check warnings above for potential issues.\")\n",
    "\n",
    "print(\"Function display_data_infretis successfully defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ed595f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iSTAR matrix construction functions defined successfully!\n"
     ]
    }
   ],
   "source": [
    "def construct_istar_transition_matrix(P: np.ndarray, N: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Construct the iSTAR transition matrix M from interface-to-interface transition probabilities.\n",
    "    \n",
    "    This implements the iSTAR model structure where states are defined at each interface\n",
    "    with special handling for boundary states.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    P : np.ndarray\n",
    "        Array of probabilities for paths between interfaces. P[i,j] represents the \n",
    "        probability of a path transitioning from interface i to interface j.\n",
    "    N : int\n",
    "        Number of interfaces in the system.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    np.ndarray\n",
    "        Transition matrix M for the iSTAR model with dimensions (2*N, 2*N).\n",
    "    \"\"\"\n",
    "    NS = 2 * N  # Dimension of the Markov state model\n",
    "    \n",
    "    # Validate input dimensions\n",
    "    if P.shape[0] != N or P.shape[1] != N:\n",
    "        raise ValueError(f\"P matrix dimensions {P.shape} don't match N={N}\")\n",
    "    \n",
    "    # Construct transition matrix\n",
    "    M = np.zeros((NS, NS))\n",
    "    \n",
    "    # States [0-] and [0*+-] - special boundary handling\n",
    "    M[0, 2] = 1            # Transition from state 0 to state 2\n",
    "    M[2, 0] = P[0, 0]      # Transition from state 2 to state 0\n",
    "    M[2, N+1:] = P[0, 1:]  # Transitions from state 2 to states N+1 and beyond\n",
    "    M[1, 0] = 1            # Transition from state 1 to state 0\n",
    "    M[-1, 0] = 1           # Transition from last state to state 0\n",
    "    \n",
    "    # Transitions from intermediate states to boundary\n",
    "    if N > 1:\n",
    "        M[N+1:-1, 1] = P[1:-1, 0]  # Transitions to state 1\n",
    "    \n",
    "    # Set up transitions for other interfaces\n",
    "    for i in range(1, N-1):\n",
    "        # Forward transitions\n",
    "        if i < N-1:\n",
    "            M[N+i, N+i+1:] = P[i, i+1:]\n",
    "        # Backward transitions\n",
    "        if i > 0:\n",
    "            M[N+i, N+1:N+i] = P[i, 1:i]\n",
    "    \n",
    "    # Handle the last interface (special case)\n",
    "    if N > 1:\n",
    "        M[N, -1] = P[N-1, N-1] if N-1 < P.shape[1] else 0  # Self-transition or to absorbing state\n",
    "    \n",
    "    # Ensure matrix is properly stochastic (rows sum to 1)\n",
    "    for i in range(NS):\n",
    "        row_sum = np.sum(M[i, :])\n",
    "        if row_sum == 0:\n",
    "            M[i, i] = 1  # Set diagonal entry to 1 for rows that sum to zero\n",
    "        elif row_sum > 0 and not np.isclose(row_sum, 1.0):\n",
    "            M[i, :] /= row_sum  # Normalize to ensure stochastic matrix\n",
    "    \n",
    "    print(f\"Constructed iSTAR transition matrix with shape {M.shape}\")\n",
    "    print(f\"Matrix properties:\")\n",
    "    print(f\"- Row sums: {[np.sum(M[i, :]) for i in range(min(5, NS))]}\")\n",
    "    print(f\"- Non-zero entries: {np.count_nonzero(M)}/{NS*NS}\")\n",
    "    \n",
    "    return M\n",
    "\n",
    "def global_pcross_istar(M: np.ndarray, doprint: bool = False) -> Tuple:\n",
    "    \"\"\"\n",
    "    Calculate global crossing probabilities from a transition matrix using the iSTAR approach.\n",
    "    \n",
    "    This function computes the probability to arrive at state -1 before reaching state 0,\n",
    "    given that we start at state 0 and leave it.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    M : np.ndarray\n",
    "        Transition matrix representing the Markov state model\n",
    "    doprint : bool\n",
    "        If True, prints detailed calculation information\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        (z1, z2, y1, y2) - solution vectors from the iSTAR calculation\n",
    "    \"\"\"\n",
    "    NS = len(M)\n",
    "    if NS <= 2:\n",
    "        print(\"Warning: Matrix too small for meaningful iSTAR analysis\")\n",
    "        return None, None, None, None\n",
    "    \n",
    "    # Extract submatrices from the transition matrix\n",
    "    Mp = M[2:-1, 2:-1]  # Transition probabilities between intermediate states\n",
    "    a = np.identity(NS-3) - Mp  # I - Mp, used for solving linear system\n",
    "    \n",
    "    # Extract other submatrices from the transition matrix\n",
    "    D = M[2:-1, np.array([0, -1])]  # Transitions from intermediate states to boundary states\n",
    "    E = M[np.array([0, -1]), 2:-1]  # Transitions from boundary states to intermediate states\n",
    "    M11 = M[np.array([0, -1]), np.array([0, -1])]  # Transitions between boundary states\n",
    "    \n",
    "    # Compute Z vector - solve the linear system\n",
    "    z1 = np.array([[0], [1]])  # Initial condition\n",
    "    try:\n",
    "        z2 = np.linalg.solve(a, np.dot(D, z1))  # Solve (I-Mp)z2 = D·z1\n",
    "    except np.linalg.LinAlgError:\n",
    "        print(\"Warning: Singular matrix encountered in iSTAR calculation\")\n",
    "        return None, None, None, None\n",
    "    \n",
    "    # Compute H vector - final probability distribution\n",
    "    y1 = np.dot(M11, z1) + np.dot(E, z2)  # Transitions to boundary states\n",
    "    y2 = np.dot(D, z1) + np.dot(Mp, z2)   # Transitions to intermediate states\n",
    "    \n",
    "    if doprint:\n",
    "        print(\"iSTAR calculation details:\")\n",
    "        print(f\"Intermediate states matrix Mp shape: {Mp.shape}\")\n",
    "        print(f\"Boundary transition matrix D shape: {D.shape}\")\n",
    "        print(f\"z1 (boundary conditions): {z1.flatten()}\")\n",
    "        print(f\"z2 (intermediate solutions): {z2.flatten()}\")\n",
    "        print(f\"y1 (boundary probabilities): {y1.flatten()}\")\n",
    "        print(f\"Global crossing probability: {y1[1, 0] if y1.shape[0] > 1 else 'N/A'}\")\n",
    "    \n",
    "    return z1, z2, y1, y2\n",
    "\n",
    "print(\"iSTAR matrix construction functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1fec66ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binless crossing probability and plotting functions defined successfully!\n"
     ]
    }
   ],
   "source": [
    "def calculate_binless_pcross(weight_results: Dict) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Calculate binless crossing probability from infretis weights.\n",
    "    \n",
    "    This is based on the method in path_weights.py and provides a direct\n",
    "    calculation of the crossing probability curve.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    weight_results : Dict\n",
    "        Results from calculate_infretis_weights function\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        (order_params, pcross_values) - arrays for plotting/analysis\n",
    "    \"\"\"\n",
    "    D = weight_results['path_data']\n",
    "    A = weight_results['unbiased_weights']\n",
    "    interfaces = weight_results['interfaces']\n",
    "    \n",
    "    # Sort paths by maximum order parameter\n",
    "    idx = np.argsort(D[\"maxop\"].flatten())\n",
    "    maxop_sorted = D[\"maxop\"][idx].flatten()\n",
    "    weight_sorted = A[idx].flatten()\n",
    "    sumw = np.sum(weight_sorted)\n",
    "    \n",
    "    # Calculate crossing probability\n",
    "    res_y = [1.0]\n",
    "    res_x = [interfaces[0]]\n",
    "    \n",
    "    for i, moi in enumerate(maxop_sorted):\n",
    "        # Skip duplicate order parameter values\n",
    "        if res_x[-1] == moi:\n",
    "            continue\n",
    "        # Crossing probability = sum of weights of paths that cross this point / total weight\n",
    "        res_y.append(np.sum(weight_sorted[i:]) / sumw)\n",
    "        res_x.append(moi)\n",
    "    \n",
    "    res_x = np.array(res_x)\n",
    "    res_y = np.array(res_y)\n",
    "    \n",
    "    print(f\"Calculated binless crossing probability with {len(res_x)} points\")\n",
    "    print(f\"Order parameter range: {res_x.min():.3f} to {res_x.max():.3f}\")\n",
    "    print(f\"Crossing probability range: {res_y.min():.6f} to {res_y.max():.6f}\")\n",
    "    \n",
    "    return res_x, res_y\n",
    "\n",
    "def plot_pcross_comparison(results_dict: Dict, title: str = \"Crossing Probability Comparison\"):\n",
    "    \"\"\"\n",
    "    Plot comparison of different crossing probability calculations.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    results_dict : Dict\n",
    "        Dictionary containing different pcross calculations with keys:\n",
    "        - 'binless': (x, y) tuple from binless calculation\n",
    "        - 'istar': global crossing probability from iSTAR\n",
    "        - 'interfaces': interface positions\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Plot binless crossing probability\n",
    "    if 'binless' in results_dict:\n",
    "        x_binless, y_binless = results_dict['binless']\n",
    "        plt.semilogy(x_binless, y_binless, 'b-', linewidth=2, label='Binless (infretis weights)')\n",
    "    \n",
    "    # Plot interfaces\n",
    "    if 'interfaces' in results_dict:\n",
    "        interfaces = results_dict['interfaces']\n",
    "        for i, intf in enumerate(interfaces):\n",
    "            plt.axvline(intf, color='black', linestyle='--', alpha=0.7, linewidth=1)\n",
    "            plt.text(intf, 0.5, f'λ_{i}', rotation=90, verticalalignment='center')\n",
    "    \n",
    "    # Add iSTAR global crossing probability if available\n",
    "    if 'istar_global' in results_dict:\n",
    "        istar_pcross = results_dict['istar_global']\n",
    "        plt.axhline(istar_pcross, color='red', linestyle='-', linewidth=2, \n",
    "                   label=f'iSTAR Global P_cross = {istar_pcross:.6f}')\n",
    "    \n",
    "    plt.xlabel('Order Parameter (λ)')\n",
    "    plt.ylabel('Crossing Probability P(λ)')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.ylim(1e-6, 1.1)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"Binless crossing probability and plotting functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b81c9b",
   "metadata": {},
   "source": [
    "## Data Loading and Configuration\n",
    "\n",
    "In this section, we'll load the infretis simulation data and configure the analysis parameters. The example uses the test data from the double-well system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f1c9a4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data generation functions updated with correct ptype format!\n"
     ]
    }
   ],
   "source": [
    "def create_test_data_with_ptype(filename: str, n_paths: int = 50, n_interfaces: int = 4):\n",
    "    \"\"\"\n",
    "    Create test infretis_data.txt with ptype information for demonstration.\n",
    "    \n",
    "    This generates synthetic data with the correct aXMXb ptype format where:\n",
    "    - a = start interface index\n",
    "    - b = end interface index  \n",
    "    - X can be L or R (representing left/right movement)\n",
    "    - direction = 1 if a < b, -1 if a > b, random if a == b\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    filename : str\n",
    "        Output filename for the test data\n",
    "    n_paths : int\n",
    "        Number of paths to generate\n",
    "    n_interfaces : int\n",
    "        Number of interfaces\n",
    "    \"\"\"\n",
    "    import random\n",
    "    \n",
    "    interfaces = [-1.0, -0.5, 0.0, 0.5, 1.0][:n_interfaces+1]  # Example interface positions\n",
    "    \n",
    "    with open(filename, 'w') as f:\n",
    "        # Write header\n",
    "        f.write(\"# Test data with ptype information\\n\")\n",
    "        f.write(\"# path_nr\\tlength\\tmaxop\\tptype\\t\")\n",
    "        f.write(\"\\t\".join([f\"ens{i:03d}\" for i in range(n_interfaces)]))\n",
    "        f.write(\"\\t\")\n",
    "        f.write(\"\\t\".join([f\"wgt{i:03d}\" for i in range(n_interfaces)]))\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "        # Generate synthetic paths\n",
    "        for path_nr in range(n_paths):\n",
    "            # Random path properties\n",
    "            length = random.randint(10, 100)\n",
    "            \n",
    "            # Random start and end interfaces\n",
    "            start_intf = random.randint(0, n_interfaces-1)\n",
    "            end_intf = random.randint(0, n_interfaces-1)\n",
    "            \n",
    "            # Create ptype in correct aXMXb format from conv_inf_py.py\n",
    "            if start_intf == 0 and end_intf == 0:\n",
    "                # Simple format for ensemble 0\n",
    "                ptype = random.choice(['RMR', 'RML', 'LMR', 'LML'])\n",
    "            else:\n",
    "                # Complex format with interface indices\n",
    "                # Choose random middle part\n",
    "                middle_parts = ['LMR', 'RML', 'LML', 'RMR']\n",
    "                middle = random.choice(middle_parts)\n",
    "                ptype = f\"{start_intf}{middle}{end_intf}\"\n",
    "            \n",
    "            # Maximum order parameter should be consistent with the path\n",
    "            if end_intf >= start_intf:  # Forward path\n",
    "                maxop = random.uniform(interfaces[start_intf], interfaces[end_intf+1] if end_intf < len(interfaces)-1 else 1.5)\n",
    "            else:  # Backward path\n",
    "                maxop = random.uniform(interfaces[end_intf], interfaces[start_intf+1] if start_intf < len(interfaces)-1 else 1.5)\n",
    "            \n",
    "            # Generate ensemble data (path_f and path_w)\n",
    "            path_f = []\n",
    "            path_w = []\n",
    "            \n",
    "            for i in range(n_interfaces):\n",
    "                if i == start_intf:\n",
    "                    # Path contributes to starting ensemble\n",
    "                    f_val = random.uniform(0.5, 2.0)\n",
    "                    w_val = random.uniform(0.5, 2.0)\n",
    "                    path_f.append(f_val)\n",
    "                    path_w.append(w_val)\n",
    "                else:\n",
    "                    # No contribution to other ensembles\n",
    "                    path_f.append(\"----\")\n",
    "                    path_w.append(\"----\")\n",
    "            \n",
    "            # Write path data\n",
    "            f.write(f\"{path_nr}\\t{length}\\t{maxop:.5f}\\t{ptype}\\t\")\n",
    "            f.write(\"\\t\".join([str(x) for x in path_f]))\n",
    "            f.write(\"\\t\")\n",
    "            f.write(\"\\t\".join([str(x) for x in path_w]))\n",
    "            f.write(\"\\n\")\n",
    "    \n",
    "    print(f\"Created test data file: {filename}\")\n",
    "    print(f\"Generated {n_paths} paths with {n_interfaces} interfaces\")\n",
    "    print(f\"File includes ptype information in correct aXMXb format\")\n",
    "\n",
    "# Test if we want to demonstrate with synthetic data\n",
    "def test_ptype_format():\n",
    "    \"\"\"Test the ptype format parsing with synthetic data\"\"\"\n",
    "    test_file = \"test_infretis_data_with_ptype.txt\"\n",
    "    create_test_data_with_ptype(test_file, n_paths=20, n_interfaces=3)\n",
    "    \n",
    "    # Show first few lines\n",
    "    with open(test_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    print(\"\\nFirst few lines of generated test data:\")\n",
    "    for i, line in enumerate(lines[:8]):\n",
    "        print(f\"{i+1}: {line.strip()}\")\n",
    "    \n",
    "    return test_file\n",
    "\n",
    "print(\"Test data generation functions updated with correct ptype format!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c81eed51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "Data directory: /mnt/0bf0c339-34bb-4500-a5fb-f3c2a863de29/DATA/APPTIS/infretis/examples/ase/staple_flat_walls_br\n",
      "TOML file: /mnt/0bf0c339-34bb-4500-a5fb-f3c2a863de29/DATA/APPTIS/infretis/examples/ase/staple_flat_walls_br/infretis.toml\n",
      "Data file: /mnt/0bf0c339-34bb-4500-a5fb-f3c2a863de29/DATA/APPTIS/infretis/examples/ase/staple_flat_walls_br/infretis_data.txt\n",
      "✓ TOML file found\n",
      "✓ Data file found\n",
      "  - Total lines: 40200\n",
      "  - First few lines:\n",
      "    1: # ==========================================================================\n",
      "    2: # \txxx\tlen\tmax OP\t\t000\t001\t002\t003\t004\n",
      "    3: # ==========================================================================\n",
      "    4: 3\t 1170\t 0.30010\t-0.10011\t0LMR4\t----\t----\t----\t----\t----\t----\t----\t----\t----\t----\t('ld', nan, 0, 0)\t2\n",
      "    5: 0\t 3021\t-0.09986\t-0.36087\tRMR\t1.0\t----\t----\t----\t----\t1.0\t----\t----\t----\t----\t('ld', nan, 0, 0)\t-1\n",
      "\\nUsing standard data format (no ptype information)\n",
      "Set USE_TEST_PTYPE_DATA = True to demonstrate ptype functionality\n"
     ]
    }
   ],
   "source": [
    "# Configuration for the analysis\n",
    "# DATA_DIR = \"/mnt/0bf0c339-34bb-4500-a5fb-f3c2a863de29/DATA/APPTIS/inftools/test/test_staple\"\n",
    "# DATA_DIR = \"/mnt/0bf0c339-34bb-4500-a5fb-f3c2a863de29/DATA/APPTIS/infretis/examples/ase/staple_flat_walls_ase\"\n",
    "DATA_DIR = \"/mnt/0bf0c339-34bb-4500-a5fb-f3c2a863de29/DATA/APPTIS/infretis/examples/ase/staple_flat_walls_br\"\n",
    "# DATA_DIR = \"/mnt/0bf0c339-34bb-4500-a5fb-f3c2a863de29/DATA/APPTIS/infretis/examples/ase/staple_flat_walls_br_0swnoinf\"\n",
    "\n",
    "TOML_FILE = f\"{DATA_DIR}/infretis.toml\"\n",
    "DATA_FILE = f\"{DATA_DIR}/infretis_data.txt\"\n",
    "# DATA_FILE = f\"{DATA_DIR}/2308noinfswap_data.txt\"\n",
    "\n",
    "# Analysis parameters\n",
    "NSKIP = 0  # Number of initial entries to skip\n",
    "VERBOSE = True\n",
    "USE_TEST_PTYPE_DATA = False  # Set to True to demonstrate ptype functionality\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "print(f\"TOML file: {TOML_FILE}\")\n",
    "print(f\"Data file: {DATA_FILE}\")\n",
    "\n",
    "# Check if files exist\n",
    "import os\n",
    "if os.path.exists(TOML_FILE):\n",
    "    print(\"✓ TOML file found\")\n",
    "else:\n",
    "    print(\"✗ TOML file not found\")\n",
    "    \n",
    "if os.path.exists(DATA_FILE):\n",
    "    print(\"✓ Data file found\")\n",
    "    # Show basic info about the data file\n",
    "    with open(DATA_FILE, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    print(f\"  - Total lines: {len(lines)}\")\n",
    "    print(f\"  - First few lines:\")\n",
    "    for i, line in enumerate(lines[:5]):\n",
    "        print(f\"    {i+1}: {line.strip()}\")\n",
    "else:\n",
    "    print(\"✗ Data file not found\")\n",
    "\n",
    "# Option to demonstrate ptype functionality\n",
    "if USE_TEST_PTYPE_DATA:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(\"DEMONSTRATING PTYPE FUNCTIONALITY\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Create test data with ptype information\n",
    "    test_data_file = test_ptype_format()\n",
    "    \n",
    "    # Create a simple TOML config for the test\n",
    "    test_toml_content = '''\n",
    "    [simulation]\n",
    "    interfaces = [-1.0, -0.5, 0.0, 0.5]\n",
    "    '''\n",
    "    \n",
    "    test_toml_file = \"test_infretis.toml\"\n",
    "    with open(test_toml_file, 'w') as f:\n",
    "        f.write(test_toml_content)\n",
    "    \n",
    "    print(f\"\\\\nSwitching to test data for ptype demonstration:\")\n",
    "    print(f\"Test TOML file: {test_toml_file}\")\n",
    "    print(f\"Test data file: {test_data_file}\")\n",
    "    \n",
    "    # Override the configuration\n",
    "    TOML_FILE = test_toml_file\n",
    "    DATA_FILE = test_data_file\n",
    "    \n",
    "    print(\"\\\\n✓ Test configuration ready for ptype demonstration\")\n",
    "else:\n",
    "    print(f\"\\\\nUsing standard data format (no ptype information)\")\n",
    "    print(f\"Set USE_TEST_PTYPE_DATA = True to demonstrate ptype functionality\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1444f7ba",
   "metadata": {},
   "source": [
    "## Step 1: Calculate Infretis Weights\n",
    "\n",
    "First, we calculate the unbiased weights for all paths using the infretis methodology. This is the key improvement over the old workflow - using proper infretis weights instead of simple path counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f27d463e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA FORMAT ANALYSIS ===\n",
      "Data shape: (10, 16)\n",
      "Number of columns: 16\n",
      "Found ptype pattern '0LMR4' in column 4, row 0\n",
      "  -> Start interface: 0, End interface: 4, Middle: LMR, Direction: 1\n",
      "Found ptype pattern 'RMR' in column 4, row 1\n",
      "  -> Simple ptype format, Direction: 1\n",
      "Found ptype pattern '0LMR1' in column 4, row 2\n",
      "  -> Start interface: 0, End interface: 1, Middle: LMR, Direction: 1\n",
      "Found ptype pattern '0LMR4' in column 4, row 3\n",
      "  -> Start interface: 0, End interface: 4, Middle: LMR, Direction: 1\n",
      "Found ptype pattern '2RMR4' in column 4, row 4\n",
      "  -> Start interface: 2, End interface: 4, Middle: RMR, Direction: 1\n",
      "Found ptype pattern 'RMR' in column 4, row 5\n",
      "  -> Simple ptype format, Direction: 1\n",
      "Found ptype pattern 'RMR' in column 4, row 6\n",
      "  -> Simple ptype format, Direction: 1\n",
      "Found ptype pattern 'RMR' in column 4, row 7\n",
      "  -> Simple ptype format, Direction: 1\n",
      "Found ptype pattern 'RMR' in column 4, row 8\n",
      "  -> Simple ptype format, Direction: 1\n",
      "Found ptype pattern '0LML0' in column 4, row 9\n",
      "  -> Start interface: 0, End interface: 0, Middle: LML, Direction: 1\n",
      "\n",
      "Ptype examples found: ['2RMR4', '0LMR1', '0LML0', '0LMR4', 'RMR']\n",
      "\n",
      "Data preview (first 3 rows):\n",
      "Row 0: ['3' '1170' '0.30010' '-0.10011' '0LMR4' '----' '----' '----' '----'\n",
      " '----' '----' '----' '----' '----' '----' \"('ld',\"]\n",
      "Row 1: ['0' '3021' '-0.09986' '-0.36087' 'RMR' '1.0' '----' '----' '----' '----'\n",
      " '1.0' '----' '----' '----' '----' \"('ld',\"]\n",
      "Row 2: ['1' '1816' '0.00423' '-0.10015' '0LMR1' '----' '0.5' '0.5' '----' '----'\n",
      " '----' '1.0' '1.0' '----' '----' \"('ld',\"]\n",
      "\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_834146/3373521962.py:6: UserWarning: Input line 1 contained no data and will not be counted towards `max_rows=10`.  This differs from the behaviour in NumPy <=1.22 which counted lines rather than rows.  If desired, the previous behaviour can be achieved by using `itertools.islice`.\n",
      "Please see the 1.23 release notes for an example on how to do this.  If you wish to ignore this warning, use `warnings.filterwarnings`.  This warning is expected to be removed in the future and is given only once per `loadtxt` call.\n",
      "  data_sample = np.loadtxt(DATA_FILE, dtype=str, max_rows=10, usecols=np.arange(16))\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate format detection and ptype parsing\n",
    "print(\"=== DATA FORMAT ANALYSIS ===\")\n",
    "\n",
    "# Load and analyze the data format\n",
    "try:\n",
    "    data_sample = np.loadtxt(DATA_FILE, dtype=str, max_rows=10, usecols=np.arange(16)) \n",
    "    print(f\"Data shape: {data_sample.shape}\")\n",
    "    print(f\"Number of columns: {data_sample.shape[1]}\")\n",
    "    \n",
    "    # Check for ptype patterns - correct pattern from conv_inf_py.py\n",
    "    import re\n",
    "    ptype_found = False\n",
    "    ptype_examples = []\n",
    "    \n",
    "    for col in range(data_sample.shape[1]):\n",
    "        for row in range(data_sample.shape[0]):\n",
    "            val = data_sample[row, col]\n",
    "            # Look for patterns like \"0LMR4\", \"10RML12\", or simple \"RMR\", \"LML\" etc.\n",
    "            if isinstance(val, str) and (re.match(r'\\d+[LR]M[LR]\\d+', val) or val in ['RMR', 'RML', 'LMR', 'LML']):\n",
    "                ptype_found = True\n",
    "                ptype_examples.append(val)\n",
    "                print(f\"Found ptype pattern '{val}' in column {col}, row {row}\")\n",
    "                \n",
    "                # Parse and show direction using the correct logic from conv_inf_py.py\n",
    "                if val in ['RMR', 'RML', 'LMR', 'LML']:\n",
    "                    # Simple format (ensemble 0)\n",
    "                    direction = 1\n",
    "                    print(f\"  -> Simple ptype format, Direction: {direction}\")\n",
    "                else:\n",
    "                    # Complex format with interface indices\n",
    "                    match = re.match(r'^(\\d+)([LR]M[LR])(\\d+)$', val)\n",
    "                    if match:\n",
    "                        a = int(match.group(1))  # First interface index\n",
    "                        b = int(match.group(3))  # Last interface index\n",
    "                        middle_part = match.group(2)  # XMX part\n",
    "                        \n",
    "                        if a < b:\n",
    "                            direction = 1\n",
    "                        elif a > b:\n",
    "                            direction = -1\n",
    "                        else:  # a == b\n",
    "                            direction = 1  # or random choice as in conv file\n",
    "                        \n",
    "                        print(f\"  -> Start interface: {a}, End interface: {b}, Middle: {middle_part}, Direction: {direction}\")\n",
    "    \n",
    "    if not ptype_found:\n",
    "        print(\"No ptype patterns (aXMXb format) detected in the data\")\n",
    "        print(\"This data uses the standard infretis format\")\n",
    "    else:\n",
    "        print(f\"\\nPtype examples found: {list(set(ptype_examples))}\")\n",
    "    \n",
    "    print(f\"\\nData preview (first 3 rows):\")\n",
    "    for i in range(min(3, data_sample.shape[0])):\n",
    "        print(f\"Row {i}: {data_sample[i]}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error analyzing data format: {e}\")\n",
    "\n",
    "print(f\"\\n{'='*50}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "17516b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STEP 1: CALCULATING INFRETIS WEIGHTS ===\n",
      "Found ptype information in column 4\n",
      "Processed 26582 non-zero paths\n",
      "Interfaces: [-0.1, 0.0, 0.1, 0.2, 0.3]\n",
      "Path type information detected:\n",
      "  Forward paths (dir=1): 14472\n",
      "  Backward paths (dir=-1): 12110\n",
      "  Other paths (dir=0): 0\n",
      "\n",
      "Weight calculation summary:\n",
      "Number of interfaces: 5\n",
      "Interfaces: [-0.1, 0.0, 0.1, 0.2, 0.3]\n",
      "Number of paths processed: 26582\n",
      "\n",
      "Path statistics:\n",
      "Order parameter range: -0.100000 to 0.327900\n",
      "Paths crossing each interface:\n",
      "  λ_0 = -0.100000: 26582 paths\n",
      "  λ_1 = 0.000000: 14590 paths\n",
      "  λ_2 = 0.100000: 12758 paths\n",
      "  λ_3 = 0.200000: 9661 paths\n",
      "  λ_4 = 0.300000: 5985 paths\n",
      "\n",
      "=== STEP 2: COMPUTING WEIGHT MATRICES ===\n",
      "Computing weight matrices for 26582 paths\n",
      "Structure: Dictionary of 2D matrices [ensemble_idx][start_interface, end_interface]\n",
      "Dimensions: 5 ensembles x 5 interfaces x 5 interfaces\n",
      "Following original istar_analysis.py logic with tr=False\n",
      "Using ptype information with direction for istar_analysis-style computation\n",
      "\n",
      "=== 3D WEIGHT MATRICES RESULTS (istar_analysis style) ===\n",
      "3D Matrix dimensions: 5 x 5 x 5\n",
      "Total weight processed: 283732.615079\n",
      "Total transitions: 106324.0\n",
      "Non-zero 3D matrix elements: 52\n",
      "Time-reversal symmetry applied: False\n",
      "\n",
      "Ensemble weight totals:\n",
      "  Sum weights ensemble 0: 0.0000\n",
      "  Sum weights ensemble 1: 62892.5226\n",
      "  Sum weights ensemble 2: 68337.1167\n",
      "  Sum weights ensemble 3: 84020.9790\n",
      "  Sum weights ensemble 4: 68481.9968\n",
      "\n",
      "2D Weight Matrix [start_interface, end_interface] (summed over ensembles):\n",
      "Rows = start interface, Columns = end interface\n",
      "Interface 0: 51623.0000 13961.4952 14255.5131 15388.6774 18551.0000 \n",
      "Interface 1: 671.0000   0.0000 9585.0667 11851.3036 13238.2595 \n",
      "Interface 2: 14376.5702 9727.5000   0.0000 10557.8167 11310.5643 \n",
      "Interface 3: 16596.5817 10937.9262 9401.2833   0.0000   0.0000 \n",
      "Interface 4: 18337.0000 14400.7619 10994.2952 7967.0000   0.0000 \n",
      "\n",
      "Transition Analysis:\n",
      "Forward transitions (j<k):  31828.000000 paths, 118699.6964 weight (41.8%)\n",
      "Backward transitions (j>k): 26528.000000 paths, 113409.9187 weight (40.0%)\n",
      "Self transitions (j=k):     47968.000000 paths, 51623.0000 weight (18.2%)\n",
      "\n",
      "Non-zero 3D matrix entries (first 10):\n",
      "  weights[1,0,0] = 51623.000000 (count: 11992.0)\n",
      "  weights[1,0,1] = 3539.516667 (count: 1729.0)\n",
      "  weights[1,0,2] = 1501.942857 (count: 1153.0)\n",
      "  weights[1,0,3] = 923.140079 (count: 879.0)\n",
      "  weights[1,0,4] = 1009.123413 (count: 1116.0)\n",
      "  weights[1,1,0] = 339.983333 (count: 103.0)\n",
      "  weights[1,2,0] = 1424.004762 (count: 946.0)\n",
      "  weights[1,3,0] = 1156.218254 (count: 752.0)\n",
      "  weights[1,4,0] = 1375.593254 (count: 945.0)\n",
      "  weights[2,0,1] = 10421.978571 (count: 1729.0)\n",
      "Weight matrices computed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Calculate infretis weights\n",
    "print(\"=== STEP 1: CALCULATING INFRETIS WEIGHTS ===\")\n",
    "weight_results = calculate_infretis_weights(DATA_FILE, TOML_FILE, nskip=NSKIP)\n",
    "\n",
    "\n",
    "# Display key results\n",
    "print(\"\\nWeight calculation summary:\")\n",
    "print(f\"Number of interfaces: {len(weight_results['interfaces'])}\")\n",
    "print(f\"Interfaces: {weight_results['interfaces']}\")\n",
    "print(f\"Number of paths processed: {len(weight_results['path_data']['pnr'])}\")\n",
    "# print(f\"Local crossing probabilities (WHAM): {weight_results['ploc_wham']}\")\n",
    "\n",
    "# Show some statistics about the weights\n",
    "# unbiased_weights = weight_results['unbiased_weights']\n",
    "# print(f\"\\nWeight statistics:\")\n",
    "# print(f\"Total weight: {np.sum(unbiased_weights):.6f}\")\n",
    "# print(f\"Average weight: {np.mean(unbiased_weights):.6f}\")\n",
    "# print(f\"Weight range: {np.min(unbiased_weights):.6f} to {np.max(unbiased_weights):.6f}\")\n",
    "\n",
    "# Show path statistics\n",
    "maxops = weight_results['path_data']['maxop'][:, 0]\n",
    "print(f\"\\nPath statistics:\")\n",
    "print(f\"Order parameter range: {np.min(maxops):.6f} to {np.max(maxops):.6f}\")\n",
    "print(f\"Paths crossing each interface:\")\n",
    "for i, intf in enumerate(weight_results['interfaces']):\n",
    "    n_crossing = np.sum(maxops >= intf)\n",
    "    print(f\"  λ_{i} = {intf:.6f}: {n_crossing} paths\")\n",
    "\n",
    "# Compute weight matrices\n",
    "print(\"\\n=== STEP 2: COMPUTING WEIGHT MATRICES ===\")\n",
    "weight_matrices_results = compute_weight_matrices_weights(weight_results, tr=False)\n",
    "w_path = weight_matrices_results['weight_matrix_3d']\n",
    "w_path_2d = weight_matrices_results['weight_matrix_2d']\n",
    "print(\"Weight matrices computed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8e6b735f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== STEP 3: ANALYZING WEIGHT MATRICES ===\n",
      "Warning: Zero count detected for q[3][4] = 0.0, counts = [0. 0.]\n",
      "Warning: Zero count detected for q[4][3] = 0.0, counts = [0. 0.]\n",
      "\n",
      "Intermediate transition probabilities (q matrix):\n",
      "[[1.     0.119  0.5802 0.605  0.5466]\n",
      " [1.     0.     1.     0.6403 0.5276]\n",
      " [0.5711 1.     0.     1.     0.5172]\n",
      " [0.5853 0.6623 1.     0.     0.    ]\n",
      " [0.5408 0.6518 0.6655 1.     0.    ]]\n",
      "\n",
      "Final transition probabilities (p matrix):\n",
      "[[0.881  0.05   0.0273 0.0189 0.0228]\n",
      " [1.     0.     0.3597 0.3024 0.3378]\n",
      " [0.5711 0.4289 0.     0.4828 0.5172]\n",
      " [0.3877 0.2746 0.3377 0.     0.    ]\n",
      " [0.2346 0.1992 0.2317 0.3345 0.    ]]\n",
      "\n",
      "Local crossing probabilities computed successfully\n",
      "iSTAR transition matrix constructed successfully!\n",
      "\n",
      "=== Eigenvalue Analysis ===\n",
      "Mp eigenvalues: [ 0.     -0.5678 -0.2794  0.5678  0.2794  0.      0.    ]\n",
      "(I-Mp) eigenvalues: [1.     0.4322 0.7206 1.5678 1.2794 1.     1.    ]\n",
      "\n",
      "=== Matrix Components ===\n",
      "D (transitions from intermediate to boundary states):\n",
      "[[0.881  0.0228]\n",
      " [0.     0.3378]\n",
      " [0.     0.5172]\n",
      " [0.     0.    ]\n",
      " [0.     0.    ]\n",
      " [0.     0.    ]\n",
      " [0.     0.    ]]\n",
      "\n",
      "E (transitions from boundary to intermediate states):\n",
      "[[1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      "M11 (transitions between boundary states):\n",
      "[0. 0.]\n",
      "\n",
      "=== Solution Vectors ===\n",
      "z1 (boundary states solution):\n",
      "[[0]\n",
      " [1]]\n",
      "\n",
      "z2 (intermediate states solution):\n",
      "[[ 0.0364]\n",
      " [ 0.5371]\n",
      " [ 0.7031]\n",
      " [-0.    ]\n",
      " [ 0.    ]\n",
      " [ 0.2304]\n",
      " [ 0.3849]]\n",
      "\n",
      "=== Result Vectors ===\n",
      "y1 (boundary states result):\n",
      "[[0.0364]\n",
      " [0.    ]]\n",
      "\n",
      "y2 (intermediate states result):\n",
      "[[0.0364]\n",
      " [0.5371]\n",
      " [0.7031]\n",
      " [0.    ]\n",
      " [0.    ]\n",
      " [0.2304]\n",
      " [0.3849]]\n",
      "\n",
      "=== Verification ===\n",
      "||y2-z2||² = 3.081488e-33\n",
      "✓ Verification passed: z2 and y2 are identical (as expected)\n",
      "Global crossing probability (iSTAR): [0.03640884]\n"
     ]
    }
   ],
   "source": [
    "# Analyze using tistools\n",
    "print(\"\\n=== STEP 3: ANALYZING WEIGHT MATRICES ===\")\n",
    "from tistools import get_transition_probs_weights, construct_M_istar, global_pcross_msm_star, ploc_memory, display_data\n",
    "\n",
    "# Construct transition matrix using iSTAR approach\n",
    "p, q = get_transition_probs_weights(weight_matrices_results['weight_matrix_3d'])\n",
    "M_istar = construct_M_istar(p, 2*len(weight_matrices_results['interfaces']), len(weight_matrices_results['interfaces']))\n",
    "print(\"iSTAR transition matrix constructed successfully!\")\n",
    "# Calculate global crossing probability using iSTAR\n",
    "z1, z2, y1, y2 = global_pcross_msm_star(M_istar, doprint=True)\n",
    "istar_global_pcross = y1[0] if y1.shape[0] > 1 else None\n",
    "print(f\"Global crossing probability (iSTAR): {istar_global_pcross}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "de1f8141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interface λ_0: -0.1\n",
      "Computing weight matrices for 108775 paths\n",
      "Structure: Dictionary of 2D matrices [ensemble_idx][start_interface, end_interface]\n",
      "Dimensions: 2 ensembles x 2 interfaces x 2 interfaces\n",
      "Following original istar_analysis.py logic with tr=False\n",
      "Using ptype information with direction for istar_analysis-style computation\n",
      "\n",
      "=== 3D WEIGHT MATRICES RESULTS (istar_analysis style) ===\n",
      "3D Matrix dimensions: 2 x 2 x 2\n",
      "Total weight processed: 199998.000000\n",
      "Total transitions: 74578.0\n",
      "Non-zero 3D matrix elements: 3\n",
      "Time-reversal symmetry applied: False\n",
      "\n",
      "Ensemble weight totals:\n",
      "  Sum weights ensemble 0: 0.0000\n",
      "  Sum weights ensemble 1: 199998.0000\n",
      "\n",
      "2D Weight Matrix [start_interface, end_interface] (summed over ensembles):\n",
      "Rows = start interface, Columns = end interface\n",
      "Interface 0: 172404.0000 18692.0000 \n",
      "Interface 1: 8902.0000   0.0000 \n",
      "\n",
      "Transition Analysis:\n",
      "Forward transitions (j<k):  21543.000000 paths, 18692.0000 weight (9.3%)\n",
      "Backward transitions (j>k): 12406.000000 paths, 8902.0000 weight (4.5%)\n",
      "Self transitions (j=k):     40629.000000 paths, 172404.0000 weight (86.2%)\n",
      "\n",
      "Non-zero 3D matrix entries (first 10):\n",
      "  weights[1,0,0] = 172404.000000 (count: 40629.0)\n",
      "  weights[1,0,1] = 18692.000000 (count: 21543.0)\n",
      "  weights[1,1,0] = 8902.000000 (count: 12406.0)\n",
      "Warning: Zero count detected for q[1][0] = 0.0, counts = [0. 0.]\n",
      "\n",
      "Intermediate transition probabilities (q matrix):\n",
      "[[1.     0.0978]\n",
      " [1.     0.    ]]\n",
      "\n",
      "Final transition probabilities (p matrix):\n",
      "[[0.9022 0.0978]\n",
      " [1.     0.    ]]\n",
      "\n",
      "Local crossing probabilities computed successfully\n",
      "Interface λ_1: 0.0\n",
      "Computing weight matrices for 108775 paths\n",
      "Structure: Dictionary of 2D matrices [ensemble_idx][start_interface, end_interface]\n",
      "Dimensions: 3 ensembles x 3 interfaces x 3 interfaces\n",
      "Following original istar_analysis.py logic with tr=False\n",
      "Using ptype information with direction for istar_analysis-style computation\n",
      "\n",
      "=== 3D WEIGHT MATRICES RESULTS (istar_analysis style) ===\n",
      "3D Matrix dimensions: 3 x 3 x 3\n",
      "Total weight processed: 399981.000000\n",
      "Total transitions: 181998.0\n",
      "Non-zero 3D matrix elements: 10\n",
      "Time-reversal symmetry applied: False\n",
      "\n",
      "Ensemble weight totals:\n",
      "  Sum weights ensemble 0: 0.0000\n",
      "  Sum weights ensemble 1: 199998.0000\n",
      "  Sum weights ensemble 2: 199983.0000\n",
      "\n",
      "2D Weight Matrix [start_interface, end_interface] (summed over ensembles):\n",
      "Rows = start interface, Columns = end interface\n",
      "Interface 0: 172404.0000 55700.0000 62313.0000 \n",
      "Interface 1: 1519.0000   0.0000 24277.0000 \n",
      "Interface 2: 60732.0000 23036.0000   0.0000 \n",
      "\n",
      "Transition Analysis:\n",
      "Forward transitions (j<k):  59610.000000 paths, 142290.0000 weight (35.6%)\n",
      "Backward transitions (j>k): 41130.000000 paths, 85287.0000 weight (21.3%)\n",
      "Self transitions (j=k):     81258.000000 paths, 172404.0000 weight (43.1%)\n",
      "\n",
      "Non-zero 3D matrix entries (first 10):\n",
      "  weights[1,0,0] = 172404.000000 (count: 40629.0)\n",
      "  weights[1,0,1] = 8970.000000 (count: 7317.0)\n",
      "  weights[1,0,2] = 9722.000000 (count: 14226.0)\n",
      "  weights[1,1,0] = 1519.000000 (count: 392.0)\n",
      "  weights[1,2,0] = 7383.000000 (count: 12014.0)\n",
      "  weights[2,0,1] = 46730.000000 (count: 7317.0)\n",
      "  weights[2,0,2] = 52591.000000 (count: 14226.0)\n",
      "  weights[2,1,2] = 24277.000000 (count: 8262.0)\n",
      "  weights[2,2,0] = 53349.000000 (count: 12014.0)\n",
      "  weights[2,2,1] = 23036.000000 (count: 8159.0)\n",
      "Warning: Zero count detected for q[1][0] = 0.0, counts = [0. 0.]\n",
      "Warning: Zero count detected for q[2][1] = 0.0, counts = [0. 0.]\n",
      "\n",
      "Intermediate transition probabilities (q matrix):\n",
      "[[1.     0.0978 0.528 ]\n",
      " [0.     0.     1.    ]\n",
      " [0.6984 1.     0.    ]]\n",
      "\n",
      "Final transition probabilities (p matrix):\n",
      "[[0.9022 0.0462 0.0516]\n",
      " [0.     0.     1.    ]\n",
      " [0.6984 0.3016 0.    ]]\n",
      "\n",
      "Local crossing probabilities computed successfully\n",
      "Interface λ_2: 0.1\n",
      "Computing weight matrices for 108775 paths\n",
      "Structure: Dictionary of 2D matrices [ensemble_idx][start_interface, end_interface]\n",
      "Dimensions: 4 ensembles x 4 interfaces x 4 interfaces\n",
      "Following original istar_analysis.py logic with tr=False\n",
      "Using ptype information with direction for istar_analysis-style computation\n",
      "\n",
      "=== 3D WEIGHT MATRICES RESULTS (istar_analysis style) ===\n",
      "3D Matrix dimensions: 4 x 4 x 4\n",
      "Total weight processed: 599977.000000\n",
      "Total transitions: 311025.0\n",
      "Non-zero 3D matrix elements: 26\n",
      "Time-reversal symmetry applied: False\n",
      "\n",
      "Ensemble weight totals:\n",
      "  Sum weights ensemble 0: 0.0000\n",
      "  Sum weights ensemble 1: 199998.0000\n",
      "  Sum weights ensemble 2: 199983.0000\n",
      "  Sum weights ensemble 3: 199996.0000\n",
      "\n",
      "2D Weight Matrix [start_interface, end_interface] (summed over ensembles):\n",
      "Rows = start interface, Columns = end interface\n",
      "Interface 0: 172404.0000 55700.0000 41801.0000 62090.0000 \n",
      "Interface 1: 1519.0000   0.0000 22039.0000 37813.0000 \n",
      "Interface 2: 41682.0000 21902.0000   0.0000 23783.0000 \n",
      "Interface 3: 59125.0000 35354.0000 24765.0000   0.0000 \n",
      "\n",
      "Transition Analysis:\n",
      "Forward transitions (j<k):  108465.000000 paths, 243226.0000 weight (40.5%)\n",
      "Backward transitions (j>k): 80673.000000 paths, 184347.0000 weight (30.7%)\n",
      "Self transitions (j=k):     121887.000000 paths, 172404.0000 weight (28.7%)\n",
      "\n",
      "Non-zero 3D matrix entries (first 10):\n",
      "  weights[1,0,0] = 172404.000000 (count: 40629.0)\n",
      "  weights[1,0,1] = 8970.000000 (count: 7317.0)\n",
      "  weights[1,0,2] = 4658.000000 (count: 4987.0)\n",
      "  weights[1,0,3] = 5064.000000 (count: 9239.0)\n",
      "  weights[1,1,0] = 1519.000000 (count: 392.0)\n",
      "  weights[1,2,0] = 3811.000000 (count: 4054.0)\n",
      "  weights[1,3,0] = 3572.000000 (count: 7960.0)\n",
      "  weights[2,0,1] = 46730.000000 (count: 7317.0)\n",
      "  weights[2,0,2] = 24718.000000 (count: 4987.0)\n",
      "  weights[2,0,3] = 27873.000000 (count: 9239.0)\n",
      "Warning: Zero count detected for q[1][0] = 0.0, counts = [0. 0.]\n",
      "Warning: Zero count detected for q[3][2] = 0.0, counts = [0. 0.]\n",
      "\n",
      "Intermediate transition probabilities (q matrix):\n",
      "[[1.     0.0978 0.528  0.5976]\n",
      " [0.     0.     1.     0.6318]\n",
      " [0.6336 1.     0.     1.    ]\n",
      " [0.6111 0.6733 1.     0.    ]]\n",
      "\n",
      "Final transition probabilities (p matrix):\n",
      "[[0.9022 0.0462 0.0208 0.0309]\n",
      " [0.     0.     0.3682 0.6318]\n",
      " [0.6336 0.3664 0.     1.    ]\n",
      " [0.4115 0.2619 0.3267 0.    ]]\n",
      "\n",
      "Local crossing probabilities computed successfully\n",
      "Interface λ_3: 0.2\n",
      "Computing weight matrices for 108775 paths\n",
      "Structure: Dictionary of 2D matrices [ensemble_idx][start_interface, end_interface]\n",
      "Dimensions: 5 ensembles x 5 interfaces x 5 interfaces\n",
      "Following original istar_analysis.py logic with tr=False\n",
      "Using ptype information with direction for istar_analysis-style computation\n",
      "\n",
      "=== 3D WEIGHT MATRICES RESULTS (istar_analysis style) ===\n",
      "3D Matrix dimensions: 5 x 5 x 5\n",
      "Total weight processed: 753341.000000\n",
      "Total transitions: 414700.0\n",
      "Non-zero 3D matrix elements: 50\n",
      "Time-reversal symmetry applied: False\n",
      "\n",
      "Ensemble weight totals:\n",
      "  Sum weights ensemble 0: 0.0000\n",
      "  Sum weights ensemble 1: 199998.0000\n",
      "  Sum weights ensemble 2: 199983.0000\n",
      "  Sum weights ensemble 3: 199996.0000\n",
      "  Sum weights ensemble 4: 153364.0000\n",
      "\n",
      "2D Weight Matrix [start_interface, end_interface] (summed over ensembles):\n",
      "Rows = start interface, Columns = end interface\n",
      "Interface 0: 172404.0000 55700.0000 41801.0000 37671.0000 45961.0000 \n",
      "Interface 1: 1519.0000   0.0000 22039.0000 24231.0000 32662.0000 \n",
      "Interface 2: 41682.0000 21902.0000   0.0000 22847.0000 36639.0000 \n",
      "Interface 3: 34686.0000 22108.0000 23614.0000   0.0000   0.0000 \n",
      "Interface 4: 45265.0000 32833.0000 37777.0000   0.0000   0.0000 \n",
      "\n",
      "Transition Analysis:\n",
      "Forward transitions (j<k):  144620.000000 paths, 319551.0000 weight (42.4%)\n",
      "Backward transitions (j>k): 107564.000000 paths, 261386.0000 weight (34.7%)\n",
      "Self transitions (j=k):     162516.000000 paths, 172404.0000 weight (22.9%)\n",
      "\n",
      "Non-zero 3D matrix entries (first 10):\n",
      "  weights[1,0,0] = 172404.000000 (count: 40629.0)\n",
      "  weights[1,0,1] = 8970.000000 (count: 7317.0)\n",
      "  weights[1,0,2] = 4658.000000 (count: 4987.0)\n",
      "  weights[1,0,3] = 2275.000000 (count: 4129.0)\n",
      "  weights[1,0,4] = 2789.000000 (count: 5110.0)\n",
      "  weights[1,1,0] = 1519.000000 (count: 392.0)\n",
      "  weights[1,2,0] = 3811.000000 (count: 4054.0)\n",
      "  weights[1,3,0] = 1536.000000 (count: 3437.0)\n",
      "  weights[1,4,0] = 2036.000000 (count: 4523.0)\n",
      "  weights[2,0,1] = 46730.000000 (count: 7317.0)\n",
      "Warning: Zero count detected for q[1][0] = 0.0, counts = [0. 0.]\n",
      "Warning: Zero count detected for q[3][4] = 0.0, counts = [0. 0.]\n",
      "Warning: Zero count detected for q[4][3] = 0.0, counts = [0. 0.]\n",
      "\n",
      "Intermediate transition probabilities (q matrix):\n",
      "[[1.     0.0978 0.528  0.5976 0.5496]\n",
      " [0.     0.     1.     0.6318 0.5741]\n",
      " [0.6336 1.     0.     1.     0.6159]\n",
      " [0.5999 0.6076 1.     0.     0.    ]\n",
      " [0.5683 0.5923 1.     1.     0.    ]]\n",
      "\n",
      "Final transition probabilities (p matrix):\n",
      "[[0.9022 0.0462 0.0208 0.0139 0.017 ]\n",
      " [0.     0.     0.3682 0.2691 0.3627]\n",
      " [0.6336 0.3664 0.     0.3841 0.6159]\n",
      " [0.3645 0.2431 0.3924 0.     0.    ]\n",
      " [0.3366 0.2557 0.4077 0.     0.    ]]\n",
      "\n",
      "Local crossing probabilities computed successfully\n",
      "[1.0, 0.09781471093063172, 0.0516479377883831, 0.036428114418281476, 0.027382651282432804]\n",
      "[0.09781471093063172, 0.5280180997008804, 0.7053159521593728, 0.7516900536770796]\n"
     ]
    }
   ],
   "source": [
    "plocs = [1.,]\n",
    "for i in range(len(weight_matrices_results['interfaces'])-1):\n",
    "    print(f\"Interface λ_{i}: {weight_matrices_results['interfaces'][i]}\")\n",
    "\n",
    "    wi_results = compute_weight_matrices_weights(weight_results, n_int=i+2, tr=False)\n",
    "    wi_ha = wi_results['weight_matrix_3d']\n",
    "    pi_ha, _ = get_transition_probs_weights(wi_ha)\n",
    "    Mi_ha = construct_M_istar(pi_ha, max(4, 2*len(weight_matrices_results[\"interfaces\"][:i+2])), len(weight_matrices_results[\"interfaces\"][:i+2]))\n",
    "    z1_ha, z2_ha, y1_ha, y2_ha = global_pcross_msm_star(Mi_ha)\n",
    "    plocs.append(y1_ha[0][0])\n",
    "\n",
    "print(plocs)\n",
    "print([plocs[i+1]/plocs[i] for i in range(len(plocs)-1)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8561d335",
   "metadata": {},
   "source": [
    "## Step 2: Compute Transition Probabilities\n",
    "\n",
    "Next, we calculate the transition probabilities between interfaces using the infretis weights. This forms the basis for the iSTAR transition matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17e7e159",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (149869049.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[13], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    P_istar =\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Calculate transition probabilities\n",
    "print(\"=== STEP 2: COMPUTING TRANSITION PROBABILITIES ===\")\n",
    "\n",
    "# Try both methods to compare\n",
    "print(\"\\nMethod 1: Standard iSTAR approach\")\n",
    "try:\n",
    "    P_istar = \n",
    "    print(\"✓ iSTAR transition probabilities calculated successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error in iSTAR method: {e}\")\n",
    "    P_istar = None\n",
    "\n",
    "print(\"\\nMethod 2: Simplified direct counting approach\")\n",
    "try:\n",
    "    P_simple = compute_simplified_transition_probabilities(weight_results)\n",
    "    print(\"✓ Simplified transition probabilities calculated successfully\")\n",
    "    print(\"\\nSimplified transition probability matrix:\")\n",
    "    print(\"Rows: starting interface, Columns: ending interface\")\n",
    "    for i in range(P_simple.shape[0]):\n",
    "        print(f\"Interface {i}: {P_simple[i, :]}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error in simplified method: {e}\")\n",
    "    P_simple = None\n",
    "\n",
    "# Use the method that worked\n",
    "if P_simple is not None:\n",
    "    P = P_simple\n",
    "    method_used = \"Simplified\"\n",
    "elif P_istar is not None:\n",
    "    P = P_istar  \n",
    "    method_used = \"iSTAR\"\n",
    "else:\n",
    "    print(\"✗ Both methods failed!\")\n",
    "    P = None\n",
    "\n",
    "if P is not None:\n",
    "    print(f\"\\nUsing {method_used} method for further analysis\")\n",
    "    print(f\"Transition matrix properties:\")\n",
    "    print(f\"- Shape: {P.shape}\")\n",
    "    print(f\"- Row sums: {[np.sum(P[i, :]) for i in range(P.shape[0])]}\")\n",
    "    print(f\"- Determinant: {np.linalg.det(P):.6f}\")\n",
    "    \n",
    "    # Check if matrix is properly stochastic\n",
    "    row_sums = np.sum(P, axis=1)\n",
    "    is_stochastic = np.allclose(row_sums, 1.0)\n",
    "    print(f\"- Is stochastic: {is_stochastic}\")\n",
    "    if not is_stochastic:\n",
    "        print(f\"  Row sums: {row_sums}\")\n",
    "else:\n",
    "    print(\"Cannot proceed without transition probabilities!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228cf5ab",
   "metadata": {},
   "source": [
    "## Step 3: Construct iSTAR Transition Matrix and Calculate Global Pcross\n",
    "\n",
    "Now we construct the full iSTAR transition matrix and calculate the global crossing probability using the Markov model approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6245249b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STEP 3: iSTAR MATRIX CONSTRUCTION AND GLOBAL PCROSS ===\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'P' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Construct iSTAR transition matrix and calculate global crossing probability\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=== STEP 3: iSTAR MATRIX CONSTRUCTION AND GLOBAL PCROSS ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mP\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m      5\u001b[0m     N \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(weight_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minterfaces\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of interfaces: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mN\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'P' is not defined"
     ]
    }
   ],
   "source": [
    "# Construct iSTAR transition matrix and calculate global crossing probability\n",
    "print(\"=== STEP 3: iSTAR MATRIX CONSTRUCTION AND GLOBAL PCROSS ===\")\n",
    "\n",
    "if P is not None:\n",
    "    N = len(weight_results['interfaces'])\n",
    "    print(f\"Number of interfaces: {N}\")\n",
    "    \n",
    "    # Construct the iSTAR transition matrix\n",
    "    try:\n",
    "        M = construct_istar_transition_matrix(P, N)\n",
    "        print(\"✓ iSTAR transition matrix constructed successfully\")\n",
    "        \n",
    "        # Display matrix properties\n",
    "        print(f\"\\nMatrix M properties:\")\n",
    "        print(f\"- Shape: {M.shape}\")\n",
    "        print(f\"- Non-zero entries: {np.count_nonzero(M)}\")\n",
    "        print(f\"- Matrix preview (first 5x5):\")\n",
    "        print(M[:5, :5])\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error constructing iSTAR matrix: {e}\")\n",
    "        M = None\n",
    "    \n",
    "    # Calculate global crossing probability\n",
    "    if M is not None:\n",
    "        try:\n",
    "            print(\"\\nCalculating global crossing probability...\")\n",
    "            z1, z2, y1, y2 = global_pcross_istar(M, doprint=True)\n",
    "            \n",
    "            if y1 is not None and y1.shape[0] > 1:\n",
    "                global_pcross = y1[1, 0]  # Probability to reach state -1 before state 0\n",
    "                print(f\"\\n✓ Global crossing probability calculated: {global_pcross:.8f}\")\n",
    "                \n",
    "                # Store results for comparison\n",
    "                istar_results = {\n",
    "                    'transition_matrix': M,\n",
    "                    'global_pcross': global_pcross,\n",
    "                    'solution_vectors': (z1, z2, y1, y2)\n",
    "                }\n",
    "            else:\n",
    "                print(\"✗ Could not extract global crossing probability\")\n",
    "                global_pcross = None\n",
    "                istar_results = None\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"✗ Error calculating global crossing probability: {e}\")\n",
    "            global_pcross = None\n",
    "            istar_results = None\n",
    "    else:\n",
    "        print(\"Cannot calculate global crossing probability without transition matrix\")\n",
    "        global_pcross = None\n",
    "        istar_results = None\n",
    "else:\n",
    "    print(\"Cannot proceed without transition probabilities!\")\n",
    "    global_pcross = None\n",
    "    istar_results = None\n",
    "\n",
    "# Summary\n",
    "if global_pcross is not None:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"ISTAR ANALYSIS SUMMARY\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"Global Crossing Probability: {global_pcross:.8f}\")\n",
    "    print(f\"Method used: {method_used} transition probabilities\")\n",
    "    print(f\"Number of interfaces: {N}\")\n",
    "    print(f\"Interface positions: {weight_results['interfaces']}\")\n",
    "else:\n",
    "    print(\"\\n✗ iSTAR analysis failed - could not calculate global crossing probability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e93b39",
   "metadata": {},
   "source": [
    "## Step 4: Calculate Binless Crossing Probability\n",
    "\n",
    "For comparison, we also calculate the binless crossing probability directly from the weighted path data. This provides a complementary view of the crossing behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c691ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STEP 4: CALCULATING BINLESS CROSSING PROBABILITY ===\n",
      "✗ Error calculating binless crossing probability: 'unbiased_weights'\n",
      "✗ Cannot prepare comparison plots without binless results\n"
     ]
    }
   ],
   "source": [
    "# Calculate binless crossing probability\n",
    "print(\"=== STEP 4: CALCULATING BINLESS CROSSING PROBABILITY ===\")\n",
    "\n",
    "try:\n",
    "    x_binless, y_binless = calculate_binless_pcross(weight_results)\n",
    "    print(\"✓ Binless crossing probability calculated successfully\")\n",
    "    \n",
    "    # Show some key values\n",
    "    interfaces = weight_results['interfaces']\n",
    "    print(f\"\\nBinless crossing probability at interfaces:\")\n",
    "    for i, intf in enumerate(interfaces):\n",
    "        # Find closest point in binless curve\n",
    "        idx = np.argmin(np.abs(x_binless - intf))\n",
    "        pcross_at_intf = y_binless[idx]\n",
    "        print(f\"  λ_{i} = {intf:.6f}: P_cross ≈ {pcross_at_intf:.6f}\")\n",
    "    \n",
    "    binless_results = (x_binless, y_binless)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ Error calculating binless crossing probability: {e}\")\n",
    "    binless_results = None\n",
    "\n",
    "# Prepare results for comparison plotting\n",
    "if binless_results is not None:\n",
    "    plot_results = {\n",
    "        'binless': binless_results,\n",
    "        'interfaces': weight_results['interfaces']\n",
    "    }\n",
    "    \n",
    "    if global_pcross is not None:\n",
    "        plot_results['istar_global'] = global_pcross\n",
    "        \n",
    "        # Compare global iSTAR result with binless at final interface\n",
    "        final_intf_idx = np.argmin(np.abs(x_binless - interfaces[-1]))\n",
    "        binless_final = y_binless[final_intf_idx]\n",
    "        \n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"COMPARISON SUMMARY\")\n",
    "        print(f\"{'='*50}\")\n",
    "        print(f\"iSTAR Global P_cross:     {global_pcross:.8f}\")\n",
    "        print(f\"Binless at final λ:       {binless_final:.8f}\")\n",
    "        print(f\"Ratio (iSTAR/Binless):    {global_pcross/binless_final:.6f}\")\n",
    "        print(f\"Absolute difference:      {abs(global_pcross - binless_final):.8f}\")\n",
    "    \n",
    "    print(\"\\n✓ Ready for visualization\")\n",
    "else:\n",
    "    print(\"✗ Cannot prepare comparison plots without binless results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60192dc6",
   "metadata": {},
   "source": [
    "## Step 5: Visualization and Analysis\n",
    "\n",
    "Finally, we visualize the results and compare the different methods for calculating the crossing probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c90507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STEP 5: VISUALIZATION AND ANALYSIS ===\n",
      "✗ Cannot create plots - missing results data\n",
      "\n",
      "============================================================\n",
      "FINAL WORKFLOW SUMMARY\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'global_pcross' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 70\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFINAL WORKFLOW SUMMARY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m60\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mglobal_pcross\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✓ iSTAR Analysis Successful\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Global Crossing Probability: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mglobal_pcross\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.8e\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'global_pcross' is not defined"
     ]
    }
   ],
   "source": [
    "# Visualization and final analysis\n",
    "print(\"=== STEP 5: VISUALIZATION AND ANALYSIS ===\")\n",
    "\n",
    "if 'plot_results' in locals() and plot_results:\n",
    "    # Plot the comparison\n",
    "    print(\"Creating comparison plot...\")\n",
    "    plot_pcross_comparison(plot_results, \n",
    "                          title=\"iSTAR vs Binless Crossing Probability (infretis weights)\")\n",
    "    \n",
    "    # Additional analysis plots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # Plot 1: Transition matrix heatmap (if available)\n",
    "    if istar_results is not None and 'transition_matrix' in istar_results:\n",
    "        M = istar_results['transition_matrix']\n",
    "        im1 = axes[0, 0].imshow(M, cmap='Blues', aspect='auto')\n",
    "        axes[0, 0].set_title('iSTAR Transition Matrix M')\n",
    "        axes[0, 0].set_xlabel('To State')\n",
    "        axes[0, 0].set_ylabel('From State')\n",
    "        plt.colorbar(im1, ax=axes[0, 0])\n",
    "    else:\n",
    "        axes[0, 0].text(0.5, 0.5, 'Transition Matrix\\nNot Available', \n",
    "                       ha='center', va='center', transform=axes[0, 0].transAxes)\n",
    "        axes[0, 0].set_title('iSTAR Transition Matrix M')\n",
    "    \n",
    "    # Plot 2: Local crossing probabilities\n",
    "    interfaces = weight_results['interfaces']\n",
    "    ploc = weight_results['ploc_wham']\n",
    "    axes[0, 1].semilogy(range(len(interfaces)), ploc, 'ro-', linewidth=2, markersize=8)\n",
    "    axes[0, 1].set_title('Local Crossing Probabilities (WHAM)')\n",
    "    axes[0, 1].set_xlabel('Interface Index')\n",
    "    axes[0, 1].set_ylabel('P_loc')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Weight distribution\n",
    "    weights = weight_results['unbiased_weights']\n",
    "    axes[1, 0].hist(np.log10(weights[weights > 0]), bins=20, alpha=0.7, color='green')\n",
    "    axes[1, 0].set_title('Distribution of Path Weights')\n",
    "    axes[1, 0].set_xlabel('log₁₀(Weight)')\n",
    "    axes[1, 0].set_ylabel('Count')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 4: Path statistics\n",
    "    maxops = weight_results['path_data']['maxop'][:, 0]\n",
    "    axes[1, 1].scatter(maxops, weights, alpha=0.6, s=20)\n",
    "    axes[1, 1].set_title('Path Weights vs Maximum Order Parameter')\n",
    "    axes[1, 1].set_xlabel('Maximum Order Parameter')\n",
    "    axes[1, 1].set_ylabel('Weight')\n",
    "    axes[1, 1].set_yscale('log')\n",
    "    \n",
    "    # Add interface lines\n",
    "    for intf in interfaces:\n",
    "        axes[1, 1].axvline(intf, color='red', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"✓ Visualization complete\")\n",
    "    \n",
    "else:\n",
    "    print(\"✗ Cannot create plots - missing results data\")\n",
    "\n",
    "# Final summary\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"FINAL WORKFLOW SUMMARY\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "if global_pcross is not None:\n",
    "    print(f\"✓ iSTAR Analysis Successful\")\n",
    "    print(f\"  Global Crossing Probability: {global_pcross:.8e}\")\n",
    "    print(f\"  Method: iSTAR with {method_used} transition probabilities\")\n",
    "else:\n",
    "    print(f\"✗ iSTAR Analysis Failed\")\n",
    "\n",
    "if binless_results is not None:\n",
    "    print(f\"✓ Binless Analysis Successful\")\n",
    "    print(f\"  Points calculated: {len(binless_results[0])}\")\n",
    "    print(f\"  Order parameter range: {binless_results[0].min():.3f} to {binless_results[0].max():.3f}\")\n",
    "else:\n",
    "    print(f\"✗ Binless Analysis Failed\")\n",
    "\n",
    "print(f\"\\nKey Improvements over Old Workflow:\")\n",
    "print(f\"• Uses proper infretis weights instead of simple path counts\")\n",
    "print(f\"• Implements WHAM-based local crossing probabilities\")\n",
    "print(f\"• Provides both iSTAR and binless methods for comparison\")\n",
    "print(f\"• Includes comprehensive error handling and diagnostics\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9c43e5",
   "metadata": {},
   "source": [
    "## Key Improvements and Usage Notes\n",
    "\n",
    "### Major Changes from Old Workflow:\n",
    "\n",
    "1. **Infretis Weight Integration**: The biggest change is using proper infretis weights (`path_f / path_w`) instead of simple path counting. This provides statistically correct weighting of paths.\n",
    "\n",
    "2. **WHAM-based Local Probabilities**: The calculation of local crossing probabilities now uses the WHAM methodology to properly combine data from different ensembles.\n",
    "\n",
    "3. **Robust Error Handling**: The workflow includes comprehensive error checking and fallback methods.\n",
    "\n",
    "4. **Multiple Methods**: Provides both iSTAR Markov model approach and direct binless calculation for comparison.\n",
    "\n",
    "### Understanding the Results:\n",
    "\n",
    "- **Global Pcross (iSTAR)**: Single value representing the overall transition probability calculated using the Markov state model\n",
    "- **Binless Pcross**: Continuous curve showing crossing probability as a function of order parameter\n",
    "- **Local Probabilities**: WHAM-weighted probabilities for transitions between adjacent interfaces\n",
    "- **Transition Matrix**: Full Markov model capturing the interface-to-interface dynamics\n",
    "\n",
    "### Usage for Different Systems:\n",
    "\n",
    "To use this workflow for your own system:\n",
    "1. Update `DATA_DIR`, `TOML_FILE`, and `DATA_FILE` paths\n",
    "2. Adjust `NSKIP` if you want to exclude initial equilibration\n",
    "3. The interfaces are automatically read from the TOML file\n",
    "4. All weight calculations are handled automatically\n",
    "\n",
    "### Validation:\n",
    "\n",
    "The workflow validates results by:\n",
    "- Comparing iSTAR global result with binless calculation\n",
    "- Checking matrix properties (stochastic, determinant)\n",
    "- Monitoring weight distributions and statistics\n",
    "- Providing comprehensive diagnostic output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a14679",
   "metadata": {},
   "source": [
    "## Using display_data_infretis Function\n",
    "\n",
    "The `display_data_infretis` function provides detailed analysis of the weight matrices similar to the original `display_data` function, but adapted for the infretis implementation.\n",
    "\n",
    "### Key Features:\n",
    "- **Ensemble-by-ensemble analysis**: Shows weight matrices and count matrices for each ensemble\n",
    "- **Anomaly detection**: Identifies significant differences between weighted and raw counts\n",
    "- **Time-reversal analysis**: Detects violations of time-reversal symmetry (when applied)\n",
    "- **Sampling quality**: Warns about interfaces with insufficient sampling\n",
    "- **Combined statistics**: Provides overall analysis across all ensembles\n",
    "\n",
    "### Usage Example:\n",
    "```python\n",
    "# After running compute_weight_matrices_weights\n",
    "if 'weight_matrices_results' in locals():\n",
    "    print(\"Detailed weight matrix analysis:\")\n",
    "    display_data_infretis(weight_matrices_results, threshold_w=0.03, threshold_tr=0.05)\n",
    "else:\n",
    "    print(\"Run compute_weight_matrices_weights first to generate weight matrices\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c9b0085a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running detailed weight matrix analysis using display_data_infretis...\n",
      "\n",
      "This function provides similar diagnostics to the original display_data\n",
      "but adapted for the infretis data structure (dictionary of 2D matrices)\n",
      "\n",
      "============================================================\n",
      "============================================================\n",
      "INFRETIS WEIGHT MATRICES ANALYSIS\n",
      "============================================================\n",
      "Structure: 5 ensembles × 5 interfaces × 5 interfaces\n",
      "Time-reversal symmetry applied: False\n",
      "Warning thresholds: weight differences ≥ 3.0%, TR violations ≥ 5.0%\n",
      "\n",
      "----------\n",
      "ENSEMBLE [0-] | ID 0\n",
      "----------\n",
      "\n",
      "1a. Raw data: unweighted count matrix C[0] (notr)\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "\n",
      "1b. Weighted data: X[0] (notr)\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "Total weight ensemble 0: 0.0000\n",
      "\n",
      "2. Time-reversal symmetry not applied for this analysis\n",
      "\n",
      "----------\n",
      "ENSEMBLE [0*] | ID 1\n",
      "----------\n",
      "\n",
      "1a. Raw data: unweighted count matrix C[1] (notr)\n",
      "[[40629.  7317.  4987.  4129.  5110.]\n",
      " [  392.     0.  2404.  2472.  3386.]\n",
      " [ 4054.  2321.     0.  2461.  3889.]\n",
      " [ 3437.  2467.  2461.     0.     0.]\n",
      " [ 4523.  3371.  3865.  5100.     0.]]\n",
      "\n",
      "1b. Weighted data: X[1] (notr)\n",
      "[[172404.   8970.   4658.   2275.   2789.]\n",
      " [  1519.      0.      0.      0.      0.]\n",
      " [  3811.      0.      0.      0.      0.]\n",
      " [  1536.      0.      0.      0.      0.]\n",
      " [  2036.      0.      0.      0.      0.]]\n",
      "Total weight ensemble 1: 199998.0000\n",
      "\n",
      "[WARNING] Significant differences between weighted and raw data (≥3.0%):\n",
      "  Path 0 → 0: raw count=40629.0, weighted=172404.0000, fraction diff=0.4885\n",
      "  Path 0 → 4: raw count=5110.0, weighted=2789.0000, fraction diff=0.0330\n",
      "  Path 1 → 4: raw count=3386.0, weighted=0.0000, fraction diff=0.0311\n",
      "  Path 2 → 4: raw count=3889.0, weighted=0.0000, fraction diff=0.0358\n",
      "  Path 4 → 0: raw count=4523.0, weighted=2036.0000, fraction diff=0.0314\n",
      "  Path 4 → 1: raw count=3371.0, weighted=0.0000, fraction diff=0.0310\n",
      "  Path 4 → 2: raw count=3865.0, weighted=0.0000, fraction diff=0.0355\n",
      "  Path 4 → 3: raw count=5100.0, weighted=0.0000, fraction diff=0.0469\n",
      "\n",
      "2. Time-reversal symmetry not applied for this analysis\n",
      "\n",
      "[WARNING] Interfaces with insufficient sampling (incoming):\n",
      "  Interface 2: incoming weight=4658.0000, only 2.3% of total (threshold: 7999.9200)\n",
      "  Interface 3: incoming weight=2275.0000, only 1.1% of total (threshold: 7999.9200)\n",
      "  Interface 4: incoming weight=2789.0000, only 1.4% of total (threshold: 7999.9200)\n",
      "\n",
      "[WARNING] Interfaces with insufficient sampling (outgoing):\n",
      "  Interface 1: outgoing weight=1519.0000, only 0.8% of total (threshold: 7999.9200)\n",
      "  Interface 2: outgoing weight=3811.0000, only 1.9% of total (threshold: 7999.9200)\n",
      "  Interface 3: outgoing weight=1536.0000, only 0.8% of total (threshold: 7999.9200)\n",
      "  Interface 4: outgoing weight=2036.0000, only 1.0% of total (threshold: 7999.9200)\n",
      "\n",
      "----------\n",
      "ENSEMBLE [1*] | ID 2\n",
      "----------\n",
      "\n",
      "1a. Raw data: unweighted count matrix C[2] (notr)\n",
      "[[40629.  7317.  4987.  4129.  5110.]\n",
      " [  392.     0.  2404.  2472.  3386.]\n",
      " [ 4054.  2321.     0.  2461.  3889.]\n",
      " [ 3437.  2467.  2461.     0.     0.]\n",
      " [ 4523.  3371.  3865.  5100.     0.]]\n",
      "\n",
      "1b. Weighted data: X[2] (notr)\n",
      "[[    0. 46730. 24718. 14049. 13824.]\n",
      " [    0.     0. 11534.  6228.  6515.]\n",
      " [25411. 11111.     0.     0.     0.]\n",
      " [13491.  5200.     0.     0.     0.]\n",
      " [14447.  6725.     0.     0.     0.]]\n",
      "Total weight ensemble 2: 199983.0000\n",
      "\n",
      "[WARNING] Significant differences between weighted and raw data (≥3.0%):\n",
      "  Path 0 → 0: raw count=40629.0, weighted=0.0000, fraction diff=0.3735\n",
      "  Path 0 → 1: raw count=7317.0, weighted=46730.0000, fraction diff=0.1664\n",
      "  Path 0 → 2: raw count=4987.0, weighted=24718.0000, fraction diff=0.0778\n",
      "  Path 0 → 3: raw count=4129.0, weighted=14049.0000, fraction diff=0.0323\n",
      "  Path 1 → 2: raw count=2404.0, weighted=11534.0000, fraction diff=0.0356\n",
      "  Path 2 → 0: raw count=4054.0, weighted=25411.0000, fraction diff=0.0898\n",
      "  Path 2 → 1: raw count=2321.0, weighted=11111.0000, fraction diff=0.0342\n",
      "  Path 2 → 4: raw count=3889.0, weighted=0.0000, fraction diff=0.0358\n",
      "  Path 3 → 0: raw count=3437.0, weighted=13491.0000, fraction diff=0.0359\n",
      "  Path 4 → 0: raw count=4523.0, weighted=14447.0000, fraction diff=0.0307\n",
      "  Path 4 → 2: raw count=3865.0, weighted=0.0000, fraction diff=0.0355\n",
      "  Path 4 → 3: raw count=5100.0, weighted=0.0000, fraction diff=0.0469\n",
      "\n",
      "2. Time-reversal symmetry not applied for this analysis\n",
      "\n",
      "----------\n",
      "ENSEMBLE [2*] | ID 3\n",
      "----------\n",
      "\n",
      "1a. Raw data: unweighted count matrix C[3] (notr)\n",
      "[[40629.  7317.  4987.  4129.  5110.]\n",
      " [  392.     0.  2404.  2472.  3386.]\n",
      " [ 4054.  2321.     0.  2461.  3889.]\n",
      " [ 3437.  2467.  2461.     0.     0.]\n",
      " [ 4523.  3371.  3865.  5100.     0.]]\n",
      "\n",
      "1b. Weighted data: X[3] (notr)\n",
      "[[    0.     0. 12425. 14376. 14777.]\n",
      " [    0.     0. 10505. 11881. 13189.]\n",
      " [12460. 10791.     0. 11633. 12150.]\n",
      " [13248. 11472. 12334.     0.     0.]\n",
      " [14367. 11957. 12431.     0.     0.]]\n",
      "Total weight ensemble 3: 199996.0000\n",
      "\n",
      "[WARNING] Significant differences between weighted and raw data (≥3.0%):\n",
      "  Path 0 → 0: raw count=40629.0, weighted=0.0000, fraction diff=0.3735\n",
      "  Path 0 → 1: raw count=7317.0, weighted=0.0000, fraction diff=0.0673\n",
      "  Path 0 → 3: raw count=4129.0, weighted=14376.0000, fraction diff=0.0339\n",
      "  Path 1 → 2: raw count=2404.0, weighted=10505.0000, fraction diff=0.0304\n",
      "  Path 1 → 3: raw count=2472.0, weighted=11881.0000, fraction diff=0.0367\n",
      "  Path 1 → 4: raw count=3386.0, weighted=13189.0000, fraction diff=0.0348\n",
      "  Path 2 → 1: raw count=2321.0, weighted=10791.0000, fraction diff=0.0326\n",
      "  Path 2 → 3: raw count=2461.0, weighted=11633.0000, fraction diff=0.0355\n",
      "  Path 3 → 0: raw count=3437.0, weighted=13248.0000, fraction diff=0.0346\n",
      "  Path 3 → 1: raw count=2467.0, weighted=11472.0000, fraction diff=0.0347\n",
      "  Path 3 → 2: raw count=2461.0, weighted=12334.0000, fraction diff=0.0390\n",
      "  Path 4 → 0: raw count=4523.0, weighted=14367.0000, fraction diff=0.0303\n",
      "  Path 4 → 3: raw count=5100.0, weighted=0.0000, fraction diff=0.0469\n",
      "\n",
      "2. Time-reversal symmetry not applied for this analysis\n",
      "\n",
      "----------\n",
      "ENSEMBLE [3*] | ID 4\n",
      "----------\n",
      "\n",
      "1a. Raw data: unweighted count matrix C[4] (notr)\n",
      "[[40629.  7317.  4987.  4129.  5110.]\n",
      " [  392.     0.  2404.  2472.  3386.]\n",
      " [ 4054.  2321.     0.  2461.  3889.]\n",
      " [ 3437.  2467.  2461.     0.     0.]\n",
      " [ 4523.  3371.  3865.  5100.     0.]]\n",
      "\n",
      "1b. Weighted data: X[4] (notr)\n",
      "[[    0.     0.     0.  6971. 14571.]\n",
      " [    0.     0.     0.  6122. 12958.]\n",
      " [    0.     0.     0. 11214. 24489.]\n",
      " [ 6411.  5436. 11280.     0.     0.]\n",
      " [14415. 14151. 25346. 46573.     0.]]\n",
      "Total weight ensemble 4: 199937.0000\n",
      "\n",
      "[WARNING] Significant differences between weighted and raw data (≥3.0%):\n",
      "  Path 0 → 0: raw count=40629.0, weighted=0.0000, fraction diff=0.3735\n",
      "  Path 0 → 1: raw count=7317.0, weighted=0.0000, fraction diff=0.0673\n",
      "  Path 0 → 2: raw count=4987.0, weighted=0.0000, fraction diff=0.0458\n",
      "  Path 1 → 4: raw count=3386.0, weighted=12958.0000, fraction diff=0.0337\n",
      "  Path 2 → 0: raw count=4054.0, weighted=0.0000, fraction diff=0.0373\n",
      "  Path 2 → 3: raw count=2461.0, weighted=11214.0000, fraction diff=0.0335\n",
      "  Path 2 → 4: raw count=3889.0, weighted=24489.0000, fraction diff=0.0867\n",
      "  Path 3 → 2: raw count=2461.0, weighted=11280.0000, fraction diff=0.0338\n",
      "  Path 4 → 0: raw count=4523.0, weighted=14415.0000, fraction diff=0.0305\n",
      "  Path 4 → 1: raw count=3371.0, weighted=14151.0000, fraction diff=0.0398\n",
      "  Path 4 → 2: raw count=3865.0, weighted=25346.0000, fraction diff=0.0912\n",
      "  Path 4 → 3: raw count=5100.0, weighted=46573.0000, fraction diff=0.1861\n",
      "\n",
      "2. Time-reversal symmetry not applied for this analysis\n",
      "\n",
      "========================================\n",
      "ALL ENSEMBLES COMBINED\n",
      "--------------------\n",
      "\n",
      "3a. Combined weight matrix (sum over all ensembles, notr):\n",
      "Rows = start interface, Columns = end interface\n",
      "[[172404.  55700.  41801.  37671.  45961.]\n",
      " [  1519.      0.  22039.  24231.  32662.]\n",
      " [ 41682.  21902.      0.  22847.  36639.]\n",
      " [ 34686.  22108.  23614.      0.      0.]\n",
      " [ 45265.  32833.  37777.  46573.      0.]]\n",
      "\n",
      "3b. Combined count matrix (sum over all ensembles, notr):\n",
      "Rows = start interface, Columns = end interface\n",
      "[[162516.  29268.  19948.  16516.  20440.]\n",
      " [  1568.      0.   9616.   9888.  13544.]\n",
      " [ 16216.   9284.      0.   9844.  15556.]\n",
      " [ 13748.   9868.   9844.      0.      0.]\n",
      " [ 18092.  13484.  15460.  20400.      0.]]\n",
      "\n",
      "=== OVERALL STATISTICS ===\n",
      "Total weight across all ensembles: 799914.0000\n",
      "Total transitions: 435100.0\n",
      "Non-zero matrix elements: 20/25\n",
      "\n",
      "Transition breakdown:\n",
      "• Forward (j<k):  319551.0000 (39.9%)\n",
      "• Backward (j>k): 307959.0000 (38.5%)\n",
      "• Self (j=k):     172404.0000 (21.6%)\n",
      "\n",
      "Interface activity analysis:\n",
      "  Interface 0: total activity = 649093.0000 (40.6% of total)\n",
      "  Interface 1: total activity = 212994.0000 (13.3% of total)\n",
      "  Interface 2: total activity = 248301.0000 (15.5% of total)\n",
      "  Interface 3: total activity = 211730.0000 (13.2% of total)\n",
      "  Interface 4: total activity = 277710.0000 (17.4% of total)\n",
      "\n",
      "============================================================\n",
      "Analysis complete. Check warnings above for potential issues.\n",
      "\n",
      "============================================================\n",
      "Analysis complete!\n",
      "\n",
      "Interpretation guide:\n",
      "• Raw count matrices show the number of paths for each transition\n",
      "• Weighted matrices include statistical weights for proper averaging\n",
      "• Time-reversal analysis checks for detailed balance violations\n",
      "• Warnings highlight potential sampling or statistical issues\n",
      "• Combined matrices show the overall transition behavior\n"
     ]
    }
   ],
   "source": [
    "# Example usage of display_data_infretis function\n",
    "if 'weight_matrices_results' in locals() and weight_matrices_results is not None:\n",
    "    print(\"Running detailed weight matrix analysis using display_data_infretis...\")\n",
    "    print(\"\\nThis function provides similar diagnostics to the original display_data\")\n",
    "    print(\"but adapted for the infretis data structure (dictionary of 2D matrices)\")\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    \n",
    "    # Run the display function with default thresholds\n",
    "    display_data_infretis(weight_matrices_results, threshold_w=0.03, threshold_tr=0.05)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Analysis complete!\")\n",
    "    print(\"\\nInterpretation guide:\")\n",
    "    print(\"• Raw count matrices show the number of paths for each transition\")\n",
    "    print(\"• Weighted matrices include statistical weights for proper averaging\")  \n",
    "    print(\"• Time-reversal analysis checks for detailed balance violations\")\n",
    "    print(\"• Warnings highlight potential sampling or statistical issues\")\n",
    "    print(\"• Combined matrices show the overall transition behavior\")\n",
    "    \n",
    "else:\n",
    "    print(\"Weight matrices not available. Please run the following cells first:\")\n",
    "    print(\"1. Load infretis data\")\n",
    "    print(\"2. Calculate infretis weights\")\n",
    "    print(\"3. Compute weight matrices\")\n",
    "    print(\"\\nThen re-run this cell to see the detailed analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b2483494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Zero count detected for q[1][0] = 0.0, counts = [0. 0.]\n",
      "Warning: Zero count detected for q[3][4] = 0.0, counts = [0. 0.]\n",
      "Warning: Zero count detected for q[4][3] = 0.0, counts = [0. 0.]\n",
      "\n",
      "Intermediate transition probabilities (q matrix):\n",
      "[[1.     0.0978 0.528  0.5976 0.5496]\n",
      " [0.     0.     1.     0.6318 0.5741]\n",
      " [0.6336 1.     0.     1.     0.6159]\n",
      " [0.5999 0.6076 1.     0.     0.    ]\n",
      " [0.5683 0.5923 0.5365 1.     0.    ]]\n",
      "\n",
      "Final transition probabilities (p matrix):\n",
      "[[0.9022 0.0462 0.0208 0.0139 0.017 ]\n",
      " [0.     0.     0.3682 0.2691 0.3627]\n",
      " [0.6336 0.3664 0.     0.3841 0.6159]\n",
      " [0.3645 0.2431 0.3924 0.     0.    ]\n",
      " [0.1806 0.1372 0.2187 0.4635 0.    ]]\n",
      "\n",
      "Local crossing probabilities computed successfully\n"
     ]
    }
   ],
   "source": [
    "p, q = get_transition_probs_weights(weight_matrices_results['weight_matrix_3d'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9590788b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GENERATING ANALYSIS REPORT ===\n",
      "✓ Generated 6 visualization plots in /mnt/0bf0c339-34bb-4500-a5fb-f3c2a863de29/DATA/APPTIS/infretis/examples/ase/staple_flat_walls_br/plots/\n",
      "Analysis report saved to:\n",
      "  JSON format: /mnt/0bf0c339-34bb-4500-a5fb-f3c2a863de29/DATA/APPTIS/infretis/examples/ase/staple_flat_walls_br/istar_analysis_report_infretis_data.json\n",
      "  Summary format: /mnt/0bf0c339-34bb-4500-a5fb-f3c2a863de29/DATA/APPTIS/infretis/examples/ase/staple_flat_walls_br/istar_analysis_summary_infretis_data.txt\n",
      "  Visualizations: /mnt/0bf0c339-34bb-4500-a5fb-f3c2a863de29/DATA/APPTIS/infretis/examples/ase/staple_flat_walls_br/plots/\n",
      "\n",
      "✓ Report generation successful!\n",
      "\n",
      "Report contents:\n",
      "• System configuration and interface setup\n",
      "• Global and local crossing probabilities\n",
      "• Transition matrix analysis and statistics\n",
      "• Path and ensemble weight distributions\n",
      "• Per-interface detailed analysis\n",
      "• Complete 2D transition matrix data\n",
      "• Visual plots of key analysis results\n",
      "\n",
      "--- SUMMARY PREVIEW ---\n",
      "================================================================================\n",
      "iSTAR ANALYSIS SUMMARY REPORT\n",
      "================================================================================\n",
      "Generated: 2025-08-26T10:12:38.924549\n",
      "Data Directory: /mnt/0bf0c339-34bb-4500-a5fb-f3c2a863de29/DATA/APPTIS/infretis/examples/ase/staple_flat_walls_br\n",
      "Analysis Type: iSTAR Workflow with Infretis Weights\n",
      "\n",
      "SYSTEM CONFIGURATION\n",
      "----------------------------------------\n",
      "Number of interfaces: 5\n",
      "Interface positions: [-0.1, 0.0, 0.1, 0.2, 0.3]\n",
      "Total paths processed: 19123\n",
      "Has ptype information: True\n",
      "\n",
      "CROSSING PROBABILITIES\n",
      "----------------------------------------\n",
      "Global crossing probability (iSTAR): 3.70662678e-02\n",
      "Local crossing probabilities:\n",
      "  Interface 0 (λ=-0.100): 1.00000000e+00\n",
      "  Interface 1 (λ=0.000): 1.07728724e-01\n",
      "  Interface 2 (λ=0.100): 7.08749342e-02\n",
      "  Interface 3 (λ=0.200): 5.14325625e-02\n",
      "  Interface 4 (λ=0.300): 3.70662678e-02\n",
      "\n",
      "Flux ratios (P[i+1]/P[i]):\n",
      "... (64 more lines)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Generate and save analysis report with visualizations\n",
    "\n",
    "def save_analysis_report(data_dir, weight_results, weight_matrices_results, istar_global_pcross, plocs):\n",
    "    \"\"\"\n",
    "    Save a comprehensive analysis report to the data directory with visualizations.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_dir : str\n",
    "        Directory where the report will be saved\n",
    "    weight_results : dict\n",
    "        Results from calculate_infretis_weights\n",
    "    weight_matrices_results : dict\n",
    "        Results from compute_weight_matrices_weights\n",
    "    istar_global_pcross : float\n",
    "        Global crossing probability from iSTAR analysis\n",
    "    plocs : list\n",
    "        Local crossing probabilities\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create report dictionarynary\n",
    "    report = {\n",
    "        \"analysis_info\": {\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"data_directory\": data_dir,\n",
    "            \"analysis_type\": \"iSTAR Workflow with Infretis Weights\",\n",
    "            \"version\": \"2024.1\"\n",
    "        },\n",
    "        \n",
    "        \"system_configuration\": {\n",
    "            \"interfaces\": weight_results['interfaces'],\n",
    "            \"n_interfaces\": len(weight_results['interfaces']),\n",
    "            \"n_ensembles\": len(weight_matrices_results['weight_matrix_3d']),\n",
    "            \"total_paths\": weight_matrices_results['total_paths_processed'],\n",
    "            \"has_ptype_info\": weight_results['has_ptype']\n",
    "        },\n",
    "        \n",
    "        \"crossing_probabilities\": {\n",
    "            \"istar_global_pcross\": float(istar_global_pcross[0]) if hasattr(istar_global_pcross, '__len__') else float(istar_global_pcross),\n",
    "            \"local_pcross\": plocs,\n",
    "            \"flux_ratios\": [plocs[i+1]/plocs[i] for i in range(len(plocs)-1)]\n",
    "        },\n",
    "        \n",
    "        \"transition_statistics\": weight_matrices_results['transition_summary'],\n",
    "        \n",
    "        \"ensemble_weights\": {\n",
    "            f\"ensemble_{i}\": float(weight_matrices_results['ensemble_totals'][i])\n",
    "            for i in range(len(weight_matrices_results['ensemble_totals']))\n",
    "        },\n",
    "        \n",
    "        \"transition_matrix_analysis\": {\n",
    "            \"total_weight\": float(weight_matrices_results['transition_summary']['total_weight']),\n",
    "            \"forward_weight_fraction\": weight_matrices_results['transition_summary']['forward_weight_fraction'],\n",
    "            \"backward_weight_fraction\": weight_matrices_results['transition_summary']['backward_weight_fraction'],\n",
    "            \"self_weight_fraction\": weight_matrices_results['transition_summary']['self_weight_fraction'],\n",
    "            \"time_reversal_applied\": weight_matrices_results['tr_applied']\n",
    "        },\n",
    "        \n",
    "        \"path_statistics\": {\n",
    "            \"maxop_range\": {\n",
    "                \"min\": float(np.min(weight_results['path_data']['maxop'])),\n",
    "                \"max\": float(np.max(weight_results['path_data']['maxop']))\n",
    "            },\n",
    "            \"path_length_stats\": {\n",
    "                \"min\": int(np.min(weight_results['path_data']['len'])),\n",
    "                \"max\": int(np.max(weight_results['path_data']['len'])),\n",
    "                \"mean\": float(np.mean(weight_results['path_data']['len']))\n",
    "            }\n",
    "        },\n",
    "\n",
    "        \"interface_analysis\": []\n",
    "    }\n",
    "    \n",
    "    # Add per-interface analysis\n",
    "    for i, intf in enumerate(weight_results['interfaces']):\n",
    "        maxops = weight_results['path_data']['maxop'][:, 0]\n",
    "        n_crossing = int(np.sum(maxops >= intf))\n",
    "        \n",
    "        interface_stats = {\n",
    "            \"interface_index\": i,\n",
    "            \"position\": float(intf),\n",
    "            \"paths_crossing\": n_crossing,\n",
    "            \"local_pcross\": plocs[i] if i < len(plocs) else None\n",
    "        }\n",
    "        \n",
    "        if i < len(plocs) - 1:\n",
    "            interface_stats[\"flux_ratio_to_next\"] = plocs[i+1] / plocs[i]\n",
    "            \n",
    "        report[\"interface_analysis\"].append(interface_stats)\n",
    "\n",
    "    # Add transition matrix summary (2D matrix)\n",
    "    w_matrix_2d = weight_matrices_results['weight_matrix_2d']\n",
    "    report[\"transition_matrix_2d\"] = {\n",
    "        \"shape\": list(w_matrix_2d.shape),\n",
    "        \"total_weight\": float(np.sum(w_matrix_2d)),\n",
    "        \"non_zero_elements\": int(np.count_nonzero(w_matrix_2d)),\n",
    "        \"matrix_data\": w_matrix_2d.tolist()  # Full matrix as nested list\n",
    "    }\n",
    "    \n",
    "    # Add detailed ensemble analysis\n",
    "    ensemble_details = {}\n",
    "    for i in range(len(weight_matrices_results['weight_matrix_3d'])):\n",
    "        w_ens = weight_matrices_results['weight_matrix_3d'][i]\n",
    "        ensemble_details[f\"ensemble_{i}\"] = {\n",
    "            \"total_weight\": float(np.sum(w_ens)),\n",
    "            \"non_zero_transitions\": int(np.count_nonzero(w_ens)),\n",
    "            \"dominant_transitions\": []\n",
    "        }\n",
    "        \n",
    "        # Find top 5 transitions by weight for this ensemble\n",
    "        flat_indices = np.argsort(w_ens.flatten())[-5:]\n",
    "        for flat_idx in reversed(flat_indices):\n",
    "            if w_ens.flat[flat_idx] > 0:\n",
    "                row, col = np.unravel_index(flat_idx, w_ens.shape)\n",
    "                ensemble_details[f\"ensemble_{i}\"][\"dominant_transitions\"].append({\n",
    "                    \"from_interface\": int(row),\n",
    "                    \"to_interface\": int(col),\n",
    "                    \"weight\": float(w_ens[row, col])\n",
    "                })\n",
    "    \n",
    "    report[\"ensemble_analysis\"] = ensemble_details\n",
    "    \n",
    "    # Create visualizations\n",
    "    create_analysis_plots(data_dir, weight_results, weight_matrices_results, istar_global_pcross, plocs, report)\n",
    "    \n",
    "    # Save JSON report\n",
    "    report_file = os.path.join(data_dir, f\"istar_analysis_report_{DATA_FILE.split('/')[-1].split('.')[0]}.json\")\n",
    "    with open(report_file, 'w') as f:\n",
    "        json.dump(report, f, indent=2)\n",
    "    \n",
    "    # Save human-readable summary\n",
    "    summary_file = os.path.join(data_dir, f\"istar_analysis_summary_{DATA_FILE.split('/')[-1].split('.')[0]}.txt\")\n",
    "    with open(summary_file, 'w') as f:\n",
    "        f.write(\"=\"*80 + \"\\n\")\n",
    "        f.write(\"iSTAR ANALYSIS SUMMARY REPORT\\n\")\n",
    "        f.write(\"=\"*80 + \"\\n\")\n",
    "        f.write(f\"Generated: {report['analysis_info']['timestamp']}\\n\")\n",
    "        f.write(f\"Data Directory: {data_dir}\\n\")\n",
    "        f.write(f\"Analysis Type: {report['analysis_info']['analysis_type']}\\n\\n\")\n",
    "        \n",
    "        f.write(\"SYSTEM CONFIGURATION\\n\")\n",
    "        f.write(\"-\" * 40 + \"\\n\")\n",
    "        f.write(f\"Number of interfaces: {report['system_configuration']['n_interfaces']}\\n\")\n",
    "        f.write(f\"Interface positions: {report['system_configuration']['interfaces']}\\n\")\n",
    "        f.write(f\"Total paths processed: {report['system_configuration']['total_paths']}\\n\")\n",
    "        f.write(f\"Has ptype information: {report['system_configuration']['has_ptype_info']}\\n\\n\")\n",
    "        \n",
    "        f.write(\"CROSSING PROBABILITIES\\n\")\n",
    "        f.write(\"-\" * 40 + \"\\n\")\n",
    "        f.write(f\"Global crossing probability (iSTAR): {report['crossing_probabilities']['istar_global_pcross']:.8e}\\n\")\n",
    "        f.write(\"Local crossing probabilities:\\n\")\n",
    "        for i, ploc in enumerate(report['crossing_probabilities']['local_pcross']):\n",
    "            f.write(f\"  Interface {i} (λ={report['system_configuration']['interfaces'][i]:.3f}): {ploc:.8e}\\n\")\n",
    "        f.write(\"\\nFlux ratios (P[i+1]/P[i]):\\n\")\n",
    "        for i, ratio in enumerate(report['crossing_probabilities']['flux_ratios']):\n",
    "            f.write(f\"  λ{i} → λ{i+1}: {ratio:.6f}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "        f.write(\"TRANSITION STATISTICS\\n\")\n",
    "        f.write(\"-\" * 40 + \"\\n\")\n",
    "        f.write(f\"Total weight: {report['transition_matrix_analysis']['total_weight']:.1f}\\n\")\n",
    "        f.write(f\"Forward transitions: {report['transition_matrix_analysis']['forward_weight_fraction']:.1%}\\n\")\n",
    "        f.write(f\"Backward transitions: {report['transition_matrix_analysis']['backward_weight_fraction']:.1%}\\n\")\n",
    "        f.write(f\"Self transitions: {report['transition_matrix_analysis']['self_weight_fraction']:.1%}\\n\")\n",
    "        f.write(f\"Time-reversal symmetry applied: {report['transition_matrix_analysis']['time_reversal_applied']}\\n\\n\")\n",
    "        \n",
    "        f.write(\"ENSEMBLE WEIGHTS\\n\")\n",
    "        f.write(\"-\" * 40 + \"\\n\")\n",
    "        for ens, weight in report['ensemble_weights'].items():\n",
    "            f.write(f\"{ens}: {weight:.1f}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "        f.write(\"PATH STATISTICS\\n\")\n",
    "        f.write(\"-\" * 40 + \"\\n\")\n",
    "        f.write(f\"Order parameter range: {report['path_statistics']['maxop_range']['min']:.6f} to {report['path_statistics']['maxop_range']['max']:.6f}\\n\")\n",
    "        f.write(f\"Path length range: {report['path_statistics']['path_length_stats']['min']} to {report['path_statistics']['path_length_stats']['max']} (mean: {report['path_statistics']['path_length_stats']['mean']:.1f})\\n\\n\")\n",
    "        \n",
    "        f.write(\"INTERFACE ANALYSIS\\n\")\n",
    "        f.write(\"-\" * 40 + \"\\n\")\n",
    "        for intf_data in report['interface_analysis']:\n",
    "            f.write(f\"Interface {intf_data['interface_index']} (λ={intf_data['position']:.3f}):\\n\")\n",
    "            f.write(f\"  Paths crossing: {intf_data['paths_crossing']}\\n\")\n",
    "            if intf_data['local_pcross'] is not None:\n",
    "                f.write(f\"  Local P_cross: {intf_data['local_pcross']:.8e}\\n\")\n",
    "            if 'flux_ratio_to_next' in intf_data:\n",
    "                f.write(f\"  Flux ratio to next: {intf_data['flux_ratio_to_next']:.6f}\\n\")\n",
    "            f.write(\"\\n\")\n",
    "        \n",
    "        f.write(\"VISUALIZATIONS\\n\")\n",
    "        f.write(\"-\" * 40 + \"\\n\")\n",
    "        f.write(\"The following plots have been generated:\\n\")\n",
    "        f.write(\"• crossing_probabilities.png - Local crossing probabilities vs interface position\\n\")\n",
    "        f.write(\"• flux_ratios.png - Flux ratios between consecutive interfaces\\n\")\n",
    "        f.write(\"• transition_matrix_heatmap.png - 2D transition matrix visualization\\n\")\n",
    "        f.write(\"• ensemble_weights.png - Weight distribution across ensembles\\n\")\n",
    "        f.write(\"• path_statistics.png - Path length and order parameter distributions\\n\")\n",
    "        f.write(\"• transition_fractions.png - Forward/backward/self transition fractions\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "        f.write(\"=\"*80 + \"\\n\")\n",
    "        f.write(\"Analysis complete. See istar_analysis_report.json for detailed data.\\n\")\n",
    "    \n",
    "    print(f\"Analysis report saved to:\")\n",
    "    print(f\"  JSON format: {report_file}\")\n",
    "    print(f\"  Summary format: {summary_file}\")\n",
    "    print(f\"  Visualizations: {data_dir}/plots/\")\n",
    "    \n",
    "    return report_file, summary_file\n",
    "\n",
    "def create_analysis_plots(data_dir, weight_results, weight_matrices_results, istar_global_pcross, plocs, report):\n",
    "    \"\"\"Create visualization plots for the analysis results.\"\"\"\n",
    "    \n",
    "    # Create plots directory\n",
    "    plots_dir = os.path.join(data_dir, \"plots\")\n",
    "    os.makedirs(plots_dir, exist_ok=True)\n",
    "    \n",
    "    # Set up matplotlib parameters\n",
    "    plt.style.use('default')\n",
    "    plt.rcParams['figure.figsize'] = (10, 6)\n",
    "    plt.rcParams['font.size'] = 12\n",
    "    \n",
    "    # 1. Crossing probabilities plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    interfaces = weight_results['interfaces'][:len(plocs)]\n",
    "    ax.semilogy(interfaces, plocs, 'bo-', linewidth=2, markersize=8, label='Local P_cross')\n",
    "    ax.axhline(y=float(istar_global_pcross[0]) if hasattr(istar_global_pcross, '__len__') else float(istar_global_pcross), \n",
    "               color='red', linestyle='--', linewidth=2, label=f'Global P_cross (iSTAR) = {float(istar_global_pcross[0]) if hasattr(istar_global_pcross, \"__len__\") else float(istar_global_pcross):.2e}')\n",
    "    ax.set_xlabel('Interface Position (λ)')\n",
    "    ax.set_ylabel('Crossing Probability')\n",
    "    ax.set_title('Crossing Probabilities vs Interface Position')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(plots_dir, \"crossing_probabilities.png\"), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 2. Flux ratios plot\n",
    "    if len(plocs) > 1:\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        flux_ratios = [plocs[i+1]/plocs[i] for i in range(len(plocs)-1)]\n",
    "        transition_labels = [f'λ{i} → λ{i+1}' for i in range(len(flux_ratios))]\n",
    "        bars = ax.bar(transition_labels, flux_ratios, color='skyblue', edgecolor='navy', alpha=0.7)\n",
    "        ax.set_ylabel('Flux Ratio P[i+1]/P[i]')\n",
    "        ax.set_title('Flux Ratios Between Consecutive Interfaces')\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar, ratio in zip(bars, flux_ratios):\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                   f'{ratio:.3f}', ha='center', va='bottom')\n",
    "        \n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(plots_dir, \"flux_ratios.png\"), dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    # 3. Transition matrix heatmap\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    w_matrix_2d = weight_matrices_results['weight_matrix_2d']\n",
    "    im = ax.imshow(w_matrix_2d, cmap='viridis', aspect='auto')\n",
    "    ax.set_xlabel('To Interface')\n",
    "    ax.set_ylabel('From Interface')\n",
    "    ax.set_title('2D Transition Weight Matrix')\n",
    "    \n",
    "    # Add interface labels\n",
    "    n_intf = len(weight_results['interfaces'])\n",
    "    ax.set_xticks(range(n_intf))\n",
    "    ax.set_yticks(range(n_intf))\n",
    "    ax.set_xticklabels([f'λ{i}' for i in range(n_intf)])\n",
    "    ax.set_yticklabels([f'λ{i}' for i in range(n_intf)])\n",
    "    \n",
    "    # Add colorbar\n",
    "    cbar = plt.colorbar(im, ax=ax)\n",
    "    cbar.set_label('Weight')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(plots_dir, \"transition_matrix_heatmap.png\"), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 4. Ensemble weights plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ensemble_totals = weight_matrices_results['ensemble_totals']\n",
    "    ensemble_labels = [f'Ensemble {i}' for i in range(len(ensemble_totals))]\n",
    "    bars = ax.bar(ensemble_labels, ensemble_totals, color='lightcoral', edgecolor='darkred', alpha=0.7)\n",
    "    ax.set_ylabel('Total Weight')\n",
    "    ax.set_title('Weight Distribution Across Ensembles')\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, weight in zip(bars, ensemble_totals):\n",
    "        height = bar.get_height()\n",
    "        if height > 0:\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height + max(ensemble_totals)*0.01,\n",
    "                   f'{weight:.0f}', ha='center', va='bottom', rotation=0)\n",
    "    \n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(plots_dir, \"ensemble_weights.png\"), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 5. Path statistics plot\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Path lengths histogram\n",
    "    path_lengths = weight_results['path_data']['len'][:, 0]\n",
    "    ax1.hist(path_lengths, bins=50, alpha=0.7, color='green', edgecolor='black')\n",
    "    ax1.set_xlabel('Path Length')\n",
    "    ax1.set_ylabel('Frequency')\n",
    "    ax1.set_title('Path Length Distribution')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Order parameter histogram\n",
    "    maxops = weight_results['path_data']['maxop'][:, 0]\n",
    "    ax2.hist(maxops, bins=50, alpha=0.7, color='orange', edgecolor='black')\n",
    "    ax2.set_xlabel('Maximum Order Parameter')\n",
    "    ax2.set_ylabel('Frequency')\n",
    "    ax2.set_title('Order Parameter Distribution')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add interface lines to order parameter plot\n",
    "    for i, intf in enumerate(weight_results['interfaces']):\n",
    "        ax2.axvline(x=intf, color='red', linestyle='--', alpha=0.7, label=f'λ{i}' if i < 3 else '')\n",
    "    if len(weight_results['interfaces']) <= 3:\n",
    "        ax2.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(plots_dir, \"path_statistics.png\"), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 6. Transition fractions pie chart\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    transition_summary = weight_matrices_results['transition_summary']\n",
    "    \n",
    "    labels = ['Forward\\nTransitions', 'Backward\\nTransitions', 'Self\\nTransitions']\n",
    "    sizes = [\n",
    "        transition_summary['forward_weight_fraction'],\n",
    "        transition_summary['backward_weight_fraction'],\n",
    "        transition_summary['self_weight_fraction']\n",
    "    ]\n",
    "    colors = ['lightblue', 'lightgreen', 'lightyellow']\n",
    "    explode = (0.05, 0.05, 0.05)  # slightly separate all slices\n",
    "    \n",
    "    wedges, texts, autotexts = ax.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%',\n",
    "                                     explode=explode, shadow=True, startangle=90)\n",
    "    \n",
    "    ax.set_title('Transition Weight Fractions')\n",
    "    \n",
    "    # Make percentage text more readable\n",
    "    for autotext in autotexts:\n",
    "        autotext.set_color('black')\n",
    "        autotext.set_fontweight('bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(plots_dir, \"transition_fractions.png\"), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"✓ Generated 6 visualization plots in {plots_dir}/\")\n",
    "\n",
    "# Generate and save the report\n",
    "print(\"=== GENERATING ANALYSIS REPORT ===\")\n",
    "\n",
    "if all([var in locals() for var in ['weight_results', 'weight_matrices_results', 'istar_global_pcross', 'plocs']]):\n",
    "    try:\n",
    "        json_file, summary_file = save_analysis_report(\n",
    "            DATA_DIR, \n",
    "            weight_results, \n",
    "            weight_matrices_results, \n",
    "            istar_global_pcross, \n",
    "            plocs\n",
    "        )\n",
    "        \n",
    "        print(f\"\\n✓ Report generation successful!\")\n",
    "        print(f\"\\nReport contents:\")\n",
    "        print(f\"• System configuration and interface setup\")\n",
    "        print(f\"• Global and local crossing probabilities\")\n",
    "        print(f\"• Transition matrix analysis and statistics\")\n",
    "        print(f\"• Path and ensemble weight distributions\")\n",
    "        print(f\"• Per-interface detailed analysis\")\n",
    "        print(f\"• Complete 2D transition matrix data\")\n",
    "        print(f\"• Visual plots of key analysis results\")\n",
    "        \n",
    "        # Show a preview of the summary file\n",
    "        print(f\"\\n--- SUMMARY PREVIEW ---\")\n",
    "        with open(summary_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        for line in lines[:25]:  # Show first 25 lines\n",
    "            print(line.rstrip())\n",
    "        if len(lines) > 25:\n",
    "            print(f\"... ({len(lines)-25} more lines)\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error generating report: {e}\")\n",
    "        \n",
    "else:\n",
    "    missing_vars = [var for var in ['weight_results', 'weight_matrices_results', 'istar_global_pcross', 'plocs'] \n",
    "                   if var not in locals()]\n",
    "    print(f\"✗ Cannot generate report. Missing variables: {missing_vars}\")\n",
    "    print(\"Please run the previous analysis cells first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244f99f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "363fa080",
   "metadata": {},
   "source": [
    "# WHAM Implementation for Weight Matrices\n",
    "\n",
    "This section implements the Weighted Histogram Analysis Method (WHAM) adapted for transition weight matrices. Instead of treating order parameter values as histogram bins, we treat each transition `[j,k]` as a \"bin\" that can be sampled by multiple ensembles with different statistical weights.\n",
    "\n",
    "## Theoretical Foundation\n",
    "\n",
    "In traditional WHAM for TIS:\n",
    "- Each ensemble `i` provides histogram counts `N_i(λ)` at order parameter `λ`\n",
    "- WHAM finds optimal Q-factors to combine overlapping ensemble data\n",
    "- The result is an unbiased probability density `ρ(λ)`\n",
    "\n",
    "In our matrix WHAM:\n",
    "- Each ensemble `i` provides weight counts `W_i[j,k]` for transition `j→k`\n",
    "- WHAM finds optimal Q-factors to combine overlapping ensemble data\n",
    "- The result is an unbiased transition weight matrix `W_WHAM[j,k]`\n",
    "\n",
    "The key adaptation is recognizing that transitions `[j,k]` play the role of histogram bins in the traditional formulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "97b202ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WHAM implementation for weight matrices defined successfully!\n"
     ]
    }
   ],
   "source": [
    "def wham_weight_matrices(weight_matrix_3d: Dict, interfaces: List[float], \n",
    "                        max_iterations: int = 1000, tolerance: float = 1e-8,\n",
    "                        verbose: bool = True) -> Dict:\n",
    "    \"\"\"\n",
    "    Apply WHAM to weight matrices from multiple ensembles.\n",
    "    \n",
    "    This function implements WHAM for transition weight matrices, treating each\n",
    "    transition [j,k] as a histogram bin that can be sampled by multiple ensembles.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    weight_matrix_3d : Dict\n",
    "        Dictionary of weight matrices {ensemble_i: matrix[j,k]}\n",
    "    interfaces : List[float]\n",
    "        List of interface positions\n",
    "    max_iterations : int\n",
    "        Maximum number of WHAM iterations\n",
    "    tolerance : float\n",
    "        Convergence tolerance for Q-factors\n",
    "    verbose : bool\n",
    "        Print convergence information\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    Dict containing:\n",
    "        - wham_matrix: WHAM-optimized weight matrix [j,k]\n",
    "        - q_factors: Optimal Q-factors for each ensemble\n",
    "        - convergence_info: Information about convergence\n",
    "        - ensemble_weights: Total weight per ensemble after WHAM\n",
    "    \"\"\"\n",
    "    \n",
    "    n_ensembles = len(weight_matrix_3d)\n",
    "    n_interfaces = len(interfaces)\n",
    "    \n",
    "    print(f\"Starting WHAM for {n_ensembles} ensembles, {n_interfaces} interfaces\")\n",
    "    print(f\"Max iterations: {max_iterations}, tolerance: {tolerance}\")\n",
    "    \n",
    "    # Extract individual matrices and compute total weights per ensemble\n",
    "    matrices = []\n",
    "    eta = []  # Total weight per ensemble (analogous to η_i in traditional WHAM)\n",
    "    \n",
    "    for i in range(n_ensembles):\n",
    "        matrix = weight_matrix_3d[i]\n",
    "        matrices.append(matrix)\n",
    "        eta.append(np.sum(np.triu(matrix)))\n",
    "        if verbose:\n",
    "            print(f\"Ensemble {i}: total weight = {eta[i]:.6f}\")\n",
    "    \n",
    "    # Initialize Q-factors (analogous to partition function ratios)\n",
    "    Q = np.ones(n_ensembles)\n",
    "    \n",
    "    # Define which ensembles can sample which transitions\n",
    "    # This is crucial - each ensemble i can primarily sample transitions \n",
    "    # involving interface i (similar to how ensemble [i+] samples around λ_i)\n",
    "    def ensemble_can_sample_transition(ensemble_idx, j, k):\n",
    "        \"\"\"\n",
    "        Determine if ensemble i can sample transition j→k.\n",
    "        This follows TIS logic where ensemble [i+] samples transitions \n",
    "        from interface i to higher interfaces.\n",
    "        \"\"\"\n",
    "        # Ensemble i can sample transitions starting from interface i\n",
    "        # and some neighboring transitions (overlapping regions)\n",
    "        if ensemble_idx <= 0:\n",
    "            return False\n",
    "        elif ensemble_idx == 1 and j == k == 0:\n",
    "            return True\n",
    "        elif j < k and j <= ensemble_idx-1 < k and j == 0:\n",
    "            return True\n",
    "        # elif j > k and k < ensemble_idx-1 <= j:\n",
    "        #     return True\n",
    "        return False\n",
    "    \n",
    "    # WHAM iteration\n",
    "    convergence_history = []\n",
    "    \n",
    "    for iteration in range(max_iterations):\n",
    "        Q_old = Q.copy()\n",
    "        \n",
    "        # Step 1: Compute unbiased weight matrix\n",
    "        # W_unbiased[j,k] = Σ_i η_i * W_i[j,k] / Σ_l η_l * Q_l * δ_il\n",
    "        # where δ_il indicates if ensemble l can sample transition [j,k]\n",
    "        \n",
    "        wham_matrix = np.zeros((n_interfaces, n_interfaces))\n",
    "        \n",
    "        for j in range(n_interfaces):\n",
    "            for k in range(n_interfaces):\n",
    "                numerator = 0.0\n",
    "                denominator = 0.0\n",
    "                \n",
    "                # Sum over all ensembles\n",
    "                for i in range(n_ensembles):\n",
    "                    if eta[i] > 0 and ensemble_can_sample_transition(i, j, k):\n",
    "                        w_ijk = matrices[i][j, k]\n",
    "                        numerator += eta[i] * w_ijk\n",
    "                        denominator += eta[i] * Q[i]\n",
    "                \n",
    "                if denominator > 0:\n",
    "                    wham_matrix[j, k] = numerator / denominator\n",
    "        \n",
    "        # Step 2: Update Q-factors\n",
    "        # Q_i = Σ_{j,k} W_unbiased[j,k] * δ_ij (sum over transitions ensemble i can sample)\n",
    "        for i in range(n_ensembles):\n",
    "            Q_new = 0.0\n",
    "            for j in range(n_interfaces):\n",
    "                for k in range(n_interfaces):\n",
    "                    if ensemble_can_sample_transition(i, j, k):\n",
    "                        Q_new += wham_matrix[j, k]\n",
    "            \n",
    "            # Avoid division by zero\n",
    "            if Q_new > 0:\n",
    "                Q[i] = Q_new\n",
    "            else:\n",
    "                Q[i] = 1e-10  # Small positive value to avoid numerical issues\n",
    "        \n",
    "        # Normalize Q-factors (optional, helps with numerical stability)\n",
    "        Q_sum = np.sum(Q)\n",
    "        if Q_sum > 0:\n",
    "            Q = Q / Q_sum * n_ensembles\n",
    "        \n",
    "        # Check convergence\n",
    "        max_change = np.max(np.abs(Q - Q_old))\n",
    "        convergence_history.append(max_change)\n",
    "        \n",
    "        if verbose and (iteration % 100 == 0 or iteration < 10):\n",
    "            print(f\"Iteration {iteration}: max Q change = {max_change:.2e}\")\n",
    "            print(f\"  Q-factors: {[f'{q:.6f}' for q in Q]}\")\n",
    "        \n",
    "        if max_change < tolerance:\n",
    "            if verbose:\n",
    "                print(f\"Converged after {iteration + 1} iterations\")\n",
    "            break\n",
    "    else:\n",
    "        if verbose:\n",
    "            print(f\"Warning: Maximum iterations ({max_iterations}) reached without convergence\")\n",
    "    \n",
    "    # Calculate final ensemble weights (total weight each ensemble contributes to WHAM result)\n",
    "    ensemble_weights = np.zeros(n_ensembles)\n",
    "    for i in range(n_ensembles):\n",
    "        weight_contribution = 0.0\n",
    "        for j in range(n_interfaces):\n",
    "            for k in range(n_interfaces):\n",
    "                if ensemble_can_sample_transition(i, j, k) and eta[i] > 0:\n",
    "                    # Weight contribution = η_i * Q_i * W_WHAM[j,k] / Σ_l η_l * Q_l\n",
    "                    denominator = sum(eta[l] * Q[l] for l in range(n_ensembles) \n",
    "                                    if ensemble_can_sample_transition(l, j, k))\n",
    "                    if denominator > 0:\n",
    "                        weight_contribution += eta[i] * Q[i] * wham_matrix[j, k] / denominator\n",
    "        ensemble_weights[i] = weight_contribution\n",
    "    \n",
    "    # Prepare results\n",
    "    results = {\n",
    "        'wham_matrix': wham_matrix,\n",
    "        'q_factors': Q,\n",
    "        'convergence_info': {\n",
    "            'iterations': min(iteration + 1, max_iterations),\n",
    "            'converged': max_change < tolerance,\n",
    "            'final_change': max_change,\n",
    "            'convergence_history': convergence_history\n",
    "        },\n",
    "        'ensemble_weights': ensemble_weights,\n",
    "        'original_eta': eta\n",
    "    }\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\n=== WHAM Results ===\")\n",
    "        print(f\"Final Q-factors: {[f'{q:.6f}' for q in Q]}\")\n",
    "        print(f\"Total WHAM matrix weight: {np.sum(wham_matrix):.6f}\")\n",
    "        print(f\"Original total weight: {sum(eta):.6f}\")\n",
    "        print(f\"Ensemble contributions to WHAM: {[f'{w:.6f}' for w in ensemble_weights]}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"WHAM implementation for weight matrices defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "656890c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WHAM analysis and visualization functions defined successfully!\n"
     ]
    }
   ],
   "source": [
    "def compare_wham_results(weight_matrices_result: Dict, wham_result: Dict) -> None:\n",
    "    \"\"\"\n",
    "    Compare original weight matrices with WHAM-optimized results.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    weight_matrices_result : Dict\n",
    "        Original weight matrices from compute_weight_matrices_weights\n",
    "    wham_result : Dict\n",
    "        WHAM results from wham_weight_matrices\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"COMPARISON: Original vs WHAM Weight Matrices\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Extract matrices\n",
    "    original_matrix = weight_matrices_result['weight_matrix_2d']\n",
    "    wham_matrix = wham_result['wham_matrix']\n",
    "    \n",
    "    print(f\"\\n1. Original combined matrix (sum over ensembles):\")\n",
    "    print(np.array2string(original_matrix, precision=4, suppress_small=True))\n",
    "    \n",
    "    print(f\"\\n2. WHAM-optimized matrix:\")\n",
    "    print(np.array2string(wham_matrix, precision=4, suppress_small=True))\n",
    "    \n",
    "    print(f\"\\n3. Difference (WHAM - Original):\")\n",
    "    diff_matrix = wham_matrix - original_matrix\n",
    "    print(np.array2string(diff_matrix, precision=4, suppress_small=True))\n",
    "    \n",
    "    # Statistical comparison\n",
    "    total_original = np.sum(original_matrix)\n",
    "    total_wham = np.sum(wham_matrix)\n",
    "    \n",
    "    print(f\"\\n4. Statistical Summary:\")\n",
    "    print(f\"   Original total weight: {total_original:.6f}\")\n",
    "    print(f\"   WHAM total weight:     {total_wham:.6f}\")\n",
    "    print(f\"   Relative change:       {((total_wham - total_original) / total_original * 100):.2f}%\")\n",
    "    \n",
    "    # Element-wise relative differences\n",
    "    rel_diff = np.zeros_like(diff_matrix)\n",
    "    mask = original_matrix > 0\n",
    "    rel_diff[mask] = diff_matrix[mask] / original_matrix[mask] * 100\n",
    "    \n",
    "    print(f\"\\n5. Relative differences (%) where original > 0:\")\n",
    "    print(np.array2string(rel_diff, precision=1, suppress_small=True))\n",
    "    \n",
    "    # Identify significant changes\n",
    "    significant_changes = np.abs(rel_diff) > 10  # > 10% change\n",
    "    if np.any(significant_changes):\n",
    "        print(f\"\\n6. Significant changes (>10%):\")\n",
    "        for j in range(significant_changes.shape[0]):\n",
    "            for k in range(significant_changes.shape[1]):\n",
    "                if significant_changes[j, k]:\n",
    "                    print(f\"   Transition [{j},{k}]: {rel_diff[j,k]:.1f}% change \"\n",
    "                          f\"({original_matrix[j,k]:.4f} → {wham_matrix[j,k]:.4f})\")\n",
    "    else:\n",
    "        print(f\"\\n6. No significant changes (>10%) detected\")\n",
    "\n",
    "def plot_wham_convergence(wham_result: Dict) -> None:\n",
    "    \"\"\"\n",
    "    Plot WHAM convergence history.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    wham_result : Dict\n",
    "        WHAM results containing convergence history\n",
    "    \"\"\"\n",
    "    \n",
    "    convergence_history = wham_result['convergence_info']['convergence_history']\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.semilogy(convergence_history, 'b-', linewidth=2)\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Max |ΔQ|')\n",
    "    plt.title('WHAM Convergence History')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add convergence line\n",
    "    tolerance = 1e-8  # Default tolerance\n",
    "    plt.axhline(y=tolerance, color='r', linestyle='--', alpha=0.7, \n",
    "                label=f'Tolerance ({tolerance:.0e})')\n",
    "    \n",
    "    # Mark convergence point\n",
    "    converged_at = wham_result['convergence_info']['iterations']\n",
    "    if converged_at < len(convergence_history):\n",
    "        plt.axvline(x=converged_at, color='g', linestyle='--', alpha=0.7,\n",
    "                   label=f'Converged at iteration {converged_at}')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Convergence Summary:\")\n",
    "    print(f\"  - Converged: {wham_result['convergence_info']['converged']}\")\n",
    "    print(f\"  - Iterations: {wham_result['convergence_info']['iterations']}\")\n",
    "    print(f\"  - Final change: {wham_result['convergence_info']['final_change']:.2e}\")\n",
    "\n",
    "def analyze_ensemble_contributions(wham_result: Dict) -> None:\n",
    "    \"\"\"\n",
    "    Analyze how much each ensemble contributes to the WHAM result.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    wham_result : Dict\n",
    "        WHAM results containing ensemble information\n",
    "    \"\"\"\n",
    "    \n",
    "    q_factors = wham_result['q_factors']\n",
    "    ensemble_weights = wham_result['ensemble_weights']\n",
    "    original_eta = wham_result['original_eta']\n",
    "    \n",
    "    print(\"=\"*50)\n",
    "    print(\"ENSEMBLE CONTRIBUTION ANALYSIS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    print(f\"\\nEnsemble Analysis:\")\n",
    "    print(f\"{'Ensemble':<10} {'Original η':<12} {'Q-factor':<12} {'WHAM Weight':<12} {'Contribution %':<15}\")\n",
    "    print(\"-\" * 65)\n",
    "    \n",
    "    total_wham_weight = sum(ensemble_weights)\n",
    "    \n",
    "    for i in range(len(q_factors)):\n",
    "        contribution_pct = (ensemble_weights[i] / total_wham_weight * 100) if total_wham_weight > 0 else 0\n",
    "        print(f\"{i:<10} {original_eta[i]:<12.6f} {q_factors[i]:<12.6f} \"\n",
    "              f\"{ensemble_weights[i]:<12.6f} {contribution_pct:<15.1f}\")\n",
    "    \n",
    "    print(\"-\" * 65)\n",
    "    print(f\"{'Total':<10} {sum(original_eta):<12.6f} {sum(q_factors):<12.6f} \"\n",
    "          f\"{total_wham_weight:<12.6f} {100.0:<15.1f}\")\n",
    "    \n",
    "    # Identify dominant ensembles\n",
    "    max_contribution = max(ensemble_weights)\n",
    "    dominant_ensemble = np.where(ensemble_weights == max_contribution)[0][0]\n",
    "    \n",
    "    print(f\"\\nKey Insights:\")\n",
    "    print(f\"  - Dominant ensemble: {dominant_ensemble} ({max_contribution/total_wham_weight*100:.1f}% contribution)\")\n",
    "    print(f\"  - Q-factor range: {min(q_factors):.6f} to {max(q_factors):.6f}\")\n",
    "    print(f\"  - Original η range: {min(original_eta):.6f} to {max(original_eta):.6f}\")\n",
    "\n",
    "print(\"WHAM analysis and visualization functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aedee7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WHAM q-probability implementation defined successfully!\n"
     ]
    }
   ],
   "source": [
    "def wham_q_probabilities(weight_matrix_3d: Dict, interfaces: List[float], \n",
    "                        max_iterations: int = 1000, tolerance: float = 1e-8,\n",
    "                        verbose: bool = True) -> Dict:\n",
    "    \"\"\"\n",
    "    Apply WHAM to calculate q probabilities using the same logic as get_transition_probs_weights.\n",
    "    \n",
    "    This function implements WHAM for each q[i][k] probability calculation, using exactly \n",
    "    the same weight extraction logic as in get_transition_probs_weights but with WHAM \n",
    "    optimization across the relevant ensembles.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    weight_matrix_3d : Dict\n",
    "        Dictionary of weight matrices {ensemble_i: matrix[j,k]}\n",
    "    interfaces : List[float]\n",
    "        List of interface positions\n",
    "    max_iterations : int\n",
    "        Maximum number of WHAM iterations\n",
    "    tolerance : float\n",
    "        Convergence tolerance for Q-factors\n",
    "    verbose : bool\n",
    "        Print convergence information\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    Dict containing:\n",
    "        - q_matrix: WHAM-optimized q probability matrix [i,k]\n",
    "        - p_matrix: Final transition probabilities computed from q\n",
    "        - q_factors_per_transition: Q-factors for each transition calculation\n",
    "        - convergence_info: Information about convergence for each transition\n",
    "    \"\"\"\n",
    "    \n",
    "    n_interfaces = len(interfaces)\n",
    "\n",
    "    print(f\"Starting WHAM for q probabilities with {len(weight_matrix_3d)} ensembles, {n_interfaces} interfaces\")\n",
    "    \n",
    "    # Initialize results\n",
    "    q_matrix = np.ones([n_interfaces, n_interfaces])\n",
    "    q_factors_per_transition = {}\n",
    "    convergence_info_per_transition = {}\n",
    "    \n",
    "    # Calculate q(i,k) using WHAM for each transition - mirroring get_transition_probs_weights logic\n",
    "    for i in range(n_interfaces):\n",
    "        for k in range(n_interfaces):\n",
    "            if verbose:\n",
    "                print(f\"\\n--- Computing WHAM q[{i}][{k}] ---\")\n",
    "            \n",
    "            # Extract the same weight subsets as in get_transition_probs_weights\n",
    "            if i == k:\n",
    "                # Self-transitions\n",
    "                if i == 0:\n",
    "                    q_matrix[i][k] = 1  # Probability to return to 0 is 1\n",
    "                    continue\n",
    "                else:\n",
    "                    q_matrix[i][k] = 0  # No self-transitions for other interfaces\n",
    "                    continue\n",
    "            elif i == 0 and k == 1:\n",
    "                # Special case: transition from 0 to 1\n",
    "                # Use ensemble i+1=1, weights weight_matrix_3d[1][0][k:] vs weight_matrix_3d[1][0][k-1:]\n",
    "                ensemble_list = [1]\n",
    "                numerator_weights = {1: np.sum(weight_matrix_3d[1][i][k:])}  # weight_matrix_3d[1][0][1:]\n",
    "                denominator_weights = {1: np.sum(weight_matrix_3d[1][i][k-1:])}  # weight_matrix_3d[1][0][0:]\n",
    "                \n",
    "            elif i < k:\n",
    "                # Forward transitions (L→R)\n",
    "                ensemble_list = []\n",
    "                numerator_weights = {}\n",
    "                denominator_weights = {}\n",
    "                \n",
    "                for pe_i in range(i+1, k+1):\n",
    "                    if pe_i > n_interfaces-1 or pe_i not in weight_matrix_3d:\n",
    "                        continue\n",
    "                    ensemble_list.append(pe_i)\n",
    "                    ratio = np.sum(weight_matrix_3d[pe_i][i][k-1:]) / np.sum(weight_matrix_3d[pe_i])\n",
    "                    numerator_weights[pe_i] = np.sum(weight_matrix_3d[pe_i][i][k:])/ratio\n",
    "                    denominator_weights[pe_i] = np.sum(weight_matrix_3d[pe_i][i][k-1:])/ratio\n",
    "\n",
    "            elif i > k:\n",
    "                # Backward transitions (R→L)\n",
    "                ensemble_list = []\n",
    "                numerator_weights = {}\n",
    "                denominator_weights = {}\n",
    "                \n",
    "                for pe_i in range(k+2, i+2):\n",
    "                    if pe_i > n_interfaces-1 or pe_i not in weight_matrix_3d:\n",
    "                        continue\n",
    "                    ensemble_list.append(pe_i)\n",
    "                    ratio = np.sum(weight_matrix_3d[pe_i][i][:k+2]) / np.sum(weight_matrix_3d[pe_i])\n",
    "                    numerator_weights[pe_i] = np.sum(weight_matrix_3d[pe_i][i][:k+1])/ratio\n",
    "                    denominator_weights[pe_i] = np.sum(weight_matrix_3d[pe_i][i][:k+2])/ratio\n",
    "            \n",
    "            # Skip if no relevant ensembles\n",
    "            if not ensemble_list:\n",
    "                q_matrix[i][k] = 0\n",
    "                continue\n",
    "            \n",
    "            # Apply WHAM to these specific weights\n",
    "            wham_result = apply_wham_to_transition_weights(\n",
    "                ensemble_list, numerator_weights, denominator_weights,\n",
    "                max_iterations, tolerance, verbose  # Limit verbose output\n",
    "            )\n",
    "            \n",
    "            q_matrix[i][k] = wham_result['probability']\n",
    "            q_factors_per_transition[(i,k)] = wham_result['q_factors']\n",
    "            convergence_info_per_transition[(i,k)] = wham_result['convergence_info']\n",
    "            \n",
    "            if verbose:  # Limit output\n",
    "                print(f\"  q[{i}][{k}] = {q_matrix[i][k]:.6f} (ensembles: {ensemble_list})\")\n",
    "\n",
    "    # Artificial probability to allow computation of p[i][k] for last interface\n",
    "    q_matrix[-1][-2] = 1\n",
    "    \n",
    "    print(\"\\nWHAM-optimized q matrix:\")\n",
    "    print(np.array2string(q_matrix, precision=4, suppress_small=True))\n",
    "    \n",
    "    # Calculate final transition probabilities p(i,k) from WHAM q values\n",
    "    # This follows the exact same logic as in get_transition_probs_weights\n",
    "    p_matrix = np.empty([n_interfaces, n_interfaces])\n",
    "    \n",
    "    for i in range(n_interfaces):\n",
    "        for k in range(n_interfaces):\n",
    "            if i < k:\n",
    "                # Forward transitions\n",
    "                if k == n_interfaces-1:\n",
    "                    p_matrix[i][k] = np.prod(q_matrix[i][i+1:k+1])\n",
    "                else:\n",
    "                    p_matrix[i][k] = np.prod(q_matrix[i][i+1:k+1]) * (1-q_matrix[i][k+1])\n",
    "            elif k < i:\n",
    "                # Backward transitions\n",
    "                if k == 0:\n",
    "                    p_matrix[i][k] = np.prod(q_matrix[i][k:i])\n",
    "                else:\n",
    "                    p_matrix[i][k] = np.prod(q_matrix[i][k:i]) * (1-q_matrix[i][k-1])\n",
    "            else:\n",
    "                # Self-transitions\n",
    "                if i == 0:\n",
    "                    p_matrix[i][k] = 1-q_matrix[i][1]\n",
    "                else:\n",
    "                    p_matrix[i][k] = 0\n",
    "    \n",
    "    print(\"\\nWHAM-optimized p matrix:\")\n",
    "    print(np.array2string(p_matrix, precision=4, suppress_small=True))\n",
    "    \n",
    "    return {\n",
    "        'q_matrix': q_matrix,\n",
    "        'p_matrix': p_matrix,\n",
    "        'q_factors_per_transition': q_factors_per_transition,\n",
    "        'convergence_info_per_transition': convergence_info_per_transition\n",
    "    }\n",
    "\n",
    "\n",
    "def apply_wham_to_transition_weights(ensemble_list, numerator_weights, denominator_weights,\n",
    "                                   max_iterations=1000, tolerance=1e-8, verbose=False):\n",
    "    \"\"\"\n",
    "    Apply WHAM to a specific transition's weights extracted for q[i][k] calculation.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    ensemble_list : List[int]\n",
    "        List of ensemble indices that contribute to this transition\n",
    "    numerator_weights : Dict[int, float]\n",
    "        Weight in numerator for each ensemble (counts[0] in original)\n",
    "    denominator_weights : Dict[int, float]\n",
    "        Weight in denominator for each ensemble (counts[1] in original)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    Dict with probability, q_factors, and convergence_info\n",
    "    \"\"\"\n",
    "    \n",
    "    if not ensemble_list:\n",
    "        return {'probability': 0.0, 'q_factors': {}, 'convergence_info': {'converged': True}}\n",
    "    \n",
    "    # Handle single ensemble case (no WHAM needed)\n",
    "    if len(ensemble_list) == 1:\n",
    "        ens = ensemble_list[0]\n",
    "        if denominator_weights[ens] > 0:\n",
    "            prob = numerator_weights[ens] / denominator_weights[ens]\n",
    "        else:\n",
    "            prob = 0.0\n",
    "        return {\n",
    "            'probability': prob,\n",
    "            'q_factors': {ens: 1.0},\n",
    "            'convergence_info': {'converged': True, 'iterations': 0}\n",
    "        }\n",
    "    \n",
    "    # Multiple ensembles - apply WHAM\n",
    "    n_ensembles = len(ensemble_list)\n",
    "    \n",
    "    # Initialize Q-factors\n",
    "    Q = np.ones(n_ensembles)\n",
    "    \n",
    "    # WHAM iterations\n",
    "    for iteration in range(max_iterations):\n",
    "        Q_old = Q.copy()\n",
    "        \n",
    "        # Calculate unbiased estimate: numerator / Σ_i η_i * Q_i\n",
    "        total_denominator = 0.0\n",
    "        total_numerator = 0.0\n",
    "        \n",
    "        for idx, ens in enumerate(ensemble_list):\n",
    "            if denominator_weights[ens] > 0:  # η_i equivalent\n",
    "                total_denominator += denominator_weights[ens] * Q[idx]\n",
    "                total_numerator += numerator_weights[ens]\n",
    "        \n",
    "        # Update Q-factors: Q_i = sampling_weight_i * prob_estimate\n",
    "        # In this case, sampling weight is the denominator weight (how much this ensemble samples)\n",
    "        prob_estimate = total_numerator / total_denominator if total_denominator > 0 else 0\n",
    "        \n",
    "        for idx, ens in enumerate(ensemble_list):\n",
    "            if denominator_weights[ens] > 0:\n",
    "                Q[idx] = denominator_weights[ens] * prob_estimate\n",
    "            else:\n",
    "                Q[idx] = 1e-10\n",
    "        \n",
    "        # Normalize Q-factors\n",
    "        Q_sum = np.sum(Q)\n",
    "        if Q_sum > 0:\n",
    "            Q = Q / Q_sum * n_ensembles\n",
    "        \n",
    "        # Check convergence\n",
    "        max_change = np.max(np.abs(Q - Q_old))\n",
    "        \n",
    "        if verbose and iteration < 5:\n",
    "            print(f\"    WHAM iter {iteration}: change = {max_change:.2e}, Q = {Q}\")\n",
    "        \n",
    "        if max_change < tolerance:\n",
    "            break\n",
    "    \n",
    "    # Final probability calculation\n",
    "    total_denominator = 0.0\n",
    "    total_numerator = 0.0\n",
    "    \n",
    "    for idx, ens in enumerate(ensemble_list):\n",
    "        if denominator_weights[ens] > 0:\n",
    "            total_denominator += denominator_weights[ens] * Q[idx]\n",
    "            total_numerator += numerator_weights[ens]\n",
    "    \n",
    "    final_probability = total_numerator / total_denominator if total_denominator > 0 else 0.0\n",
    "    \n",
    "    # Convert Q back to dict with ensemble keys\n",
    "    q_factors_dict = {ensemble_list[idx]: Q[idx] for idx in range(len(ensemble_list))}\n",
    "    \n",
    "    return {\n",
    "        'probability': final_probability,\n",
    "        'q_factors': q_factors_dict,\n",
    "        'convergence_info': {\n",
    "            'converged': max_change < tolerance,\n",
    "            'iterations': min(iteration + 1, max_iterations),\n",
    "            'final_change': max_change\n",
    "        }\n",
    "    }\n",
    "\n",
    "print(\"WHAM q-probability implementation defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6fed29c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q-probability comparison function defined successfully!\n"
     ]
    }
   ],
   "source": [
    "def compare_q_probability_results(original_results: Dict, wham_q_results: Dict) -> None:\n",
    "    \"\"\"\n",
    "    Compare original q probabilities with WHAM-optimized q probabilities.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    original_results : Dict\n",
    "        Results from get_transition_probs_weights (contains 'q_matrix' and 'p_matrix')\n",
    "    wham_q_results : Dict\n",
    "        Results from wham_q_probabilities\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=== Comparison: Original vs WHAM Q-Probabilities ===\\n\")\n",
    "    \n",
    "    original_q = original_results['q_matrix']\n",
    "    original_p = original_results['p_matrix']\n",
    "    wham_q = wham_q_results['q_matrix']\n",
    "    wham_p = wham_q_results['p_matrix']\n",
    "    \n",
    "    print(\"Original Q Matrix:\")\n",
    "    print(np.array2string(original_q, precision=4, suppress_small=True))\n",
    "    print(\"\\nWHAM Q Matrix:\")\n",
    "    print(np.array2string(wham_q, precision=4, suppress_small=True))\n",
    "    \n",
    "    print(\"\\nOriginal P Matrix:\")\n",
    "    print(np.array2string(original_p, precision=4, suppress_small=True))\n",
    "    print(\"\\nWHAM P Matrix:\")\n",
    "    print(np.array2string(wham_p, precision=4, suppress_small=True))\n",
    "    \n",
    "    # Calculate differences\n",
    "    q_diff = wham_q - original_q\n",
    "    p_diff = wham_p - original_p\n",
    "    \n",
    "    print(\"\\nQ Matrix Differences (WHAM - Original):\")\n",
    "    print(np.array2string(q_diff, precision=4, suppress_small=True))\n",
    "    print(\"\\nP Matrix Differences (WHAM - Original):\")\n",
    "    print(np.array2string(p_diff, precision=4, suppress_small=True))\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(f\"\\nQ Matrix Changes:\")\n",
    "    print(f\"  Max absolute difference: {np.max(np.abs(q_diff)):.6f}\")\n",
    "    print(f\"  Mean absolute difference: {np.mean(np.abs(q_diff)):.6f}\")\n",
    "    print(f\"  RMS difference: {np.sqrt(np.mean(q_diff**2)):.6f}\")\n",
    "    \n",
    "    print(f\"\\nP Matrix Changes:\")\n",
    "    print(f\"  Max absolute difference: {np.max(np.abs(p_diff)):.6f}\")\n",
    "    print(f\"  Mean absolute difference: {np.mean(np.abs(p_diff)):.6f}\")\n",
    "    print(f\"  RMS difference: {np.sqrt(np.mean(p_diff**2)):.6f}\")\n",
    "    \n",
    "    # Analyze convergence information\n",
    "    if 'q_factors_per_transition' in wham_q_results:\n",
    "        print(f\"\\n=== WHAM Convergence Analysis ===\")\n",
    "        converged_transitions = 0\n",
    "        total_transitions = 0\n",
    "        \n",
    "        for (i, k), conv_info in wham_q_results['convergence_info_per_transition'].items():\n",
    "            total_transitions += 1\n",
    "            if conv_info['converged']:\n",
    "                converged_transitions += 1\n",
    "            \n",
    "            if i <= 2 and k <= 2:  # Show details for first few transitions\n",
    "                print(f\"  q[{i}][{k}]: converged={conv_info['converged']}, \"\n",
    "                      f\"iterations={conv_info.get('iterations', 'N/A')}\")\n",
    "        \n",
    "        print(f\"\\nConvergence summary: {converged_transitions}/{total_transitions} transitions converged\")\n",
    "\n",
    "print(\"Q-probability comparison function defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976d1aab",
   "metadata": {},
   "source": [
    "## WHAM for Q-Probabilities\n",
    "\n",
    "The `wham_q_probabilities` function implements WHAM optimization for the specific weight subsets used in calculating the q-probabilities matrix in `get_transition_probs_weights`. \n",
    "\n",
    "### Key Differences from Matrix WHAM:\n",
    "\n",
    "1. **Selective Weight Extraction**: Instead of applying WHAM to entire weight matrices, this function extracts the exact same weight subsets that `get_transition_probs_weights` uses for each q[i,k] calculation.\n",
    "\n",
    "2. **Transition-Specific WHAM**: Each q[i,k] probability gets its own WHAM optimization using only the ensembles and weight ranges that contribute to that specific transition probability.\n",
    "\n",
    "3. **Follows iSTAR Logic**: \n",
    "   - Forward transitions (i < k): Uses ensembles pe_i ∈ [i+1, k] with weights w_path[pe_i][i][k:] vs w_path[pe_i][i][k-1:]\n",
    "   - Backward transitions (i > k): Uses ensembles pe_i ∈ [k+2, i+1] with weights w_path[pe_i][i][:k+1] vs w_path[pe_i][i][:k+2]\n",
    "   - Special cases: Handles i=k and i=0,k=1 transitions following the original logic\n",
    "\n",
    "4. **Per-Transition Q-Factors**: Each transition calculation has its own set of Q-factors optimized for the specific ensembles contributing to that transition.\n",
    "\n",
    "This approach ensures that WHAM is applied to exactly the same data subsets that would be used in the non-WHAM q-probability calculation, providing optimal statistical combination while preserving the physical meaning of each transition probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "24550f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying WHAM to q-probability calculations...\n",
      "Calculating original q and p probabilities...\n",
      "Warning: Zero count detected for q[3][4] = 0.0, counts = [0. 0.]\n",
      "Warning: Zero count detected for q[4][3] = 0.0, counts = [0. 0.]\n",
      "\n",
      "Intermediate transition probabilities (q matrix):\n",
      "[[1.     0.119  0.5802 0.605  0.5466]\n",
      " [1.     0.     1.     0.6403 0.5276]\n",
      " [0.5711 1.     0.     1.     0.5172]\n",
      " [0.5853 0.6623 1.     0.     0.    ]\n",
      " [0.5408 0.6518 0.6655 1.     0.    ]]\n",
      "\n",
      "Final transition probabilities (p matrix):\n",
      "[[0.881  0.05   0.0273 0.0189 0.0228]\n",
      " [1.     0.     0.3597 0.3024 0.3378]\n",
      " [0.5711 0.4289 0.     0.4828 0.5172]\n",
      " [0.3877 0.2746 0.3377 0.     0.    ]\n",
      " [0.2346 0.1992 0.2317 0.3345 0.    ]]\n",
      "\n",
      "Local crossing probabilities computed successfully\n",
      "\n",
      "Applying WHAM to q-probability calculations...\n",
      "Starting WHAM for q probabilities with 5 ensembles, 5 interfaces\n",
      "\n",
      "--- Computing WHAM q[0][0] ---\n",
      "\n",
      "--- Computing WHAM q[0][1] ---\n",
      "  q[0][1] = 0.119012 (ensembles: [1])\n",
      "\n",
      "--- Computing WHAM q[0][2] ---\n",
      "    WHAM iter 0: change = 4.15e-02, Q = [0.95851094 1.04148906]\n",
      "    WHAM iter 1: change = 2.22e-16, Q = [0.95851094 1.04148906]\n",
      "  q[0][2] = 0.549322 (ensembles: [1, 2])\n",
      "\n",
      "--- Computing WHAM q[0][3] ---\n",
      "    WHAM iter 0: change = 1.71e-01, Q = [0.87654832 0.95243095 1.17102073]\n",
      "    WHAM iter 1: change = 0.00e+00, Q = [0.87654832 0.95243095 1.17102073]\n",
      "  q[0][3] = 0.586035 (ensembles: [1, 2, 3])\n",
      "\n",
      "--- Computing WHAM q[0][4] ---\n",
      "    WHAM iter 0: change = 1.85e-01, Q = [0.88664495 0.96340164 1.18450928 0.96544413]\n",
      "    WHAM iter 1: change = 2.22e-16, Q = [0.88664495 0.96340164 1.18450928 0.96544413]\n",
      "  q[0][4] = 0.536431 (ensembles: [1, 2, 3, 4])\n",
      "\n",
      "--- Computing WHAM q[1][0] ---\n",
      "  q[1][0] = 1.000000 (ensembles: [2])\n",
      "\n",
      "--- Computing WHAM q[1][1] ---\n",
      "\n",
      "--- Computing WHAM q[1][2] ---\n",
      "  q[1][2] = 1.000000 (ensembles: [2])\n",
      "\n",
      "--- Computing WHAM q[1][3] ---\n",
      "    WHAM iter 0: change = 1.03e-01, Q = [0.89705921 1.10294079]\n",
      "    WHAM iter 1: change = 0.00e+00, Q = [0.89705921 1.10294079]\n",
      "  q[1][3] = 0.632520 (ensembles: [2, 3])\n",
      "\n",
      "--- Computing WHAM q[1][4] ---\n",
      "    WHAM iter 0: change = 1.41e-01, Q = [0.92832487 1.14138214 0.93029299]\n",
      "    WHAM iter 1: change = 2.22e-16, Q = [0.92832487 1.14138214 0.93029299]\n",
      "  q[1][4] = 0.520794 (ensembles: [2, 3, 4])\n",
      "\n",
      "--- Computing WHAM q[2][0] ---\n",
      "    WHAM iter 0: change = 1.03e-01, Q = [0.89705921 1.10294079]\n",
      "    WHAM iter 1: change = 0.00e+00, Q = [0.89705921 1.10294079]\n",
      "  q[2][0] = 0.565060 (ensembles: [2, 3])\n",
      "\n",
      "--- Computing WHAM q[2][1] ---\n",
      "  q[2][1] = 1.000000 (ensembles: [3])\n",
      "\n",
      "--- Computing WHAM q[2][2] ---\n",
      "\n",
      "--- Computing WHAM q[2][3] ---\n",
      "  q[2][3] = 1.000000 (ensembles: [3])\n",
      "\n",
      "--- Computing WHAM q[2][4] ---\n",
      "    WHAM iter 0: change = 1.02e-01, Q = [1.10189298 0.89810702]\n",
      "    WHAM iter 1: change = 2.22e-16, Q = [1.10189298 0.89810702]\n",
      "  q[2][4] = 0.511846 (ensembles: [3, 4])\n",
      "\n",
      "--- Computing WHAM q[3][0] ---\n",
      "    WHAM iter 0: change = 1.41e-01, Q = [0.92832487 1.14138214 0.93029299]\n",
      "    WHAM iter 1: change = 2.22e-16, Q = [0.92832487 1.14138214 0.93029299]\n",
      "  q[3][0] = 0.577613 (ensembles: [2, 3, 4])\n",
      "\n",
      "--- Computing WHAM q[3][1] ---\n",
      "    WHAM iter 0: change = 1.02e-01, Q = [1.10189298 0.89810702]\n",
      "    WHAM iter 1: change = 1.11e-16, Q = [1.10189298 0.89810702]\n",
      "  q[3][1] = 0.652715 (ensembles: [3, 4])\n",
      "\n",
      "--- Computing WHAM q[3][2] ---\n",
      "  q[3][2] = 1.000000 (ensembles: [4])\n",
      "\n",
      "--- Computing WHAM q[3][3] ---\n",
      "\n",
      "--- Computing WHAM q[3][4] ---\n",
      "  q[3][4] = 0.000000 (ensembles: [4])\n",
      "\n",
      "--- Computing WHAM q[4][0] ---\n",
      "    WHAM iter 0: change = 1.41e-01, Q = [0.92832487 1.14138214 0.93029299]\n",
      "    WHAM iter 1: change = 2.22e-16, Q = [0.92832487 1.14138214 0.93029299]\n",
      "  q[4][0] = 0.533724 (ensembles: [2, 3, 4])\n",
      "\n",
      "--- Computing WHAM q[4][1] ---\n",
      "    WHAM iter 0: change = 1.02e-01, Q = [1.10189298 0.89810702]\n",
      "    WHAM iter 1: change = 0.00e+00, Q = [1.10189298 0.89810702]\n",
      "  q[4][1] = 0.643872 (ensembles: [3, 4])\n",
      "\n",
      "--- Computing WHAM q[4][2] ---\n",
      "  q[4][2] = 0.665467 (ensembles: [4])\n",
      "\n",
      "--- Computing WHAM q[4][3] ---\n",
      "\n",
      "--- Computing WHAM q[4][4] ---\n",
      "\n",
      "WHAM-optimized q matrix:\n",
      "[[1.     0.119  0.5493 0.586  0.5364]\n",
      " [1.     0.     1.     0.6325 0.5208]\n",
      " [0.5651 1.     0.     1.     0.5118]\n",
      " [0.5776 0.6527 1.     0.     0.    ]\n",
      " [0.5337 0.6439 0.6655 1.     0.    ]]\n",
      "\n",
      "WHAM-optimized p matrix:\n",
      "[[0.881  0.0536 0.0271 0.0178 0.0206]\n",
      " [1.     0.     0.3675 0.3031 0.3294]\n",
      " [0.5651 0.4349 0.     0.4882 0.5118]\n",
      " [0.377  0.2757 0.3473 0.     0.    ]\n",
      " [0.2287 0.1998 0.237  0.3345 0.    ]]\n",
      "\n",
      "================================================================================\n",
      "=== Comparison: Original vs WHAM Q-Probabilities ===\n",
      "\n",
      "Original Q Matrix:\n",
      "[[1.     0.119  0.5802 0.605  0.5466]\n",
      " [1.     0.     1.     0.6403 0.5276]\n",
      " [0.5711 1.     0.     1.     0.5172]\n",
      " [0.5853 0.6623 1.     0.     0.    ]\n",
      " [0.5408 0.6518 0.6655 1.     0.    ]]\n",
      "\n",
      "WHAM Q Matrix:\n",
      "[[1.     0.119  0.5493 0.586  0.5364]\n",
      " [1.     0.     1.     0.6325 0.5208]\n",
      " [0.5651 1.     0.     1.     0.5118]\n",
      " [0.5776 0.6527 1.     0.     0.    ]\n",
      " [0.5337 0.6439 0.6655 1.     0.    ]]\n",
      "\n",
      "Original P Matrix:\n",
      "[[0.881  0.05   0.0273 0.0189 0.0228]\n",
      " [1.     0.     0.3597 0.3024 0.3378]\n",
      " [0.5711 0.4289 0.     0.4828 0.5172]\n",
      " [0.3877 0.2746 0.3377 0.     0.    ]\n",
      " [0.2346 0.1992 0.2317 0.3345 0.    ]]\n",
      "\n",
      "WHAM P Matrix:\n",
      "[[0.881  0.0536 0.0271 0.0178 0.0206]\n",
      " [1.     0.     0.3675 0.3031 0.3294]\n",
      " [0.5651 0.4349 0.     0.4882 0.5118]\n",
      " [0.377  0.2757 0.3473 0.     0.    ]\n",
      " [0.2287 0.1998 0.237  0.3345 0.    ]]\n",
      "\n",
      "Q Matrix Differences (WHAM - Original):\n",
      "[[ 0.      0.     -0.0309 -0.019  -0.0102]\n",
      " [ 0.      0.      0.     -0.0077 -0.0068]\n",
      " [-0.006   0.      0.      0.     -0.0054]\n",
      " [-0.0077 -0.0096  0.      0.      0.    ]\n",
      " [-0.0071 -0.0079  0.      0.      0.    ]]\n",
      "\n",
      "P Matrix Differences (WHAM - Original):\n",
      "[[ 0.      0.0037 -0.0002 -0.0012 -0.0023]\n",
      " [ 0.      0.      0.0077  0.0007 -0.0084]\n",
      " [-0.006   0.006   0.      0.0054 -0.0054]\n",
      " [-0.0106  0.0011  0.0096  0.      0.    ]\n",
      " [-0.0059  0.0006  0.0053  0.      0.    ]]\n",
      "\n",
      "Q Matrix Changes:\n",
      "  Max absolute difference: 0.030875\n",
      "  Mean absolute difference: 0.004733\n",
      "  RMS difference: 0.008609\n",
      "\n",
      "P Matrix Changes:\n",
      "  Max absolute difference: 0.010642\n",
      "  Mean absolute difference: 0.003203\n",
      "  RMS difference: 0.004693\n",
      "\n",
      "=== WHAM Convergence Analysis ===\n",
      "  q[0][1]: converged=True, iterations=0\n",
      "  q[0][2]: converged=True, iterations=2\n",
      "  q[1][0]: converged=True, iterations=0\n",
      "  q[1][2]: converged=True, iterations=0\n",
      "  q[2][0]: converged=True, iterations=2\n",
      "  q[2][1]: converged=True, iterations=0\n",
      "\n",
      "Convergence summary: 19/19 transitions converged\n"
     ]
    }
   ],
   "source": [
    "# Example: Apply WHAM to Q-Probabilities\n",
    "if 'weight_matrices_results' in locals() and weight_matrices_results is not None:\n",
    "    print(\"Applying WHAM to q-probability calculations...\")\n",
    "    \n",
    "    # Calculate original q and p probabilities (for comparison)\n",
    "    from tistools import get_transition_probs_weights\n",
    "    \n",
    "    # Convert our weight_matrix_3d to the format expected by istar_analysis\n",
    "    w_path_for_comparison = weight_matrices_results['weight_matrix_3d']\n",
    "    \n",
    "    # Calculate original q and p matrices\n",
    "    print(\"Calculating original q and p probabilities...\")\n",
    "    p_original, q_original = get_transition_probs_weights(w_path_for_comparison)\n",
    "    \n",
    "    original_results = {\n",
    "        'q_matrix': q_original,\n",
    "        'p_matrix': p_original\n",
    "    }\n",
    "    \n",
    "    # Apply WHAM to q-probability calculations\n",
    "    print(\"\\nApplying WHAM to q-probability calculations...\")\n",
    "    wham_q_results = wham_q_probabilities(\n",
    "        weight_matrices_results['weight_matrix_3d'],\n",
    "        weight_matrices_results['interfaces'],\n",
    "        max_iterations=500,\n",
    "        tolerance=1e-8,\n",
    "        verbose=True  # Set to False to reduce output\n",
    "    )\n",
    "    \n",
    "    # Compare results\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    compare_q_probability_results(original_results, wham_q_results)\n",
    "    \n",
    "    # Store results for further analysis\n",
    "    wham_q_transition_results = wham_q_results\n",
    "    \n",
    "else:\n",
    "    print(\"No weight_matrices_results available. Please run the weight matrix calculation first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7bf8a3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== STEP 3: ANALYZING WEIGHT MATRICES ===\n",
      "iSTAR transition matrix constructed successfully!\n",
      "\n",
      "=== Eigenvalue Analysis ===\n",
      "Mp eigenvalues: [ 0.     -0.5754 -0.2861  0.5754  0.2861  0.      0.    ]\n",
      "(I-Mp) eigenvalues: [1.     1.5754 1.2861 0.4246 0.7139 1.     1.    ]\n",
      "\n",
      "=== Matrix Components ===\n",
      "D (transitions from intermediate to boundary states):\n",
      "[[0.881  0.0206]\n",
      " [0.     0.3294]\n",
      " [0.     0.5118]\n",
      " [0.     0.    ]\n",
      " [0.     0.    ]\n",
      " [0.     0.    ]\n",
      " [0.     0.    ]]\n",
      "\n",
      "E (transitions from boundary to intermediate states):\n",
      "[[1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      "M11 (transitions between boundary states):\n",
      "[0. 0.]\n",
      "\n",
      "=== Solution Vectors ===\n",
      "z1 (boundary states solution):\n",
      "[[0]\n",
      " [1]]\n",
      "\n",
      "z2 (intermediate states solution):\n",
      "[[ 0.0338]\n",
      " [ 0.5332]\n",
      " [ 0.7027]\n",
      " [-0.    ]\n",
      " [ 0.    ]\n",
      " [ 0.2319]\n",
      " [ 0.391 ]]\n",
      "\n",
      "=== Result Vectors ===\n",
      "y1 (boundary states result):\n",
      "[[0.0338]\n",
      " [0.    ]]\n",
      "\n",
      "y2 (intermediate states result):\n",
      "[[0.0338]\n",
      " [0.5332]\n",
      " [0.7027]\n",
      " [0.    ]\n",
      " [0.    ]\n",
      " [0.2319]\n",
      " [0.391 ]]\n",
      "\n",
      "=== Verification ===\n",
      "||y2-z2||² = 1.309632e-32\n",
      "✓ Verification passed: z2 and y2 are identical (as expected)\n",
      "Global crossing probability (iSTAR): [0.03377285]\n"
     ]
    }
   ],
   "source": [
    "# Analyze using tistools\n",
    "print(\"\\n=== STEP 3: ANALYZING WEIGHT MATRICES ===\")\n",
    "from tistools import construct_M_istar, global_pcross_msm_star, ploc_memory, display_data\n",
    "\n",
    "# Construct transition matrix using iSTAR approach\n",
    "p = wham_q_transition_results['p_matrix']\n",
    "M_istar = construct_M_istar(p, 2*len(weight_matrices_results['interfaces']), len(weight_matrices_results['interfaces']))\n",
    "print(\"iSTAR transition matrix constructed successfully!\")\n",
    "# Calculate global crossing probability using iSTAR\n",
    "z1, z2, y1, y2 = global_pcross_msm_star(M_istar, doprint=True)\n",
    "istar_global_pcross = y1[0] if y1.shape[0] > 1 else None\n",
    "print(f\"Global crossing probability (iSTAR): {istar_global_pcross}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d3231b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interface λ_0: -0.1\n",
      "Computing weight matrices for 26582 paths\n",
      "Structure: Dictionary of 2D matrices [ensemble_idx][start_interface, end_interface]\n",
      "Dimensions: 2 ensembles x 2 interfaces x 2 interfaces\n",
      "Following original istar_analysis.py logic with tr=False\n",
      "Using ptype information with direction for istar_analysis-style computation\n",
      "\n",
      "=== 3D WEIGHT MATRICES RESULTS (istar_analysis style) ===\n",
      "3D Matrix dimensions: 2 x 2 x 2\n",
      "Total weight processed: 62892.522619\n",
      "Total transitions: 19615.0\n",
      "Non-zero 3D matrix elements: 3\n",
      "Time-reversal symmetry applied: False\n",
      "\n",
      "Ensemble weight totals:\n",
      "  Sum weights ensemble 0: 0.0000\n",
      "  Sum weights ensemble 1: 62892.5226\n",
      "\n",
      "2D Weight Matrix [start_interface, end_interface] (summed over ensembles):\n",
      "Rows = start interface, Columns = end interface\n",
      "Interface 0: 51623.0000 6973.7230 \n",
      "Interface 1: 4295.7996   0.0000 \n",
      "\n",
      "Transition Analysis:\n",
      "Forward transitions (j<k):  4877.000000 paths, 6973.7230 weight (11.1%)\n",
      "Backward transitions (j>k): 2746.000000 paths, 4295.7996 weight (6.8%)\n",
      "Self transitions (j=k):     11992.000000 paths, 51623.0000 weight (82.1%)\n",
      "\n",
      "Non-zero 3D matrix entries (first 10):\n",
      "  weights[1,0,0] = 51623.000000 (count: 11992.0)\n",
      "  weights[1,0,1] = 6973.723016 (count: 4877.0)\n",
      "  weights[1,1,0] = 4295.799603 (count: 2746.0)\n",
      "Starting WHAM for q probabilities with 2 ensembles, 2 interfaces\n",
      "\n",
      "--- Computing WHAM q[0][0] ---\n",
      "\n",
      "--- Computing WHAM q[0][1] ---\n",
      "  q[0][1] = 0.119012 (ensembles: [1])\n",
      "\n",
      "--- Computing WHAM q[1][0] ---\n",
      "\n",
      "--- Computing WHAM q[1][1] ---\n",
      "\n",
      "WHAM-optimized q matrix:\n",
      "[[1.    0.119]\n",
      " [1.    0.   ]]\n",
      "\n",
      "WHAM-optimized p matrix:\n",
      "[[0.881 0.119]\n",
      " [1.    0.   ]]\n",
      "Interface λ_1: 0.0\n",
      "Computing weight matrices for 26582 paths\n",
      "Structure: Dictionary of 2D matrices [ensemble_idx][start_interface, end_interface]\n",
      "Dimensions: 3 ensembles x 3 interfaces x 3 interfaces\n",
      "Following original istar_analysis.py logic with tr=False\n",
      "Using ptype information with direction for istar_analysis-style computation\n",
      "\n",
      "=== 3D WEIGHT MATRICES RESULTS (istar_analysis style) ===\n",
      "3D Matrix dimensions: 3 x 3 x 3\n",
      "Total weight processed: 124219.689286\n",
      "Total transitions: 46062.0\n",
      "Non-zero 3D matrix elements: 11\n",
      "Time-reversal symmetry applied: False\n",
      "\n",
      "Ensemble weight totals:\n",
      "  Sum weights ensemble 0: 0.0000\n",
      "  Sum weights ensemble 1: 62892.5226\n",
      "  Sum weights ensemble 2: 61327.1667\n",
      "\n",
      "2D Weight Matrix [start_interface, end_interface] (summed over ensembles):\n",
      "Rows = start interface, Columns = end interface\n",
      "Interface 0: 51623.0000 13961.4952 19295.7710 \n",
      "Interface 1: 671.0000   0.0000 9150.8167 \n",
      "Interface 2: 20118.5540 9399.0524   0.0000 \n",
      "\n",
      "Transition Analysis:\n",
      "Forward transitions (j<k):  13182.000000 paths, 42408.0829 weight (34.1%)\n",
      "Backward transitions (j>k): 8896.000000 paths, 30188.6063 weight (24.3%)\n",
      "Self transitions (j=k):     23984.000000 paths, 51623.0000 weight (41.6%)\n",
      "\n",
      "Non-zero 3D matrix entries (first 10):\n",
      "  weights[1,0,0] = 51623.000000 (count: 11992.0)\n",
      "  weights[1,0,1] = 3539.516667 (count: 1729.0)\n",
      "  weights[1,0,2] = 3434.206349 (count: 3148.0)\n",
      "  weights[1,1,0] = 339.983333 (count: 103.0)\n",
      "  weights[1,2,0] = 3955.816270 (count: 2643.0)\n",
      "  weights[2,0,1] = 10421.978571 (count: 1729.0)\n",
      "  weights[2,0,2] = 15861.564683 (count: 3148.0)\n",
      "  weights[2,1,0] = 331.016667 (count: 103.0)\n",
      "  weights[2,1,2] = 9150.816667 (count: 1714.0)\n",
      "  weights[2,2,0] = 16162.737698 (count: 2643.0)\n",
      "Starting WHAM for q probabilities with 3 ensembles, 3 interfaces\n",
      "\n",
      "--- Computing WHAM q[0][0] ---\n",
      "\n",
      "--- Computing WHAM q[0][1] ---\n",
      "  q[0][1] = 0.119012 (ensembles: [1])\n",
      "\n",
      "--- Computing WHAM q[0][2] ---\n",
      "    WHAM iter 0: change = 1.26e-02, Q = [1.01260151 0.98739849]\n",
      "    WHAM iter 1: change = 2.22e-16, Q = [1.01260151 0.98739849]\n",
      "  q[0][2] = 0.547178 (ensembles: [1, 2])\n",
      "\n",
      "--- Computing WHAM q[1][0] ---\n",
      "  q[1][0] = 1.000000 (ensembles: [2])\n",
      "\n",
      "--- Computing WHAM q[1][1] ---\n",
      "\n",
      "--- Computing WHAM q[1][2] ---\n",
      "  q[1][2] = 1.000000 (ensembles: [2])\n",
      "\n",
      "--- Computing WHAM q[2][0] ---\n",
      "  q[2][0] = 0.632301 (ensembles: [2])\n",
      "\n",
      "--- Computing WHAM q[2][1] ---\n",
      "\n",
      "--- Computing WHAM q[2][2] ---\n",
      "\n",
      "WHAM-optimized q matrix:\n",
      "[[1.     0.119  0.5472]\n",
      " [1.     0.     1.    ]\n",
      " [0.6323 1.     0.    ]]\n",
      "\n",
      "WHAM-optimized p matrix:\n",
      "[[0.881  0.0539 0.0651]\n",
      " [1.     0.     1.    ]\n",
      " [0.6323 0.3677 0.    ]]\n",
      "Interface λ_2: 0.1\n",
      "Computing weight matrices for 26582 paths\n",
      "Structure: Dictionary of 2D matrices [ensemble_idx][start_interface, end_interface]\n",
      "Dimensions: 4 ensembles x 4 interfaces x 4 interfaces\n",
      "Following original istar_analysis.py logic with tr=False\n",
      "Using ptype information with direction for istar_analysis-style computation\n",
      "\n",
      "=== 3D WEIGHT MATRICES RESULTS (istar_analysis style) ===\n",
      "3D Matrix dimensions: 4 x 4 x 4\n",
      "Total weight processed: 203842.564683\n",
      "Total transitions: 77127.0\n",
      "Non-zero 3D matrix elements: 27\n",
      "Time-reversal symmetry applied: False\n",
      "\n",
      "Ensemble weight totals:\n",
      "  Sum weights ensemble 0: 0.0000\n",
      "  Sum weights ensemble 1: 62892.5226\n",
      "  Sum weights ensemble 2: 68337.1167\n",
      "  Sum weights ensemble 3: 72612.9254\n",
      "\n",
      "2D Weight Matrix [start_interface, end_interface] (summed over ensembles):\n",
      "Rows = start interface, Columns = end interface\n",
      "Interface 0: 51623.0000 13961.4952 14255.5131 21834.6893 \n",
      "Interface 1: 671.0000   0.0000 8176.8667 15426.8833 \n",
      "Interface 2: 14376.5702 8440.4000   0.0000 8467.7571 \n",
      "Interface 3: 22956.7397 15622.8429 8028.8071   0.0000 \n",
      "\n",
      "Transition Analysis:\n",
      "Forward transitions (j<k):  23871.000000 paths, 82123.2048 weight (40.3%)\n",
      "Backward transitions (j>k): 17280.000000 paths, 70096.3599 weight (34.4%)\n",
      "Self transitions (j=k):     35976.000000 paths, 51623.0000 weight (25.3%)\n",
      "\n",
      "Non-zero 3D matrix entries (first 10):\n",
      "  weights[1,0,0] = 51623.000000 (count: 11992.0)\n",
      "  weights[1,0,1] = 3539.516667 (count: 1729.0)\n",
      "  weights[1,0,2] = 1501.942857 (count: 1153.0)\n",
      "  weights[1,0,3] = 1932.263492 (count: 1995.0)\n",
      "  weights[1,1,0] = 339.983333 (count: 103.0)\n",
      "  weights[1,2,0] = 1424.004762 (count: 946.0)\n",
      "  weights[1,3,0] = 2531.811508 (count: 1697.0)\n",
      "  weights[2,0,1] = 10421.978571 (count: 1729.0)\n",
      "  weights[2,0,2] = 6004.334524 (count: 1153.0)\n",
      "  weights[2,0,3] = 9857.230159 (count: 1995.0)\n",
      "Starting WHAM for q probabilities with 4 ensembles, 4 interfaces\n",
      "\n",
      "--- Computing WHAM q[0][0] ---\n",
      "\n",
      "--- Computing WHAM q[0][1] ---\n",
      "  q[0][1] = 0.119012 (ensembles: [1])\n",
      "\n",
      "--- Computing WHAM q[0][2] ---\n",
      "    WHAM iter 0: change = 4.15e-02, Q = [0.95851094 1.04148906]\n",
      "    WHAM iter 1: change = 1.11e-16, Q = [0.95851094 1.04148906]\n",
      "  q[0][2] = 0.549322 (ensembles: [1, 2])\n",
      "\n",
      "--- Computing WHAM q[0][3] ---\n",
      "    WHAM iter 0: change = 7.44e-02, Q = [0.92560437 1.00573376 1.06866187]\n",
      "    WHAM iter 1: change = 0.00e+00, Q = [0.92560437 1.00573376 1.06866187]\n",
      "  q[0][3] = 0.592969 (ensembles: [1, 2, 3])\n",
      "\n",
      "--- Computing WHAM q[1][0] ---\n",
      "  q[1][0] = 1.000000 (ensembles: [2])\n",
      "\n",
      "--- Computing WHAM q[1][1] ---\n",
      "\n",
      "--- Computing WHAM q[1][2] ---\n",
      "  q[1][2] = 1.000000 (ensembles: [2])\n",
      "\n",
      "--- Computing WHAM q[1][3] ---\n",
      "    WHAM iter 0: change = 3.03e-02, Q = [0.96966437 1.03033563]\n",
      "    WHAM iter 1: change = 1.11e-16, Q = [0.96966437 1.03033563]\n",
      "  q[1][3] = 0.652213 (ensembles: [2, 3])\n",
      "\n",
      "--- Computing WHAM q[2][0] ---\n",
      "    WHAM iter 0: change = 3.03e-02, Q = [0.96966437 1.03033563]\n",
      "    WHAM iter 1: change = 1.11e-16, Q = [0.96966437 1.03033563]\n",
      "  q[2][0] = 0.604786 (ensembles: [2, 3])\n",
      "\n",
      "--- Computing WHAM q[2][1] ---\n",
      "  q[2][1] = 1.000000 (ensembles: [3])\n",
      "\n",
      "--- Computing WHAM q[2][2] ---\n",
      "\n",
      "--- Computing WHAM q[2][3] ---\n",
      "  q[2][3] = 1.000000 (ensembles: [3])\n",
      "\n",
      "--- Computing WHAM q[3][0] ---\n",
      "    WHAM iter 0: change = 3.03e-02, Q = [0.96966437 1.03033563]\n",
      "    WHAM iter 1: change = 2.22e-16, Q = [0.96966437 1.03033563]\n",
      "  q[3][0] = 0.567574 (ensembles: [2, 3])\n",
      "\n",
      "--- Computing WHAM q[3][1] ---\n",
      "  q[3][1] = 0.683319 (ensembles: [3])\n",
      "\n",
      "--- Computing WHAM q[3][2] ---\n",
      "\n",
      "--- Computing WHAM q[3][3] ---\n",
      "\n",
      "WHAM-optimized q matrix:\n",
      "[[1.     0.119  0.5493 0.593 ]\n",
      " [1.     0.     1.     0.6522]\n",
      " [0.6048 1.     0.     1.    ]\n",
      " [0.5676 0.6833 1.     0.    ]]\n",
      "\n",
      "WHAM-optimized p matrix:\n",
      "[[0.881  0.0536 0.0266 0.0388]\n",
      " [1.     0.     0.3478 0.6522]\n",
      " [0.6048 0.3952 0.     1.    ]\n",
      " [0.3878 0.2955 0.3167 0.    ]]\n",
      "Interface λ_3: 0.2\n",
      "Computing weight matrices for 26582 paths\n",
      "Structure: Dictionary of 2D matrices [ensemble_idx][start_interface, end_interface]\n",
      "Dimensions: 5 ensembles x 5 interfaces x 5 interfaces\n",
      "Following original istar_analysis.py logic with tr=False\n",
      "Using ptype information with direction for istar_analysis-style computation\n",
      "\n",
      "=== 3D WEIGHT MATRICES RESULTS (istar_analysis style) ===\n",
      "3D Matrix dimensions: 5 x 5 x 5\n",
      "Total weight processed: 275765.615079\n",
      "Total transitions: 102836.0\n",
      "Non-zero 3D matrix elements: 51\n",
      "Time-reversal symmetry applied: False\n",
      "\n",
      "Ensemble weight totals:\n",
      "  Sum weights ensemble 0: 0.0000\n",
      "  Sum weights ensemble 1: 62892.5226\n",
      "  Sum weights ensemble 2: 68337.1167\n",
      "  Sum weights ensemble 3: 84020.9790\n",
      "  Sum weights ensemble 4: 60514.9968\n",
      "\n",
      "2D Weight Matrix [start_interface, end_interface] (summed over ensembles):\n",
      "Rows = start interface, Columns = end interface\n",
      "Interface 0: 51623.0000 13961.4952 14255.5131 15388.6774 18551.0000 \n",
      "Interface 1: 671.0000   0.0000 9585.0667 11851.3036 13238.2595 \n",
      "Interface 2: 14376.5702 9727.5000   0.0000 10557.8167 11310.5643 \n",
      "Interface 3: 16596.5817 10937.9262 9401.2833   0.0000   0.0000 \n",
      "Interface 4: 18337.0000 14400.7619 10994.2952   0.0000   0.0000 \n",
      "\n",
      "Transition Analysis:\n",
      "Forward transitions (j<k):  31828.000000 paths, 118699.6964 weight (43.0%)\n",
      "Backward transitions (j>k): 23040.000000 paths, 105442.9187 weight (38.2%)\n",
      "Self transitions (j=k):     47968.000000 paths, 51623.0000 weight (18.7%)\n",
      "\n",
      "Non-zero 3D matrix entries (first 10):\n",
      "  weights[1,0,0] = 51623.000000 (count: 11992.0)\n",
      "  weights[1,0,1] = 3539.516667 (count: 1729.0)\n",
      "  weights[1,0,2] = 1501.942857 (count: 1153.0)\n",
      "  weights[1,0,3] = 923.140079 (count: 879.0)\n",
      "  weights[1,0,4] = 1009.123413 (count: 1116.0)\n",
      "  weights[1,1,0] = 339.983333 (count: 103.0)\n",
      "  weights[1,2,0] = 1424.004762 (count: 946.0)\n",
      "  weights[1,3,0] = 1156.218254 (count: 752.0)\n",
      "  weights[1,4,0] = 1375.593254 (count: 945.0)\n",
      "  weights[2,0,1] = 10421.978571 (count: 1729.0)\n",
      "Starting WHAM for q probabilities with 5 ensembles, 5 interfaces\n",
      "\n",
      "--- Computing WHAM q[0][0] ---\n",
      "\n",
      "--- Computing WHAM q[0][1] ---\n",
      "  q[0][1] = 0.119012 (ensembles: [1])\n",
      "\n",
      "--- Computing WHAM q[0][2] ---\n",
      "    WHAM iter 0: change = 4.15e-02, Q = [0.95851094 1.04148906]\n",
      "    WHAM iter 1: change = 2.22e-16, Q = [0.95851094 1.04148906]\n",
      "  q[0][2] = 0.549322 (ensembles: [1, 2])\n",
      "\n",
      "--- Computing WHAM q[0][3] ---\n",
      "    WHAM iter 0: change = 1.71e-01, Q = [0.87654832 0.95243095 1.17102073]\n",
      "    WHAM iter 1: change = 0.00e+00, Q = [0.87654832 0.95243095 1.17102073]\n",
      "  q[0][3] = 0.586035 (ensembles: [1, 2, 3])\n",
      "\n",
      "--- Computing WHAM q[0][4] ---\n",
      "    WHAM iter 0: change = 2.19e-01, Q = [0.91226055 0.99123477 1.21873032 0.87777436]\n",
      "    WHAM iter 1: change = 2.22e-16, Q = [0.91226055 0.99123477 1.21873032 0.87777436]\n",
      "  q[0][4] = 0.533911 (ensembles: [1, 2, 3, 4])\n",
      "\n",
      "--- Computing WHAM q[1][0] ---\n",
      "  q[1][0] = 1.000000 (ensembles: [2])\n",
      "\n",
      "--- Computing WHAM q[1][1] ---\n",
      "\n",
      "--- Computing WHAM q[1][2] ---\n",
      "  q[1][2] = 1.000000 (ensembles: [2])\n",
      "\n",
      "--- Computing WHAM q[1][3] ---\n",
      "    WHAM iter 0: change = 1.03e-01, Q = [0.89705921 1.10294079]\n",
      "    WHAM iter 1: change = 0.00e+00, Q = [0.89705921 1.10294079]\n",
      "  q[1][3] = 0.632520 (ensembles: [2, 3])\n",
      "\n",
      "--- Computing WHAM q[1][4] ---\n",
      "    WHAM iter 0: change = 1.84e-01, Q = [0.96306841 1.18409957 0.85283202]\n",
      "    WHAM iter 1: change = 2.22e-16, Q = [0.96306841 1.18409957 0.85283202]\n",
      "  q[1][4] = 0.516759 (ensembles: [2, 3, 4])\n",
      "\n",
      "--- Computing WHAM q[2][0] ---\n",
      "    WHAM iter 0: change = 1.03e-01, Q = [0.89705921 1.10294079]\n",
      "    WHAM iter 1: change = 0.00e+00, Q = [0.89705921 1.10294079]\n",
      "  q[2][0] = 0.565060 (ensembles: [2, 3])\n",
      "\n",
      "--- Computing WHAM q[2][1] ---\n",
      "  q[2][1] = 1.000000 (ensembles: [3])\n",
      "\n",
      "--- Computing WHAM q[2][2] ---\n",
      "\n",
      "--- Computing WHAM q[2][3] ---\n",
      "  q[2][3] = 1.000000 (ensembles: [3])\n",
      "\n",
      "--- Computing WHAM q[2][4] ---\n",
      "    WHAM iter 0: change = 1.63e-01, Q = [1.16263067 0.83736933]\n",
      "    WHAM iter 1: change = 1.11e-16, Q = [1.16263067 0.83736933]\n",
      "  q[2][4] = 0.503782 (ensembles: [3, 4])\n",
      "\n",
      "--- Computing WHAM q[3][0] ---\n",
      "    WHAM iter 0: change = 1.84e-01, Q = [0.96306841 1.18409957 0.85283202]\n",
      "    WHAM iter 1: change = 1.11e-16, Q = [0.96306841 1.18409957 0.85283202]\n",
      "  q[3][0] = 0.571713 (ensembles: [2, 3, 4])\n",
      "\n",
      "--- Computing WHAM q[3][1] ---\n",
      "    WHAM iter 0: change = 1.63e-01, Q = [1.16263067 0.83736933]\n",
      "    WHAM iter 1: change = 2.22e-16, Q = [1.16263067 0.83736933]\n",
      "  q[3][1] = 0.641061 (ensembles: [3, 4])\n",
      "\n",
      "--- Computing WHAM q[3][2] ---\n",
      "  q[3][2] = 1.000000 (ensembles: [4])\n",
      "\n",
      "--- Computing WHAM q[3][3] ---\n",
      "\n",
      "--- Computing WHAM q[3][4] ---\n",
      "  q[3][4] = 0.000000 (ensembles: [4])\n",
      "\n",
      "--- Computing WHAM q[4][0] ---\n",
      "    WHAM iter 0: change = 1.84e-01, Q = [0.96306841 1.18409957 0.85283202]\n",
      "    WHAM iter 1: change = 3.33e-16, Q = [0.96306841 1.18409957 0.85283202]\n",
      "  q[4][0] = 0.527446 (ensembles: [2, 3, 4])\n",
      "\n",
      "--- Computing WHAM q[4][1] ---\n",
      "    WHAM iter 0: change = 1.63e-01, Q = [1.16263067 0.83736933]\n",
      "    WHAM iter 1: change = 0.00e+00, Q = [1.16263067 0.83736933]\n",
      "  q[4][1] = 0.633094 (ensembles: [3, 4])\n",
      "\n",
      "--- Computing WHAM q[4][2] ---\n",
      "  q[4][2] = 1.000000 (ensembles: [4])\n",
      "\n",
      "--- Computing WHAM q[4][3] ---\n",
      "\n",
      "--- Computing WHAM q[4][4] ---\n",
      "\n",
      "WHAM-optimized q matrix:\n",
      "[[1.     0.119  0.5493 0.586  0.5339]\n",
      " [1.     0.     1.     0.6325 0.5168]\n",
      " [0.5651 1.     0.     1.     0.5038]\n",
      " [0.5717 0.6411 1.     0.     0.    ]\n",
      " [0.5274 0.6331 1.     1.     0.    ]]\n",
      "\n",
      "WHAM-optimized p matrix:\n",
      "[[0.881  0.0536 0.0271 0.0179 0.0205]\n",
      " [1.     0.     0.3675 0.3057 0.3269]\n",
      " [0.5651 0.4349 0.     0.4962 0.5038]\n",
      " [0.3665 0.2746 0.3589 0.     0.    ]\n",
      " [0.3339 0.2992 0.3669 0.     0.    ]]\n",
      "[1.0, 0.11901216752315538, 0.06512081035335231, 0.046718074010115324, 0.033855150262105775]\n",
      "[0.11901216752315538, 0.5471777525662004, 0.7174062140292509, 0.7246692201989215]\n"
     ]
    }
   ],
   "source": [
    "plocs = [1.,]\n",
    "for i in range(len(weight_matrices_results['interfaces'])-1):\n",
    "    print(f\"Interface λ_{i}: {weight_matrices_results['interfaces'][i]}\")\n",
    "\n",
    "    wi_results = compute_weight_matrices_weights(weight_results, n_int=i+2, tr=False)\n",
    "    wi_ha = wi_results['weight_matrix_3d']\n",
    "    wham_qi_results = wham_q_probabilities(\n",
    "        wi_ha,\n",
    "        weight_matrices_results[\"interfaces\"][:i+2],\n",
    "        max_iterations=500,\n",
    "        tolerance=1e-8,\n",
    "        verbose=True  # Set to False to reduce output\n",
    "    )\n",
    "    pi_ha = wham_qi_results['p_matrix']\n",
    "    Mi_ha = construct_M_istar(pi_ha, max(4, 2*len(weight_matrices_results[\"interfaces\"][:i+2])), len(weight_matrices_results[\"interfaces\"][:i+2]))\n",
    "    z1_ha, z2_ha, y1_ha, y2_ha = global_pcross_msm_star(Mi_ha)\n",
    "    plocs.append(y1_ha[0][0])\n",
    "\n",
    "print(plocs)\n",
    "print([plocs[i+1]/plocs[i] for i in range(len(plocs)-1)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6404a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying WHAM to weight matrices...\n",
      "\n",
      "This implements WHAM where each transition [j,k] is treated as a histogram bin\n",
      "that can be sampled by multiple ensembles with different statistical weights.\n",
      "Starting WHAM for 5 ensembles, 5 interfaces\n",
      "Max iterations: 1000, tolerance: 1e-08\n",
      "Ensemble 0: total weight = 0.000000\n",
      "Ensemble 1: total weight = 57429.202381\n",
      "Ensemble 2: total weight = 35434.359921\n",
      "Ensemble 3: total weight = 30732.803968\n",
      "Ensemble 4: total weight = 26879.633730\n",
      "Iteration 0: max Q change = 2.80e+00\n",
      "  Q-factors: ['0.000000', '3.796496', '0.576613', '0.390670', '0.236222']\n",
      "Iteration 1: max Q change = 5.99e-01\n",
      "  Q-factors: ['0.000000', '3.197222', '0.808447', '0.604496', '0.389835']\n",
      "Iteration 2: max Q change = 8.72e-02\n",
      "  Q-factors: ['0.000000', '3.284472', '0.775618', '0.572960', '0.366951']\n",
      "Iteration 3: max Q change = 1.40e-02\n",
      "  Q-factors: ['0.000000', '3.270483', '0.780918', '0.578008', '0.370591']\n",
      "Iteration 4: max Q change = 2.21e-03\n",
      "  Q-factors: ['0.000000', '3.272694', '0.780081', '0.577210', '0.370015']\n",
      "Iteration 5: max Q change = 3.50e-04\n",
      "  Q-factors: ['0.000000', '3.272344', '0.780214', '0.577336', '0.370106']\n",
      "Iteration 6: max Q change = 5.55e-05\n",
      "  Q-factors: ['0.000000', '3.272399', '0.780193', '0.577316', '0.370092']\n",
      "Iteration 7: max Q change = 8.79e-06\n",
      "  Q-factors: ['0.000000', '3.272390', '0.780196', '0.577320', '0.370094']\n",
      "Iteration 8: max Q change = 1.39e-06\n",
      "  Q-factors: ['0.000000', '3.272392', '0.780196', '0.577319', '0.370093']\n",
      "Iteration 9: max Q change = 2.20e-07\n",
      "  Q-factors: ['0.000000', '3.272392', '0.780196', '0.577319', '0.370094']\n",
      "Converged after 12 iterations\n",
      "\n",
      "=== WHAM Results ===\n",
      "Final Q-factors: ['0.000000', '3.272392', '0.780196', '0.577319', '0.370094']\n",
      "Total WHAM matrix weight: 21751.507647\n",
      "Original total weight: 150476.000000\n",
      "Ensemble contributions to WHAM: ['0.000000', '20751.037575', '615.707440', '284.165208', '100.597424']\n",
      "\n",
      "============================================================\n",
      "WHAM ANALYSIS COMPLETE\n",
      "============================================================\n",
      "============================================================\n",
      "COMPARISON: Original vs WHAM Weight Matrices\n",
      "============================================================\n",
      "\n",
      "1. Original combined matrix (sum over ensembles):\n",
      "[[51623. 13008. 12709. 13799. 18551.]\n",
      " [  671.     0.  5396.  8214. 11356.]\n",
      " [12397.  5465.     0.  6039.  9781.]\n",
      " [14861.  7844.  5326.     0.     0.]\n",
      " [18337. 12340.  9634.  7967.     0.]]\n",
      "\n",
      "2. WHAM-optimized matrix:\n",
      "[[15775.3121   790.2542  1348.5148  1377.4239  2460.0026]\n",
      " [    0.         0.         0.         0.         0.    ]\n",
      " [    0.         0.         0.         0.         0.    ]\n",
      " [    0.         0.         0.         0.         0.    ]\n",
      " [    0.         0.         0.         0.         0.    ]]\n",
      "\n",
      "3. Difference (WHAM - Original):\n",
      "[[-35847.6879 -12217.7458 -11360.4852 -12421.5761 -16090.9974]\n",
      " [  -671.          0.      -5396.      -8214.     -11356.    ]\n",
      " [-12397.      -5465.          0.      -6039.      -9781.    ]\n",
      " [-14861.      -7844.      -5326.          0.          0.    ]\n",
      " [-18337.     -12340.      -9634.      -7967.          0.    ]]\n",
      "\n",
      "4. Statistical Summary:\n",
      "   Original total weight: 245318.000000\n",
      "   WHAM total weight:     21751.507647\n",
      "   Relative change:       -91.13%\n",
      "\n",
      "5. Relative differences (%) where original > 0:\n",
      "[[ -69.4  -93.9  -89.4  -90.   -86.7]\n",
      " [-100.     0.  -100.  -100.  -100. ]\n",
      " [-100.  -100.     0.  -100.  -100. ]\n",
      " [-100.  -100.  -100.     0.     0. ]\n",
      " [-100.  -100.  -100.  -100.     0. ]]\n",
      "\n",
      "6. Significant changes (>10%):\n",
      "   Transition [0,0]: -69.4% change (51623.0000 → 15775.3121)\n",
      "   Transition [0,1]: -93.9% change (13008.0000 → 790.2542)\n",
      "   Transition [0,2]: -89.4% change (12709.0000 → 1348.5148)\n",
      "   Transition [0,3]: -90.0% change (13799.0000 → 1377.4239)\n",
      "   Transition [0,4]: -86.7% change (18551.0000 → 2460.0026)\n",
      "   Transition [1,0]: -100.0% change (671.0000 → 0.0000)\n",
      "   Transition [1,2]: -100.0% change (5396.0000 → 0.0000)\n",
      "   Transition [1,3]: -100.0% change (8214.0000 → 0.0000)\n",
      "   Transition [1,4]: -100.0% change (11356.0000 → 0.0000)\n",
      "   Transition [2,0]: -100.0% change (12397.0000 → 0.0000)\n",
      "   Transition [2,1]: -100.0% change (5465.0000 → 0.0000)\n",
      "   Transition [2,3]: -100.0% change (6039.0000 → 0.0000)\n",
      "   Transition [2,4]: -100.0% change (9781.0000 → 0.0000)\n",
      "   Transition [3,0]: -100.0% change (14861.0000 → 0.0000)\n",
      "   Transition [3,1]: -100.0% change (7844.0000 → 0.0000)\n",
      "   Transition [3,2]: -100.0% change (5326.0000 → 0.0000)\n",
      "   Transition [4,0]: -100.0% change (18337.0000 → 0.0000)\n",
      "   Transition [4,1]: -100.0% change (12340.0000 → 0.0000)\n",
      "   Transition [4,2]: -100.0% change (9634.0000 → 0.0000)\n",
      "   Transition [4,3]: -100.0% change (7967.0000 → 0.0000)\n",
      "==================================================\n",
      "ENSEMBLE CONTRIBUTION ANALYSIS\n",
      "==================================================\n",
      "\n",
      "Ensemble Analysis:\n",
      "Ensemble   Original η   Q-factor     WHAM Weight  Contribution % \n",
      "-----------------------------------------------------------------\n",
      "0          0.000000     0.000000     0.000000     0.0            \n",
      "1          57429.202381 3.272392     20751.037575 95.4           \n",
      "2          35434.359921 0.780196     615.707440   2.8            \n",
      "3          30732.803968 0.577319     284.165208   1.3            \n",
      "4          26879.633730 0.370094     100.597424   0.5            \n",
      "-----------------------------------------------------------------\n",
      "Total      150476.000000 5.000000     21751.507647 100.0          \n",
      "\n",
      "Key Insights:\n",
      "  - Dominant ensemble: 1 (95.4% contribution)\n",
      "  - Q-factor range: 0.000000 to 3.272392\n",
      "  - Original η range: 0.000000 to 57429.202381\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convergence Summary:\n",
      "  - Converged: True\n",
      "  - Iterations: 12\n",
      "  - Final change: 5.53e-09\n",
      "\n",
      "============================================================\n",
      "WHAM Implementation Summary:\n",
      "• Applied WHAM self-consistency equations to weight matrices\n",
      "• Found optimal Q-factors for combining ensemble data\n",
      "• Generated unbiased weight matrix from multiple ensembles\n",
      "• Analyzed ensemble contributions and convergence\n",
      "\n",
      "The WHAM matrix can now be used for transition probability calculations\n",
      "and should provide better statistical accuracy than simple summation.\n"
     ]
    }
   ],
   "source": [
    "# Example usage of WHAM for weight matrices\n",
    "if 'weight_matrices_results' in locals() and weight_matrices_results is not None:\n",
    "    print(\"Applying WHAM to weight matrices...\")\n",
    "    print(\"\\nThis implements WHAM where each transition [j,k] is treated as a histogram bin\")\n",
    "    print(\"that can be sampled by multiple ensembles with different statistical weights.\")\n",
    "    \n",
    "    # Apply WHAM to the weight matrices\n",
    "    wham_results = wham_weight_matrices(\n",
    "        weight_matrix_3d=weight_matrices_results['weight_matrix_3d'],\n",
    "        interfaces=weight_matrices_results['interfaces'],\n",
    "        max_iterations=1000,\n",
    "        tolerance=1e-8,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"WHAM ANALYSIS COMPLETE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Compare original vs WHAM results\n",
    "    compare_wham_results(weight_matrices_results, wham_results)\n",
    "    \n",
    "    # Analyze ensemble contributions\n",
    "    analyze_ensemble_contributions(wham_results)\n",
    "    \n",
    "    # Plot convergence (if matplotlib is available)\n",
    "    try:\n",
    "        plot_wham_convergence(wham_results)\n",
    "    except NameError:\n",
    "        print(\"\\nNote: matplotlib not imported - skipping convergence plot\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"WHAM Implementation Summary:\")\n",
    "    print(\"• Applied WHAM self-consistency equations to weight matrices\")\n",
    "    print(\"• Found optimal Q-factors for combining ensemble data\") \n",
    "    print(\"• Generated unbiased weight matrix from multiple ensembles\")\n",
    "    print(\"• Analyzed ensemble contributions and convergence\")\n",
    "    print(\"\\nThe WHAM matrix can now be used for transition probability calculations\")\n",
    "    print(\"and should provide better statistical accuracy than simple summation.\")\n",
    "    \n",
    "else:\n",
    "    print(\"Weight matrices not available. Please run the following steps first:\")\n",
    "    print(\"1. Load infretis data\")\n",
    "    print(\"2. Calculate infretis weights\") \n",
    "    print(\"3. Compute weight matrices\")\n",
    "    print(\"\\nThen re-run this cell to apply WHAM optimization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ad990f",
   "metadata": {},
   "source": [
    "## WHAM for Weight Matrices: Detailed Explanation\n",
    "\n",
    "### Theoretical Foundation\n",
    "\n",
    "The implementation adapts the standard WHAM equations to work with transition weight matrices instead of order parameter histograms:\n",
    "\n",
    "**Standard WHAM equations:**\n",
    "```\n",
    "ρ(λ) = Σᵢ ηᵢ Nᵢ(λ) / Σⱼ ηⱼ Qⱼ\n",
    "Qᵢ = Σ_λ ρ(λ) [if ensemble i can sample λ]\n",
    "```\n",
    "\n",
    "**Matrix WHAM equations:**\n",
    "```\n",
    "W_WHAM[j,k] = Σᵢ ηᵢ Wᵢ[j,k] / Σⱼ ηⱼ Qⱼ [where ensemble j can sample transition j→k]\n",
    "Qᵢ = Σ_{j,k} W_WHAM[j,k] [if ensemble i can sample transition j→k]\n",
    "```\n",
    "\n",
    "### Key Adaptations\n",
    "\n",
    "1. **Histogram bins → Transition elements**: Each matrix element `[j,k]` represents a transition that can be sampled by multiple ensembles.\n",
    "\n",
    "2. **Ensemble sampling rules**: The function `ensemble_can_sample_transition(i, j, k)` defines which ensembles can contribute to each transition, following TIS logic where ensemble `[i+]` primarily samples transitions starting from interface `i`.\n",
    "\n",
    "3. **Q-factors**: Represent the relative statistical weight of each ensemble, automatically determined by WHAM to optimally combine overlapping data.\n",
    "\n",
    "4. **Convergence**: The algorithm iterates until Q-factors stabilize, ensuring self-consistent combination of ensemble data.\n",
    "\n",
    "### Advantages over Simple Summation\n",
    "\n",
    "- **Optimal weighting**: Automatically determines how much to weight each ensemble based on statistical quality\n",
    "- **Bias correction**: Accounts for different sampling efficiencies between ensembles  \n",
    "- **Error reduction**: Properly combines overlapping information to reduce statistical noise\n",
    "- **Self-consistency**: Ensures the final result is consistent with all ensemble data simultaneously\n",
    "\n",
    "### Usage Notes\n",
    "\n",
    "The WHAM-optimized matrix can be used in place of the simple summed matrix for:\n",
    "- Transition probability calculations\n",
    "- iSTAR model construction  \n",
    "- Global crossing probability estimation\n",
    "\n",
    "The Q-factors provide insight into the relative importance of each ensemble in the final result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a34738",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
